{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "899a8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be7ac0",
   "metadata": {},
   "source": [
    "# Populate unique tokens of PPs to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "73b9e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pp_lexicon/unique_tokens_copy.json', 'r') as f:\n",
    "    unique_tokens_copy = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d7fc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lexicon = {}\n",
    "\n",
    "# Define a template for each lexical entry\n",
    "template = {\n",
    "    \"isAtomicMorph\": \"\",\n",
    "    \"class\": \"\",\n",
    "    \"spellOutHEAD\": [\"\"],\n",
    "    \"path_p_morphology\": \"\",\n",
    "    \"measure_allowed\": \"\"\n",
    "}\n",
    "\n",
    "for token in unique_tokens_copy:\n",
    "    p_lexicon[token] = {\n",
    "        \"isAtomicMorph\": template[\"isAtomicMorph\"],\n",
    "        \"class\": template[\"class\"],\n",
    "        \"spellOutHEAD\": list(template[\"spellOutHEAD\"]),\n",
    "        \"path_p_morphology\": template[\"path_p_morphology\"],\n",
    "        \"measure_allowed\": template[\"measure_allowed\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8acce877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write the p_lexicon to a JSON file\n",
    "# with open('pp_lexicon/p_lexicon.json', 'w') as f:\n",
    "#     json.dump(p_lexicon, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c9e6acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pp_lexicon/p_lexicon.json', 'r') as f:\n",
    "    annotated_p_lex = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a9fd592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty tokens: []\n",
      "Number of entries with empty values: 0\n"
     ]
    }
   ],
   "source": [
    "# check if annotated_p_lex value is empty string and calculate how many entries have empty values\n",
    "# also print the empty token\n",
    "empty_count = 0\n",
    "empty_tokens = []\n",
    "for token, entry in annotated_p_lex.items():\n",
    "    if entry[\"isAtomicMorph\"] == \"\" and entry[\"class\"] == \"\" and entry[\"path_p_morphology\"] == \"\" and entry[\"measure_allowed\"] == \"\" and entry[\"spellOutHEAD\"] == [\"\"]:\n",
    "        empty_count += 1\n",
    "        empty_tokens.append(token)\n",
    "print(f\"Empty tokens: {empty_tokens[8:18]}\")\n",
    "print(f\"Number of entries with empty values: {empty_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "81c67b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pps = list(annotated_p_lex.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c2a00db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pp_lexicon/unique_tokens_to_decompose.json', 'r') as f:\n",
    "    ut_decompose = json.load(f)\n",
    "\n",
    "to_decompose = ut_decompose[0]['to_decompose'] \n",
    "atomic = ut_decompose[1]['atomic'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30c08429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'top',\n",
       " 'by',\n",
       " 'to',\n",
       " 'but',\n",
       " 'end',\n",
       " 'for',\n",
       " 'high',\n",
       " 'via',\n",
       " 'side',\n",
       " 'back',\n",
       " 'rear',\n",
       " 'part',\n",
       " 'back',\n",
       " 'center',\n",
       " 'with',\n",
       " 'prior',\n",
       " 'front',\n",
       " 'opposite',\n",
       " 'from',\n",
       " 'beneath',\n",
       " 'rear',\n",
       " 'of',\n",
       " 'far',\n",
       " 'amid',\n",
       " 'board',\n",
       " 'next',\n",
       " 'ward',\n",
       " 'wards',\n",
       " 'under',\n",
       " 'neath',\n",
       " 'skin',\n",
       " 'flank',\n",
       " 'plus',\n",
       " 'middle',\n",
       " 'rim',\n",
       " 'face',\n",
       " 'close',\n",
       " 'amidst',\n",
       " 'virtue']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c9f2144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposer_pps = list_pps.copy()\n",
    "# drop values in decomposer_pps = ['astride', 'edge', 'on', 'to']\n",
    "decomposer_pps = [pp for pp in decomposer_pps if pp not in ['astride', 'edge', 'on', 'to']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b3f8576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english_word(w):\n",
    "    w = w.lower()\n",
    "    return bool(wn.synsets(w))\n",
    "\n",
    "def decompose_preposition(preposition, atomic_tokens, require_atomic_remainder=True):\n",
    "   \n",
    "    result = {}\n",
    "    p = preposition.lower()\n",
    "    atomic_lower = {tok.lower() for tok in atomic_tokens}\n",
    "\n",
    "    for token in atomic_tokens:\n",
    "        t = token.lower()\n",
    "        # Skip trivial cases and tokens that don't even appear inside p\n",
    "        if t == p:\n",
    "            continue\n",
    "        if t not in p:\n",
    "            continue\n",
    "\n",
    "        # Count how many times ‘t’ shows up in ‘p’\n",
    "        count = p.count(t)  \n",
    "        # Remove exactly one occurrence of t from p\n",
    "        remainder = p.replace(t, \"\", 1)\n",
    "\n",
    "        # Check remainder:\n",
    "        if require_atomic_remainder:\n",
    "            # We only accept remainders that are themselves in atomic_tokens:\n",
    "            if remainder in atomic_lower:\n",
    "                result[token] = {\n",
    "                    'decomposition': [token, remainder],\n",
    "                    'occurrence': count\n",
    "                }\n",
    "        else:\n",
    "            # We accept any English‐word remainder\n",
    "            if is_english_word(remainder):\n",
    "                result[token] = {\n",
    "                    'decomposition': [token, remainder],\n",
    "                    'occurrence': count\n",
    "                }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8728f4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'top',\n",
       " 'by',\n",
       " 'to',\n",
       " 'but',\n",
       " 'end',\n",
       " 'for',\n",
       " 'high',\n",
       " 'via',\n",
       " 'side',\n",
       " 'back',\n",
       " 'rear',\n",
       " 'part',\n",
       " 'back',\n",
       " 'center',\n",
       " 'with',\n",
       " 'prior',\n",
       " 'front',\n",
       " 'opposite',\n",
       " 'from',\n",
       " 'beneath',\n",
       " 'rear',\n",
       " 'of',\n",
       " 'far',\n",
       " 'amid',\n",
       " 'board',\n",
       " 'next',\n",
       " 'ward',\n",
       " 'wards',\n",
       " 'under',\n",
       " 'neath',\n",
       " 'skin',\n",
       " 'flank',\n",
       " 'plus',\n",
       " 'middle',\n",
       " 'rim',\n",
       " 'face',\n",
       " 'close',\n",
       " 'amidst',\n",
       " 'virtue']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3371752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astride',\n",
       " 'atop',\n",
       " 'corner',\n",
       " 'by',\n",
       " 'edge',\n",
       " 'onto',\n",
       " 'after',\n",
       " 'but',\n",
       " 'end',\n",
       " 'into',\n",
       " 'upside',\n",
       " 'for',\n",
       " 'base',\n",
       " 'higher',\n",
       " 'bottom',\n",
       " 'as',\n",
       " 'via',\n",
       " 'aside',\n",
       " 'back',\n",
       " 'nearest',\n",
       " 'betwixt',\n",
       " 'at',\n",
       " 'ahead',\n",
       " 'astern',\n",
       " 'following',\n",
       " 'center',\n",
       " 'within',\n",
       " 'prior',\n",
       " 'without',\n",
       " 'front',\n",
       " 'before',\n",
       " 'opposite',\n",
       " 'from',\n",
       " 'beneath',\n",
       " 'means',\n",
       " 'apart',\n",
       " 'towards',\n",
       " 'except',\n",
       " 'heart',\n",
       " 'afore',\n",
       " 'tween',\n",
       " 'aboard',\n",
       " 'throughout',\n",
       " 'foot',\n",
       " 'nearer',\n",
       " 'nigh',\n",
       " 'alongside',\n",
       " 'toward',\n",
       " 'amongst',\n",
       " 'adjacent',\n",
       " 'underneath',\n",
       " 'subsequent',\n",
       " 'addition',\n",
       " 'cross',\n",
       " 'surface',\n",
       " 'amidst',\n",
       " 'underside']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70c0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac7d9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposer_pps = list_pps.copy()\n",
    "\n",
    "\n",
    "result_decompose = {}\n",
    "for pp in to_decompose:\n",
    "    comps = decompose_preposition(pp, atomic, require_atomic_remainder=False)\n",
    "    if comps:\n",
    "        result_decompose[pp] = comps\n",
    "\n",
    "# turn it into a flat table\n",
    "rows = []\n",
    "for preposition, comps in result_decompose.items():\n",
    "    for token, details in comps.items():\n",
    "        rows.append({\n",
    "            'preposition': preposition,\n",
    "            'token': token,\n",
    "            'decomposition': details['decomposition'],\n",
    "            'occurrence': details['occurrence']\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de014758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print result_decompose dict as pandas\n",
    "df_decompose = pd.DataFrame(rows)\n",
    "df_decompose = df_decompose.sort_values(by=['preposition', 'occurrence'], ascending=[True, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae4465d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decompose\n",
    "# drop df_decompose row by index\n",
    "df_decompose = df_decompose.drop(index=[8,12, 6, 17, 19, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c5fd4f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>token</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aboard</td>\n",
       "      <td>a</td>\n",
       "      <td>[a, board]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aboard</td>\n",
       "      <td>board</td>\n",
       "      <td>[board, a]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>afore</td>\n",
       "      <td>a</td>\n",
       "      <td>[a, fore]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ahead</td>\n",
       "      <td>a</td>\n",
       "      <td>[a, head]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>alongside</td>\n",
       "      <td>side</td>\n",
       "      <td>[side, along]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>amidst</td>\n",
       "      <td>a</td>\n",
       "      <td>[a, midst]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>apart</td>\n",
       "      <td>a</td>\n",
       "      <td>[a, part]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>apart</td>\n",
       "      <td>part</td>\n",
       "      <td>[part, a]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aside</td>\n",
       "      <td>a</td>\n",
       "      <td>[a, side]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aside</td>\n",
       "      <td>side</td>\n",
       "      <td>[side, a]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>astern</td>\n",
       "      <td>a</td>\n",
       "      <td>[a, stern]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>astride</td>\n",
       "      <td>a</td>\n",
       "      <td>[a, stride]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atop</td>\n",
       "      <td>a</td>\n",
       "      <td>[a, top]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atop</td>\n",
       "      <td>top</td>\n",
       "      <td>[top, a]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>beneath</td>\n",
       "      <td>neath</td>\n",
       "      <td>[neath, be]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>higher</td>\n",
       "      <td>high</td>\n",
       "      <td>[high, er]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>into</td>\n",
       "      <td>to</td>\n",
       "      <td>[to, in]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onto</td>\n",
       "      <td>to</td>\n",
       "      <td>[to, on]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>surface</td>\n",
       "      <td>face</td>\n",
       "      <td>[face, sur]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>toward</td>\n",
       "      <td>to</td>\n",
       "      <td>[to, ward]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>towards</td>\n",
       "      <td>to</td>\n",
       "      <td>[to, wards]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>underneath</td>\n",
       "      <td>neath</td>\n",
       "      <td>[neath, under]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>underside</td>\n",
       "      <td>side</td>\n",
       "      <td>[side, under]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>underside</td>\n",
       "      <td>under</td>\n",
       "      <td>[under, side]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>upside</td>\n",
       "      <td>side</td>\n",
       "      <td>[side, up]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>within</td>\n",
       "      <td>with</td>\n",
       "      <td>[with, in]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>without</td>\n",
       "      <td>with</td>\n",
       "      <td>[with, out]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preposition  token   decomposition  occurrence\n",
       "24      aboard      a      [a, board]           2\n",
       "25      aboard  board      [board, a]           1\n",
       "23       afore      a       [a, fore]           1\n",
       "13       ahead      a       [a, head]           2\n",
       "26   alongside   side   [side, along]           1\n",
       "30      amidst      a      [a, midst]           1\n",
       "20       apart      a       [a, part]           2\n",
       "21       apart   part       [part, a]           1\n",
       "10       aside      a       [a, side]           1\n",
       "11       aside   side       [side, a]           1\n",
       "14      astern      a      [a, stern]           1\n",
       "0      astride      a     [a, stride]           1\n",
       "1         atop      a        [a, top]           1\n",
       "2         atop    top        [top, a]           1\n",
       "18     beneath  neath     [neath, be]           1\n",
       "7       higher   high      [high, er]           1\n",
       "4         into     to        [to, in]           1\n",
       "3         onto     to        [to, on]           1\n",
       "29     surface   face     [face, sur]           1\n",
       "27      toward     to      [to, ward]           1\n",
       "22     towards     to     [to, wards]           1\n",
       "28  underneath  neath  [neath, under]           1\n",
       "31   underside   side   [side, under]           1\n",
       "32   underside  under   [under, side]           1\n",
       "5       upside   side      [side, up]           1\n",
       "15      within   with      [with, in]           1\n",
       "16     without   with     [with, out]           1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8af761ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aboard',\n",
       " 'afore',\n",
       " 'ahead',\n",
       " 'alongside',\n",
       " 'amidst',\n",
       " 'apart',\n",
       " 'aside',\n",
       " 'astern',\n",
       " 'astride',\n",
       " 'atop',\n",
       " 'beneath',\n",
       " 'higher',\n",
       " 'into',\n",
       " 'onto',\n",
       " 'surface',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'underneath',\n",
       " 'underside',\n",
       " 'upside',\n",
       " 'within',\n",
       " 'without'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposed = set(df_decompose['preposition'])\n",
    "decomposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "89c2abca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['behind', 'above', 'below', 'beyond', 'in front of', 'inside', 'outside', 'left', 'right', 'against', 'among', 'beside', 'between', 'near', 'next to', 'upon', 'across', 'along', 'around', 'over', 'past', 'through', 'under', 'up', 'down', 'on', 'off', 'in', 'out', 'away'])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('pp_lexicon/atomic_p.json', 'r') as f:\n",
    "    atomic_p = json.load(f)\n",
    "atomic_p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea313ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'above',\n",
       " 'across',\n",
       " 'against',\n",
       " 'along',\n",
       " 'among',\n",
       " 'around',\n",
       " 'away',\n",
       " 'behind',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'down',\n",
       " 'in',\n",
       " 'in front of',\n",
       " 'inside',\n",
       " 'left',\n",
       " 'near',\n",
       " 'next to',\n",
       " 'off',\n",
       " 'on',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'past',\n",
       " 'right',\n",
       " 'through',\n",
       " 'under',\n",
       " 'up',\n",
       " 'upon'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract keys into a separate set so atomic_p (the dict) isn’t overwritten\n",
    "atomic_p_keys = set(atomic_p.keys())\n",
    "atomic_p_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "936143c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neath', 'plus', 'under', 'virtue', 'ward', 'wards'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match ut_decompose[1]['atomic'] with annotated_p_lex that is not empty entry\n",
    "atomic_set = set(atomic)\n",
    "annotated_atomic = set()\n",
    "for token, entry in annotated_p_lex.items():\n",
    "    if entry[\"isAtomicMorph\"] != \"\" or entry[\"class\"] != \"\" or entry[\"path_p_morphology\"] != \"\" or entry[\"measure_allowed\"] != \"\" or entry[\"spellOutHEAD\"] != [\"\"]:\n",
    "        annotated_atomic.add(token)\n",
    "annotated_atomic = annotated_atomic.intersection(atomic_set)\n",
    "# annotated_atomic\n",
    "\n",
    "# not annotated atomic tokens\n",
    "not_annotated_atomic = atomic_set - annotated_atomic\n",
    "not_annotated_atomic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bc6cf762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'back',\n",
       " 'beneath',\n",
       " 'board',\n",
       " 'but',\n",
       " 'by',\n",
       " 'center',\n",
       " 'close',\n",
       " 'end',\n",
       " 'face',\n",
       " 'far',\n",
       " 'flank',\n",
       " 'for',\n",
       " 'from',\n",
       " 'front',\n",
       " 'high',\n",
       " 'middle',\n",
       " 'next',\n",
       " 'of',\n",
       " 'opposite',\n",
       " 'part',\n",
       " 'prior',\n",
       " 'rear',\n",
       " 'rim',\n",
       " 'side',\n",
       " 'skin',\n",
       " 'to',\n",
       " 'top',\n",
       " 'via',\n",
       " 'with'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_atomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f9ff2c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'top',\n",
       " 'by',\n",
       " 'to',\n",
       " 'but',\n",
       " 'end',\n",
       " 'for',\n",
       " 'high',\n",
       " 'via',\n",
       " 'side',\n",
       " 'back',\n",
       " 'rear',\n",
       " 'part',\n",
       " 'back',\n",
       " 'center',\n",
       " 'with',\n",
       " 'prior',\n",
       " 'front',\n",
       " 'opposite',\n",
       " 'from',\n",
       " 'beneath',\n",
       " 'rear',\n",
       " 'of',\n",
       " 'far',\n",
       " 'amid',\n",
       " 'board',\n",
       " 'next',\n",
       " 'ward',\n",
       " 'wards',\n",
       " 'under',\n",
       " 'neath',\n",
       " 'skin',\n",
       " 'flank',\n",
       " 'plus',\n",
       " 'middle',\n",
       " 'rim',\n",
       " 'face',\n",
       " 'close',\n",
       " 'amidst',\n",
       " 'virtue']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut_decompose[1]['atomic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "efa61cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neath', 'plus', 'virtue', 'ward', 'wards'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_annotated_atomic = not_annotated_atomic - atomic_p_keys\n",
    "not_annotated_atomic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ac407",
   "metadata": {},
   "source": [
    "list of morphemes that are not annotated: {'neath', 'plus', 'virtue', 'ward', 'wards'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec1b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21c333b8",
   "metadata": {},
   "source": [
    "# Decompose spatial prepositional phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9640e02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'preposition', 'is_atomic', 'is_spatial', 'class',\n",
       "       'transitivity', 'synonyms', 'antonyms', 'hypernym', 'hyponym',\n",
       "       'meronym', 'holonym', 'supersense'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_pp_wordnet = pd.read_csv('dictionaries/pp_wordnet_dict_wiki_pop_fix.csv', sep=',')\n",
    "spatial_df_pp_wordnet = df_pp_wordnet[df_pp_wordnet['is_spatial'] == True]\n",
    "spatial_df_pp_wordnet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f5a66565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/80/2jj_gcx548x_37sfbd_5ny_h0000gn/T/ipykernel_69163/2395340022.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spatial_df_pp_wordnet.drop(columns=['Unnamed: 0'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "spatial_df_pp_wordnet.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ae1d91b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_full_pp = list(spatial_df_pp_wordnet['preposition'])\n",
    "len(list_full_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bbc89b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abroad',\n",
       " 'adrift',\n",
       " 'aft',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'ahead',\n",
       " 'apart',\n",
       " 'ashore',\n",
       " 'aside',\n",
       " 'away',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'beforehand',\n",
       " 'downhill',\n",
       " 'downstage',\n",
       " 'downstairs',\n",
       " 'downstream',\n",
       " 'downward',\n",
       " 'downwards',\n",
       " 'downwind',\n",
       " 'east',\n",
       " 'eastward',\n",
       " 'eastwards',\n",
       " 'forth',\n",
       " 'forward',\n",
       " 'forwards',\n",
       " 'heavenward',\n",
       " 'hence',\n",
       " 'henceforth',\n",
       " 'here',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereof',\n",
       " 'hereto',\n",
       " 'herewith',\n",
       " 'home',\n",
       " 'homeward',\n",
       " 'homewards',\n",
       " 'indoors',\n",
       " 'inward',\n",
       " 'inwards',\n",
       " 'leftward',\n",
       " 'leftwards',\n",
       " 'north',\n",
       " 'northeast',\n",
       " 'northward',\n",
       " 'northwards',\n",
       " 'northwest',\n",
       " 'now',\n",
       " 'onward',\n",
       " 'onwards',\n",
       " 'outdoors',\n",
       " 'outward',\n",
       " 'outwards',\n",
       " 'overboard',\n",
       " 'overhead',\n",
       " 'overland',\n",
       " 'overseas',\n",
       " 'rightward',\n",
       " 'rightwards',\n",
       " 'seaward',\n",
       " 'seawards',\n",
       " 'skyward',\n",
       " 'skywards',\n",
       " 'south',\n",
       " 'southeast',\n",
       " 'southward',\n",
       " 'southwards',\n",
       " 'southwest',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'thenceforth',\n",
       " 'there',\n",
       " 'thereby',\n",
       " 'therein',\n",
       " 'thereof',\n",
       " 'thereto',\n",
       " 'therewith',\n",
       " 'together',\n",
       " 'underfoot',\n",
       " 'underground',\n",
       " 'uphill',\n",
       " 'upstage',\n",
       " 'upstairs',\n",
       " 'upstream',\n",
       " 'upward',\n",
       " 'upwards',\n",
       " 'upwind',\n",
       " 'west',\n",
       " 'westward',\n",
       " 'westwards',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'where',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereto',\n",
       " 'wherewith']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intransitive_p = [\n",
    "    \"abroad\",\n",
    "    \"adrift\",\n",
    "    \"aft\",\n",
    "    \"afterward\",\n",
    "    \"afterwards\",\n",
    "    \"ahead\",\n",
    "    \"apart\",\n",
    "    \"ashore\",\n",
    "    \"aside\",\n",
    "    \"away\",\n",
    "    \"back\",\n",
    "    \"backward\",\n",
    "    \"backwards\",\n",
    "    \"beforehand\",\n",
    "    \"downhill\",\n",
    "    \"downstage\",\n",
    "    \"downstairs\",\n",
    "    \"downstream\",\n",
    "    \"downward\",\n",
    "    \"downwards\",\n",
    "    \"downwind\",\n",
    "    \"east\",\n",
    "    \"eastward(s)\",\n",
    "    \"forth\",\n",
    "    \"forward(s)\",\n",
    "    \"heavenward\",\n",
    "    \"hence\",\n",
    "    \"henceforth\",\n",
    "    \"here\",\n",
    "    \"hereby\",\n",
    "    \"herein\",\n",
    "    \"hereof\",\n",
    "    \"hereto\",\n",
    "    \"herewith\",\n",
    "    \"home\",\n",
    "    \"homeward(s)\",\n",
    "    \"indoors\",\n",
    "    \"inward(s)\",\n",
    "    \"leftward(s)\",\n",
    "    \"north\",\n",
    "    \"northeast\",\n",
    "    \"northward(s)\",\n",
    "    \"northwest\",\n",
    "    \"now\",\n",
    "    \"onward(s)\",\n",
    "    \"outdoors\",\n",
    "    \"outward(s)\",\n",
    "    \"overboard\",\n",
    "    \"overhead\",\n",
    "    \"overland\",\n",
    "    \"overseas\",\n",
    "    \"rightward(s)\",\n",
    "    \"seaward(s)\",\n",
    "    \"skyward(s)\",\n",
    "    \"south\",\n",
    "    \"southeast\",\n",
    "    \"southward(s)\",\n",
    "    \"southwest\",\n",
    "    \"then\",\n",
    "    \"thence\",\n",
    "    \"thenceforth\",\n",
    "    \"there\",\n",
    "    \"thereby\",\n",
    "    \"therein\",\n",
    "    \"thereof\",\n",
    "    \"thereto\",\n",
    "    \"therewith\",\n",
    "    \"together\",\n",
    "    \"underfoot\",\n",
    "    \"underground\",\n",
    "    \"uphill\",\n",
    "    \"upstage\",\n",
    "    \"upstairs\",\n",
    "    \"upstream\",\n",
    "    \"upward(s)\",\n",
    "    \"upwind\",\n",
    "    \"west\",\n",
    "    \"westward(s)\",\n",
    "    \"when\",\n",
    "    \"whence\",\n",
    "    \"where\",\n",
    "    \"whereby\",\n",
    "    \"wherein\",\n",
    "    \"whereto\",\n",
    "    \"wherewith\"\n",
    "]\n",
    "\n",
    "processed_list = []\n",
    "\n",
    "for item in intransitive_p:\n",
    "    if \"(s)\" in item:\n",
    "        processed_list.append(item.replace(\"(s)\", \"\"))\n",
    "        processed_list.append(item.replace(\"(s)\", \"s\"))\n",
    "    else:\n",
    "        processed_list.append(item)\n",
    "\n",
    "\n",
    "intransitive_p = processed_list\n",
    "\n",
    "intransitive_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53ba8643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>is_spatial</th>\n",
       "      <th>is_atomic</th>\n",
       "      <th>transitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aboard</td>\n",
       "      <td>True</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>above</td>\n",
       "      <td>True</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>across</td>\n",
       "      <td>True</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adjacent</td>\n",
       "      <td>True</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preposition is_spatial is_atomic transitivity\n",
       "0           a       True      TRUE          NaN\n",
       "1      aboard       True      TRUE         both\n",
       "3       above       True      TRUE         both\n",
       "6      across       True      TRUE         both\n",
       "7    adjacent       True      TRUE          NaN"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add intransitive_p to spatial_df_pp_wordnet\n",
    "spatial_df_pp_wordnet[[\n",
    "    'preposition', 'is_spatial', 'is_atomic', 'transitivity',\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b1e7b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add entries to spatial_df_pp_wordnet\n",
    "for pp in intransitive_p:\n",
    "    if pp not in spatial_df_pp_wordnet['preposition'].values:\n",
    "        new_row = pd.Series({\n",
    "            'preposition': pp,\n",
    "            'is_spatial': True,\n",
    "            'is_atomic': False,\n",
    "            'transitivity': 'intransitive',\n",
    "            'is_conjunctive': None\n",
    "        })\n",
    "        spatial_df_pp_wordnet = pd.concat(\n",
    "            [spatial_df_pp_wordnet, new_row.to_frame().T],\n",
    "            ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c60d0882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>is_atomic</th>\n",
       "      <th>is_spatial</th>\n",
       "      <th>class</th>\n",
       "      <th>transitivity</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>antonyms</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "      <th>meronym</th>\n",
       "      <th>holonym</th>\n",
       "      <th>supersense</th>\n",
       "      <th>is_conjunctive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ahead</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intransitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>apart</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intransitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aside</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>back</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>away</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>PARTICLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>where</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intransitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>whereby</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intransitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>wherein</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intransitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>whereto</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intransitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>wherewith</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intransitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    preposition is_atomic is_spatial     class  transitivity synonyms  \\\n",
       "9         ahead      TRUE       True       NaN  intransitive      NaN   \n",
       "17        apart      TRUE       True       NaN  intransitive      NaN   \n",
       "21        aside      TRUE       True       NaN           NaN      NaN   \n",
       "30         back      TRUE       True       NaN           NaN      NaN   \n",
       "132        away      TRUE       True  PARTICLE           NaN      NaN   \n",
       "..          ...       ...        ...       ...           ...      ...   \n",
       "222       where     False       True       NaN  intransitive      NaN   \n",
       "223     whereby     False       True       NaN  intransitive      NaN   \n",
       "224     wherein     False       True       NaN  intransitive      NaN   \n",
       "225     whereto     False       True       NaN  intransitive      NaN   \n",
       "226   wherewith     False       True       NaN  intransitive      NaN   \n",
       "\n",
       "    antonyms hypernym hyponym meronym holonym supersense is_conjunctive  \n",
       "9        NaN      NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "17       NaN      NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "21       NaN      NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "30       NaN      NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "132      NaN      NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "..       ...      ...     ...     ...     ...        ...            ...  \n",
       "222      NaN      NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "223      NaN      NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "224      NaN      NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "225      NaN      NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "226      NaN      NaN     NaN     NaN     NaN        NaN           None  \n",
       "\n",
       "[99 rows x 13 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_df_pp_wordnet[spatial_df_pp_wordnet['preposition'].isin(intransitive_p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "234d029a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spatial_df_pp_wordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a6f658e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transitivity\n",
       "intransitive    97\n",
       "both            25\n",
       "transitive      16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_pp_wordnet['transitivity'] == 'intransitive'\n",
    "spatial_df_pp_wordnet['transitivity'].value_counts()\n",
    "\n",
    "# save the spatial_df_pp_wordnet to a csv file\n",
    "# spatial_df_pp_wordnet.to_csv('dictionaries/pp_wordnet_wiki_pop_fix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2718a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunctive_p = [\n",
    "    \"after\",\n",
    "    \"although\",\n",
    "    \"as\",\n",
    "    \"at\",\n",
    "    \"because\",\n",
    "    \"before\",\n",
    "    \"beside\",\n",
    "    \"besides\",\n",
    "    \"between\",\n",
    "    \"by\",\n",
    "    \"considering\",\n",
    "    \"despite\",\n",
    "    \"except\",\n",
    "    \"for\",\n",
    "    \"from\",\n",
    "    \"given\",\n",
    "    \"granted\",\n",
    "    \"if\",\n",
    "    \"into\",\n",
    "    \"lest\",\n",
    "    \"like\",\n",
    "    \"notwithstanding\",\n",
    "    \"now\",\n",
    "    \"of\",\n",
    "    \"on\",\n",
    "    \"once\",\n",
    "    \"provided\",\n",
    "    \"providing\",\n",
    "    \"save\",\n",
    "    \"seeing\",\n",
    "    \"since\",\n",
    "    \"so\",\n",
    "    \"supposing\",\n",
    "    \"than\",\n",
    "    \"though\",\n",
    "    \"till\",\n",
    "    \"to\",\n",
    "    \"unless\",\n",
    "    \"until\",\n",
    "    \"upon\",\n",
    "    \"when\",\n",
    "    \"whenever\",\n",
    "    \"where\",\n",
    "    \"whereas\",\n",
    "    \"wherever\",\n",
    "    \"while\",\n",
    "    \"whilst\",\n",
    "    \"with\",\n",
    "    \"without\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "97fc4103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>is_atomic</th>\n",
       "      <th>is_spatial</th>\n",
       "      <th>class</th>\n",
       "      <th>transitivity</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>antonyms</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "      <th>meronym</th>\n",
       "      <th>holonym</th>\n",
       "      <th>supersense</th>\n",
       "      <th>is_conjunctive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aboard</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>alongside, on base, on board</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>above</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>PROJECTIVE</td>\n",
       "      <td>both</td>\n",
       "      <td>higher up, in a higher place, supra, to a high...</td>\n",
       "      <td>below</td>\n",
       "      <td>section, subdivision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>across</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>EXTENDED</td>\n",
       "      <td>both</td>\n",
       "      <td>crossways, crosswise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjacent</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preposition is_atomic is_spatial       class transitivity  \\\n",
       "0           a      TRUE       True         NaN          NaN   \n",
       "1      aboard      TRUE       True         NaN         both   \n",
       "2       above      TRUE       True  PROJECTIVE         both   \n",
       "3      across      TRUE       True    EXTENDED         both   \n",
       "4    adjacent      TRUE       True         NaN          NaN   \n",
       "\n",
       "                                            synonyms antonyms  \\\n",
       "0                                                NaN      NaN   \n",
       "1                       alongside, on base, on board      NaN   \n",
       "2  higher up, in a higher place, supra, to a high...    below   \n",
       "3                               crossways, crosswise      NaN   \n",
       "4                                                NaN      NaN   \n",
       "\n",
       "               hypernym hyponym meronym holonym supersense is_conjunctive  \n",
       "0                   NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "1                   NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "2  section, subdivision     NaN     NaN     NaN        NaN            NaN  \n",
       "3                   NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "4                   NaN     NaN     NaN     NaN        NaN            NaN  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_df_pp_wordnet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0fa276bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add entries to spatial_df_pp_wordnet\n",
    "for pp in conjunctive_p:\n",
    "    if pp not in spatial_df_pp_wordnet['preposition'].values:\n",
    "        new_row = pd.Series({\n",
    "            'preposition': pp,\n",
    "            'is_spatial': True,\n",
    "            'is_atomic': False,\n",
    "            'transitivity': 'transitive',\n",
    "            'is_conjunctive': True\n",
    "        })\n",
    "        spatial_df_pp_wordnet = pd.concat(\n",
    "            [spatial_df_pp_wordnet, new_row.to_frame().T],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "# mark all others as not conjunctive\n",
    "# mask = spatial_df_pp_wordnet['preposition'].isin(conjunctive_p)\n",
    "# spatial_df_pp_wordnet.loc[~mask, 'is_conjunctive'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0776ad12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>is_atomic</th>\n",
       "      <th>is_spatial</th>\n",
       "      <th>class</th>\n",
       "      <th>transitivity</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>antonyms</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "      <th>meronym</th>\n",
       "      <th>holonym</th>\n",
       "      <th>supersense</th>\n",
       "      <th>is_conjunctive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aboard</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>alongside, on base, on board</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>above</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>PROJECTIVE</td>\n",
       "      <td>both</td>\n",
       "      <td>higher up, in a higher place, supra, to a high...</td>\n",
       "      <td>below</td>\n",
       "      <td>section, subdivision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>across</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>EXTENDED</td>\n",
       "      <td>both</td>\n",
       "      <td>crossways, crosswise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjacent</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preposition is_atomic is_spatial       class transitivity  \\\n",
       "0           a      TRUE       True         NaN          NaN   \n",
       "1      aboard      TRUE       True         NaN         both   \n",
       "2       above      TRUE       True  PROJECTIVE         both   \n",
       "3      across      TRUE       True    EXTENDED         both   \n",
       "4    adjacent      TRUE       True         NaN          NaN   \n",
       "\n",
       "                                            synonyms antonyms  \\\n",
       "0                                                NaN      NaN   \n",
       "1                       alongside, on base, on board      NaN   \n",
       "2  higher up, in a higher place, supra, to a high...    below   \n",
       "3                               crossways, crosswise      NaN   \n",
       "4                                                NaN      NaN   \n",
       "\n",
       "               hypernym hyponym meronym holonym supersense is_conjunctive  \n",
       "0                   NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "1                   NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "2  section, subdivision     NaN     NaN     NaN        NaN            NaN  \n",
       "3                   NaN     NaN     NaN     NaN        NaN            NaN  \n",
       "4                   NaN     NaN     NaN     NaN        NaN            NaN  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_df_pp_wordnet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7ea1922b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_conjunctive\n",
       "True    30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_df_pp_wordnet['is_conjunctive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aea4f395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_spatial\n",
       "True    257\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_df_pp_wordnet['is_spatial'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4038396b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: preposition, dtype: object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_df_pp_wordnet.loc[\n",
    "\tspatial_df_pp_wordnet['preposition'] == 'according to',\n",
    "\t'preposition'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "113aea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_plus_p = [\n",
    "    \"across from\",\n",
    "    \"ahead of\",\n",
    "    \"along with\",\n",
    "    \"apart from\",\n",
    "    \"as for\",\n",
    "    \"as from\",\n",
    "    \"as of\",\n",
    "    \"as per\",\n",
    "    \"as regards\",\n",
    "    \"as to\",\n",
    "    \"aside from\",\n",
    "    \"away from\",\n",
    "    \"back to\",\n",
    "    \"counter to\",\n",
    "    \"in between\",\n",
    "    \"near to\",\n",
    "    \"next to\",\n",
    "    \"opposite of\",\n",
    "    \"out from\",\n",
    "    \"out of\",\n",
    "    \"outside of\",\n",
    "    \"round about\",\n",
    "    \"up against\",\n",
    "    \"up to\",\n",
    "    \"close to\",\n",
    "    \"due to\",\n",
    "    \"far from\",\n",
    "    \"prior to\",\n",
    "    \"pursuant to\",\n",
    "    \"rather than\",\n",
    "    \"subsequent to\",\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8361b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_article_noun_p = [\n",
    "    \"by way of\",\n",
    "    \"for lack of\",\n",
    "    \"from want of\",\n",
    "    \"for want of\",\n",
    "    \"in contact with\",\n",
    "    \"in line with\",\n",
    "    \"in place of\",\n",
    "    \"in point of\",\n",
    "    \"in relation to\",\n",
    "    \"with regard to\",\n",
    "    \"in regard to\",\n",
    "    \"with respect to\",\n",
    "    \"in respect to\",\n",
    "    \"in touch with\",\n",
    "    \"on grounds of\",\n",
    "    \"on the part of\",\n",
    "    \"on top of\",\n",
    "    \"with a view to\",\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d6192150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial_df_pp_wordnet['is_conjunctive'] turn to false if not true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6aa2a770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_spatial\n",
       "True    257\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_df_pp_wordnet['is_spatial'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "49ea582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make conjunctive_p p_plus_p p_article_noun_p to json file named complex_pp.json\n",
    "# complex_pp = {\n",
    "#     \"conjunctive_p\": conjunctive_p,\n",
    "#     \"p_plus_p\": p_plus_p,\n",
    "#     \"p_article_noun_p\": p_article_noun_p\n",
    "# }\n",
    "# with open('pp_lexicon/complex_pp_repop.json', 'w') as f:\n",
    "#     json.dump(complex_pp, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
