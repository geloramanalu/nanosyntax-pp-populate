{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e6a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import json\n",
    "import csv\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef62d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['above', 'across', 'against', 'along', 'among', 'around', 'away', 'behind', 'below', 'beside', 'between', 'beyond', 'down', 'in', 'in front of', 'inside', 'left', 'near', 'next to', 'off', 'on', 'out', 'outside', 'over', 'past', 'right', 'through', 'under', 'up', 'upon']\n"
     ]
    }
   ],
   "source": [
    "with open('pp_lexicon/atomic_p.json', 'r') as f:\n",
    "    pp = json.load(f)\n",
    "    \n",
    "# sort pp['atomic_p'].keys() alphabetically\n",
    "keys_sorted = sorted(pp['atomic_p'].keys())\n",
    "print(keys_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f2f3284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "497f8c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'above': ['above',\n",
       "  'supra',\n",
       "  'higher_up',\n",
       "  'in_a_higher_place',\n",
       "  'to_a_higher_place'],\n",
       " 'across': ['across', 'crosswise', 'crossways'],\n",
       " 'against': [],\n",
       " 'along': ['along', 'on'],\n",
       " 'among': [],\n",
       " 'around': ['about',\n",
       "  'around',\n",
       "  'approximately',\n",
       "  'close_to',\n",
       "  'just_about',\n",
       "  'some',\n",
       "  'roughly',\n",
       "  'more_or_less',\n",
       "  'or_so',\n",
       "  'round'],\n",
       " 'away': ['away', 'outside', 'off', 'forth', 'out', 'aside', 'by'],\n",
       " 'behind': ['buttocks',\n",
       "  'nates',\n",
       "  'arse',\n",
       "  'butt',\n",
       "  'backside',\n",
       "  'bum',\n",
       "  'buns',\n",
       "  'can',\n",
       "  'fundament',\n",
       "  'hindquarters',\n",
       "  'hind_end',\n",
       "  'keister',\n",
       "  'posterior',\n",
       "  'prat',\n",
       "  'rear',\n",
       "  'rear_end',\n",
       "  'rump',\n",
       "  'stern',\n",
       "  'seat',\n",
       "  'tail',\n",
       "  'tail_end',\n",
       "  'tooshie',\n",
       "  'tush',\n",
       "  'bottom',\n",
       "  'behind',\n",
       "  'derriere',\n",
       "  'fanny',\n",
       "  'ass',\n",
       "  'slow',\n",
       "  'behindhand',\n",
       "  'in_arrears'],\n",
       " 'below': ['below',\n",
       "  'at_a_lower_place',\n",
       "  'to_a_lower_place',\n",
       "  'beneath',\n",
       "  'infra',\n",
       "  'downstairs',\n",
       "  'down_the_stairs',\n",
       "  'on_a_lower_floor',\n",
       "  'under'],\n",
       " 'beside': [],\n",
       " 'between': ['between', 'betwixt', \"'tween\"],\n",
       " 'beyond': ['beyond'],\n",
       " 'down': ['down',\n",
       "  'down_feather',\n",
       "  'Down',\n",
       "  'John_L._H._Down',\n",
       "  'pile',\n",
       "  'toss_off',\n",
       "  'pop',\n",
       "  'bolt_down',\n",
       "  'belt_down',\n",
       "  'pour_down',\n",
       "  'drink_down',\n",
       "  'kill',\n",
       "  'devour',\n",
       "  'consume',\n",
       "  'go_through',\n",
       "  'shoot_down',\n",
       "  'land',\n",
       "  'knock_down',\n",
       "  'cut_down',\n",
       "  'push_down',\n",
       "  'pull_down',\n",
       "  'polish',\n",
       "  'refine',\n",
       "  'fine-tune',\n",
       "  'downward',\n",
       "  'down_pat',\n",
       "  'mastered',\n",
       "  'depressed',\n",
       "  'gloomy',\n",
       "  'grim',\n",
       "  'blue',\n",
       "  'dispirited',\n",
       "  'downcast',\n",
       "  'downhearted',\n",
       "  'down_in_the_mouth',\n",
       "  'low',\n",
       "  'low-spirited',\n",
       "  'downwards',\n",
       "  'downwardly'],\n",
       " 'in': ['inch',\n",
       "  'in',\n",
       "  'indium',\n",
       "  'In',\n",
       "  'atomic_number_49',\n",
       "  'Indiana',\n",
       "  'Hoosier_State',\n",
       "  'IN',\n",
       "  'inwards',\n",
       "  'inward'],\n",
       " 'in front of': [],\n",
       " 'inside': ['inside',\n",
       "  'interior',\n",
       "  'inner',\n",
       "  'privileged',\n",
       "  'indoors',\n",
       "  'within',\n",
       "  'inwardly',\n",
       "  'at_heart',\n",
       "  'at_bottom',\n",
       "  'deep_down',\n",
       "  'in_spite_of_appearance'],\n",
       " 'left': ['left',\n",
       "  'left_wing',\n",
       "  'left_hand',\n",
       "  'left_field',\n",
       "  'leftfield',\n",
       "  'leave',\n",
       "  'go_forth',\n",
       "  'go_away',\n",
       "  'leave_alone',\n",
       "  'leave_behind',\n",
       "  'exit',\n",
       "  'go_out',\n",
       "  'get_out',\n",
       "  'allow_for',\n",
       "  'allow',\n",
       "  'provide',\n",
       "  'result',\n",
       "  'lead',\n",
       "  'depart',\n",
       "  'pull_up_stakes',\n",
       "  'entrust',\n",
       "  'bequeath',\n",
       "  'will',\n",
       "  'impart',\n",
       "  'give',\n",
       "  'pass_on',\n",
       "  'forget',\n",
       "  'leftover',\n",
       "  'left_over',\n",
       "  'odd',\n",
       "  'remaining',\n",
       "  'unexpended',\n",
       "  'left-hand'],\n",
       " 'near': ['approach',\n",
       "  'near',\n",
       "  'come_on',\n",
       "  'go_up',\n",
       "  'draw_near',\n",
       "  'draw_close',\n",
       "  'come_near',\n",
       "  'close',\n",
       "  'nigh',\n",
       "  'cheeseparing',\n",
       "  'penny-pinching',\n",
       "  'skinny',\n",
       "  'dear',\n",
       "  'good',\n",
       "  'approximate',\n",
       "  'about',\n",
       "  'almost',\n",
       "  'most',\n",
       "  'nearly',\n",
       "  'virtually',\n",
       "  'well-nigh'],\n",
       " 'next to': [],\n",
       " 'off': ['murder',\n",
       "  'slay',\n",
       "  'hit',\n",
       "  'dispatch',\n",
       "  'bump_off',\n",
       "  'off',\n",
       "  'polish_off',\n",
       "  'remove',\n",
       "  'cancelled',\n",
       "  'sour',\n",
       "  'turned',\n",
       "  'away',\n",
       "  'forth'],\n",
       " 'on': ['on', 'along'],\n",
       " 'out': ['out',\n",
       "  'come_out_of_the_closet',\n",
       "  'come_out',\n",
       "  'extinct',\n",
       "  'forbidden',\n",
       "  'prohibited',\n",
       "  'proscribed',\n",
       "  'taboo',\n",
       "  'tabu',\n",
       "  'verboten',\n",
       "  'knocked_out',\n",
       "  'kayoed',\n",
       "  \"KO'd\",\n",
       "  'stunned',\n",
       "  'away'],\n",
       " 'outside': ['outside',\n",
       "  'exterior',\n",
       "  'external',\n",
       "  'extraneous',\n",
       "  'outdoor',\n",
       "  'out-of-door',\n",
       "  'international',\n",
       "  'remote',\n",
       "  'away',\n",
       "  'outdoors',\n",
       "  'out_of_doors',\n",
       "  'alfresco'],\n",
       " 'over': ['over',\n",
       "  'complete',\n",
       "  'concluded',\n",
       "  'ended',\n",
       "  'all_over',\n",
       "  'terminated',\n",
       "  \"o'er\"],\n",
       " 'past': ['past',\n",
       "  'past_times',\n",
       "  'yesteryear',\n",
       "  'past_tense',\n",
       "  'preceding',\n",
       "  'retiring',\n",
       "  'by'],\n",
       " 'right': ['right',\n",
       "  'right_field',\n",
       "  'rightfield',\n",
       "  'right_wing',\n",
       "  'right_hand',\n",
       "  'rightfulness',\n",
       "  'compensate',\n",
       "  'redress',\n",
       "  'correct',\n",
       "  'rectify',\n",
       "  'proper',\n",
       "  'right-hand',\n",
       "  'good',\n",
       "  'ripe',\n",
       "  'veracious',\n",
       "  'flop',\n",
       "  'properly',\n",
       "  'decently',\n",
       "  'decent',\n",
       "  'in_good_order',\n",
       "  'the_right_way',\n",
       "  'right_on',\n",
       "  'mighty',\n",
       "  'mightily',\n",
       "  'powerful',\n",
       "  'justly',\n",
       "  'correctly',\n",
       "  'aright'],\n",
       " 'through': ['done', 'through', 'through_with', 'through_and_through'],\n",
       " 'under': ['nether', 'under', 'below'],\n",
       " 'up': ['up', 'astir', 'improving', 'upward', 'upwards', 'upwardly'],\n",
       " 'upon': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_atomic_p = {}\n",
    "for key in keys_sorted:\n",
    "    # collect all lemma names in a flat list\n",
    "    all_lemmas = []\n",
    "    for syn in wn.synsets(key):\n",
    "        all_lemmas.extend(syn.lemma_names())\n",
    "    # remove duplicates while preserving order\n",
    "    synonyms_atomic_p[key] = list(dict.fromkeys(all_lemmas))\n",
    "\n",
    "# inspect result\n",
    "synonyms_atomic_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # synonyms atomic_p to json\n",
    "# with open('synonyms_atomic_p.json', 'w') as f:\n",
    "#     json.dump(synonyms_atomic_p, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f49238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atomic_p_prop(prop='', counter=5):\n",
    "# pp is a dict, access preposition as key\n",
    "    try:\n",
    "        if prop is not None and prop in ['isAtomicMorph', 'class', 'spellOutHEAD', 'path_p_morphology', 'measure_allowed']:\n",
    "            for key, value in pp['atomic_p'].items():\n",
    "                # print(f\"key: {key}\")\n",
    "                for el in value:\n",
    "                    if el == prop:\n",
    "                        print(f\"{key}: {pp['atomic_p'][key][el]} \")\n",
    "                        counter += 1\n",
    "                        if counter == 5:\n",
    "                            break\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} not found in atomic_p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b81715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_wordnet_wiki_pop = []\n",
    "with open('dictionaries/pp_wordnet_wiki_pop.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, quotechar='|', dialect='excel')\n",
    "    for row in reader:\n",
    "        if row['preposition'] == '':\n",
    "            continue\n",
    "        pp_wordnet_wiki_pop.append({\n",
    "            'preposition': row['preposition'],\n",
    "            'isAtomic': row.get('is_atomic'),\n",
    "            'isSpatial': row.get('is_spatial')\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7877221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pp_wordnet_wiki_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac005df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_wordnet_wiki_pop_spatial = [pp for pp in pp_wordnet_wiki_pop if pp['isSpatial'] == 'TRUE']\n",
    "len(pp_wordnet_wiki_pop_spatial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdb45a",
   "metadata": {},
   "source": [
    "## Get atomic morphemes from unique tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0990610",
   "metadata": {},
   "source": [
    "Unique tokens from the list of wikipedia, wordnet, and dictionaries preposition phrase individual words (as token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5578b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of unique_tokens before: 106\n",
      "numbers of non overlapping unique_tokens: 78\n",
      "top\n",
      "astride\n",
      "atop\n",
      "corner\n",
      "by\n",
      "edge\n",
      "onto\n",
      "after\n",
      "but\n",
      "end\n",
      "into\n",
      "upside\n",
      "for\n",
      "place\n",
      "base\n",
      "higher\n",
      "bottom\n",
      "as\n",
      "via\n",
      "aside\n",
      "back\n",
      "nearest\n",
      "betwixt\n",
      "at\n",
      "ahead\n",
      "astern\n",
      "following\n",
      "center\n",
      "within\n",
      "prior\n",
      "without\n",
      "front\n",
      "before\n",
      "opposite\n",
      "from\n",
      "beneath\n",
      "with\n",
      "rear\n",
      "means\n",
      "apart\n",
      "towards\n",
      "except\n",
      "heart\n",
      "afore\n",
      "tween\n",
      "aboard\n",
      "throughout\n",
      "foot\n",
      "nearer\n",
      "nigh\n",
      "alongside\n",
      "virtue\n",
      "next\n",
      "toward\n",
      "amongst\n",
      "side\n",
      "the\n",
      "of\n",
      "far\n",
      "amid\n",
      "adjacent\n",
      "underneath\n",
      "skin\n",
      "flank\n",
      "plus\n",
      "to\n",
      "subsequent\n",
      "addition\n",
      "cross\n",
      "surface\n",
      "a\n",
      "amidst\n",
      "underside\n",
      "middle\n",
      "core\n",
      "rim\n",
      "face\n",
      "close\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = set() # unique token is defined as set of unique words in preposition\n",
    "def tokenize_preposition(preposition):\n",
    "    return preposition.split(' ')\n",
    "\n",
    "# Example usage\n",
    "for pp in pp_wordnet_wiki_pop_spatial:\n",
    "    tokens = tokenize_preposition(pp['preposition'])\n",
    "    # print(f\"Tokens for '{pp['preposition']}': {tokens}\")    \n",
    "    unique_tokens.update(tokens)\n",
    "\n",
    "print(f\"length of unique_tokens before: {len(unique_tokens)}\")\n",
    "\n",
    "c = 0\n",
    "unique_tokens_copy = unique_tokens.copy()\n",
    "for k in keys_sorted:\n",
    "    if k in unique_tokens_copy:\n",
    "        unique_tokens_copy.remove(k)\n",
    "        c += 1\n",
    "        # print(f\"{k} is in unique tokens\")\n",
    "    else:\n",
    "        # print(f\"{k} is NOT in unique tokens\")\n",
    "        continue\n",
    "print(f\"numbers of non overlapping unique_tokens: {len(unique_tokens_copy)}\")\n",
    "\n",
    "for k in unique_tokens_copy:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d444a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export unique_tokens_copy as json\n",
    "# with open('pp_lexicon/unique_tokens_copy.json', 'w') as f:\n",
    "#     json.dump(list(unique_tokens_copy), f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b9cfc",
   "metadata": {},
   "source": [
    "## Decompose p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3164a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english_word(w):\n",
    "    w = w.lower()\n",
    "    return bool(wn.synsets(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baad4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_preposition(preposition, unique_tokens, method='substring'):\n",
    "    \n",
    "    result = {}\n",
    "    p = preposition.lower()\n",
    "\n",
    "    if method == 'substring':\n",
    "        for token in unique_tokens:\n",
    "            t = token.lower()\n",
    "            if p not in t:\n",
    "                continue\n",
    "\n",
    "            count = t.count(p)\n",
    "\n",
    "            remainder = t.replace(p, \"\", 1)\n",
    "\n",
    "            # if remainder == '':\n",
    "            #     continue\n",
    "            if is_english_word(p) and is_english_word(remainder):\n",
    "                result[token] = {\n",
    "                    'decomposition': [p, remainder],\n",
    "                    'occurrence': count\n",
    "            }\n",
    "\n",
    "        return result\n",
    "    \n",
    "        # if method == 'find_bigram':\n",
    "    \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60f0b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['above',\n",
       " 'across',\n",
       " 'against',\n",
       " 'along',\n",
       " 'among',\n",
       " 'around',\n",
       " 'away',\n",
       " 'behind',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'down',\n",
       " 'in',\n",
       " 'in front of',\n",
       " 'inside',\n",
       " 'left',\n",
       " 'near',\n",
       " 'next to',\n",
       " 'off',\n",
       " 'on',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'past',\n",
       " 'right',\n",
       " 'through',\n",
       " 'under',\n",
       " 'up',\n",
       " 'upon']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# atomic = list(keys_sorted['atomic_p'].keys())\n",
    "atomic = keys_sorted\n",
    "atomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc09f230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'aboard',\n",
       " 'addition',\n",
       " 'adjacent',\n",
       " 'afore',\n",
       " 'after',\n",
       " 'ahead',\n",
       " 'alongside',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amongst',\n",
       " 'apart',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'astern',\n",
       " 'astride',\n",
       " 'at',\n",
       " 'atop',\n",
       " 'back',\n",
       " 'base',\n",
       " 'before',\n",
       " 'beneath',\n",
       " 'betwixt',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'center',\n",
       " 'close',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'cross',\n",
       " 'edge',\n",
       " 'end',\n",
       " 'except',\n",
       " 'face',\n",
       " 'far',\n",
       " 'flank',\n",
       " 'following',\n",
       " 'foot',\n",
       " 'for',\n",
       " 'from',\n",
       " 'front',\n",
       " 'heart',\n",
       " 'higher',\n",
       " 'into',\n",
       " 'means',\n",
       " 'middle',\n",
       " 'nearer',\n",
       " 'nearest',\n",
       " 'next',\n",
       " 'nigh',\n",
       " 'of',\n",
       " 'onto',\n",
       " 'opposite',\n",
       " 'place',\n",
       " 'plus',\n",
       " 'prior',\n",
       " 'rear',\n",
       " 'rim',\n",
       " 'side',\n",
       " 'skin',\n",
       " 'subsequent',\n",
       " 'surface',\n",
       " 'the',\n",
       " 'throughout',\n",
       " 'to',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tween',\n",
       " 'underneath',\n",
       " 'underside',\n",
       " 'upside',\n",
       " 'via',\n",
       " 'virtue',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fb5094e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>token</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>along</td>\n",
       "      <td>alongside</td>\n",
       "      <td>[along, side]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>near</td>\n",
       "      <td>nearest</td>\n",
       "      <td>[near, est]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>near</td>\n",
       "      <td>nearer</td>\n",
       "      <td>[near, er]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>out</td>\n",
       "      <td>throughout</td>\n",
       "      <td>[out, through]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>through</td>\n",
       "      <td>throughout</td>\n",
       "      <td>[through, out]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>under</td>\n",
       "      <td>underside</td>\n",
       "      <td>[under, side]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>up</td>\n",
       "      <td>upside</td>\n",
       "      <td>[up, side]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preposition       token   decomposition  occurrence\n",
       "0       along   alongside   [along, side]           1\n",
       "1        near     nearest     [near, est]           1\n",
       "2        near      nearer      [near, er]           1\n",
       "3         out  throughout  [out, through]           1\n",
       "4     through  throughout  [through, out]           1\n",
       "5       under   underside   [under, side]           1\n",
       "6          up      upside      [up, side]           1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect all decompositions\n",
    "result_decompose = {}\n",
    "for pp in atomic:\n",
    "    if pp in unique_tokens:\n",
    "        comps = decompose_preposition(pp, unique_tokens_copy, method='substring')\n",
    "        if comps:\n",
    "            result_decompose[pp] = comps\n",
    "\n",
    "# turn it into a flat table\n",
    "rows = []\n",
    "for preposition, comps in result_decompose.items():\n",
    "    for token, details in comps.items():\n",
    "        rows.append({\n",
    "            'preposition': preposition,\n",
    "            'token': token,\n",
    "            'decomposition': details['decomposition'],\n",
    "            'occurrence': details['occurrence']\n",
    "        })\n",
    "\n",
    "# dataFrame of all decompositions\n",
    "df_decompose = pandas.DataFrame(rows)\n",
    "df_decompose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea05cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "ece68351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'er', 'est', 'out', 'side', 'through'}"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remainder_decomp = [el[1] for el in df_decompose['decomposition']]\n",
    "# remainder_decomp = set(remainder_decomp)\n",
    "# to_remove = {'so', 'pot', 'mus', 'pot', 'mus', 'ab'} #particles and morphemes that isnt valid\n",
    "# remainder_decomp = remainder_decomp - to_remove\n",
    "# remainder_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70cee548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of unique_tokens_not_decomposed: 72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'aboard',\n",
       " 'addition',\n",
       " 'adjacent',\n",
       " 'afore',\n",
       " 'after',\n",
       " 'ahead',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amongst',\n",
       " 'apart',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'astern',\n",
       " 'astride',\n",
       " 'at',\n",
       " 'atop',\n",
       " 'back',\n",
       " 'base',\n",
       " 'before',\n",
       " 'beneath',\n",
       " 'betwixt',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'center',\n",
       " 'close',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'cross',\n",
       " 'edge',\n",
       " 'end',\n",
       " 'except',\n",
       " 'face',\n",
       " 'far',\n",
       " 'flank',\n",
       " 'following',\n",
       " 'foot',\n",
       " 'for',\n",
       " 'from',\n",
       " 'front',\n",
       " 'heart',\n",
       " 'higher',\n",
       " 'into',\n",
       " 'means',\n",
       " 'middle',\n",
       " 'next',\n",
       " 'nigh',\n",
       " 'of',\n",
       " 'onto',\n",
       " 'opposite',\n",
       " 'place',\n",
       " 'plus',\n",
       " 'prior',\n",
       " 'rear',\n",
       " 'rim',\n",
       " 'side',\n",
       " 'skin',\n",
       " 'subsequent',\n",
       " 'surface',\n",
       " 'the',\n",
       " 'to',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tween',\n",
       " 'underneath',\n",
       " 'via',\n",
       " 'virtue',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tokens in df_decompose\n",
    "tokens_decompose = set()\n",
    "for token in df_decompose['token']:\n",
    "    tokens_decompose.add(token)\n",
    "\n",
    "unique_tokens_not_decomposed = unique_tokens_copy - tokens_decompose\n",
    "print(f\"length of unique_tokens_not_decomposed: {len(unique_tokens_not_decomposed)}\")\n",
    "unique_tokens_not_decomposed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d36227",
   "metadata": {},
   "source": [
    "There are 114 unique tokens of prepositional phrase that are not decomposed by atomic_ps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1526f5",
   "metadata": {},
   "source": [
    "## Stemming for checking atomic elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a5c1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "# Create instances of each stemmer\n",
    "porter   = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50646d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          index           0        1\n",
      "0          away        away     None\n",
      "1           top         top     None\n",
      "2            by          by     None\n",
      "3           edg        edge     None\n",
      "4         after       after     None\n",
      "5           but         but     None\n",
      "6           end         end     None\n",
      "7        outsid     outside     None\n",
      "8         among       among     None\n",
      "9          into        into     None\n",
      "10        along       along     None\n",
      "11        upsid      upside     None\n",
      "12          for         for     None\n",
      "13        place       place     None\n",
      "14       bottom      bottom     None\n",
      "15         asid       aside     None\n",
      "16      betwixt     betwixt     None\n",
      "17           at          at     None\n",
      "18        ahead       ahead     None\n",
      "19       astern      astern     None\n",
      "20       center      center     None\n",
      "21      without     without     None\n",
      "22        front       front     None\n",
      "23         near        near     None\n",
      "24         with        with     None\n",
      "25         rear        rear     None\n",
      "26        apart       apart     None\n",
      "27       except      except     None\n",
      "28         past        past     None\n",
      "29          off         off     None\n",
      "30        tween       tween     None\n",
      "31   throughout  throughout     None\n",
      "32     alongsid   alongside     None\n",
      "33       toward      toward  towards\n",
      "34      amongst     amongst     None\n",
      "35         side        side     None\n",
      "36         left        left     None\n",
      "37      through     through     None\n",
      "38      between     between     None\n",
      "39          plu        plus     None\n",
      "40           to          to     None\n",
      "41      subsequ  subsequent     None\n",
      "42        addit    addition     None\n",
      "43        cross       cross     None\n",
      "44            a           a     None\n",
      "45           up          up     None\n",
      "46       amidst      amidst     None\n",
      "47     undersid   underside     None\n",
      "48         core        core     None\n",
      "49         over        over     None\n",
      "50       beyond      beyond     None\n",
      "51         atop        atop     None\n",
      "52       across      across     None\n",
      "53      against     against     None\n",
      "54       corner      corner     None\n",
      "55         down        down     None\n",
      "56         onto        onto     None\n",
      "57        right       right     None\n",
      "58         base        base     None\n",
      "59       higher      higher     None\n",
      "60           as          as     None\n",
      "61          via         via     None\n",
      "62         back        back     None\n",
      "63      nearest     nearest     None\n",
      "64        below       below     None\n",
      "65       follow   following     None\n",
      "66       within      within     None\n",
      "67        prior       prior     None\n",
      "68       behind      behind     None\n",
      "69         abov       above     None\n",
      "70        befor      before     None\n",
      "71      opposit    opposite     None\n",
      "72        under       under     None\n",
      "73         from        from     None\n",
      "74      beneath     beneath     None\n",
      "75          out         out     None\n",
      "76         mean       means     None\n",
      "77        besid      beside     None\n",
      "78        heart       heart     None\n",
      "79         afor       afore     None\n",
      "80           on          on     None\n",
      "81       aboard      aboard     None\n",
      "82         foot        foot     None\n",
      "83        insid      inside     None\n",
      "84       nearer      nearer     None\n",
      "85         nigh        nigh     None\n",
      "86        virtu      virtue     None\n",
      "87         next        next     None\n",
      "88          the         the     None\n",
      "89       around      around     None\n",
      "90           of          of     None\n",
      "91           in          in     None\n",
      "92          far         far     None\n",
      "93         amid        amid     None\n",
      "94        adjac    adjacent     None\n",
      "95   underneath  underneath     None\n",
      "96         skin        skin     None\n",
      "97        flank       flank     None\n",
      "98         upon        upon     None\n",
      "99       surfac     surface     None\n",
      "100       middl      middle     None\n",
      "101         rim         rim     None\n",
      "102        face        face     None\n",
      "103      astrid     astride     None\n",
      "104       close       close     None\n"
     ]
    }
   ],
   "source": [
    "stemmer = [porter, lancaster, snowball]\n",
    "# build mapping token -> stem for each stemmer\n",
    "def build_stem_mapping(tokens, stemmer):\n",
    "    stem_mapping = {}\n",
    "    for token in tokens:\n",
    "        stem = stemmer.stem(token)\n",
    "        if stem not in stem_mapping:\n",
    "            stem_mapping[stem] = []\n",
    "        stem_mapping[stem].append(token)\n",
    "    return stem_mapping\n",
    "\n",
    "df_stem_porter = build_stem_mapping(unique_tokens, porter)\n",
    "df_stem_lancaster = build_stem_mapping(unique_tokens, lancaster)\n",
    "df_stem_snowball = build_stem_mapping(unique_tokens, snowball)\n",
    "# Convert the stem mappings to DataFrames\n",
    "df_stem_porter = pandas.DataFrame.from_dict(df_stem_porter, orient='index').reset_index()\n",
    "\n",
    "print(df_stem_porter.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b89189b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'away': ['away'],\n",
       " 'top': ['top'],\n",
       " 'by': ['by'],\n",
       " 'edg': ['edge'],\n",
       " 'aft': ['after'],\n",
       " 'but': ['but'],\n",
       " 'end': ['end'],\n",
       " 'outsid': ['outside'],\n",
       " 'among': ['among'],\n",
       " 'into': ['into'],\n",
       " 'along': ['along'],\n",
       " 'upsid': ['upside'],\n",
       " 'for': ['for'],\n",
       " 'plac': ['place'],\n",
       " 'bottom': ['bottom'],\n",
       " 'asid': ['aside'],\n",
       " 'betwixt': ['betwixt'],\n",
       " 'at': ['at'],\n",
       " 'ahead': ['ahead'],\n",
       " 'astern': ['astern'],\n",
       " 'cent': ['center'],\n",
       " 'without': ['without'],\n",
       " 'front': ['front'],\n",
       " 'near': ['near', 'nearer'],\n",
       " 'with': ['with'],\n",
       " 'rear': ['rear'],\n",
       " 'apart': ['apart'],\n",
       " 'exceiv': ['except'],\n",
       " 'past': ['past'],\n",
       " 'off': ['off'],\n",
       " 'tween': ['tween'],\n",
       " 'throughout': ['throughout'],\n",
       " 'alongsid': ['alongside'],\n",
       " 'toward': ['toward', 'towards'],\n",
       " 'amongst': ['amongst'],\n",
       " 'sid': ['side'],\n",
       " 'left': ['left'],\n",
       " 'through': ['through'],\n",
       " 'between': ['between'],\n",
       " 'plu': ['plus'],\n",
       " 'to': ['to'],\n",
       " 'subsequ': ['subsequent'],\n",
       " 'addit': ['addition'],\n",
       " 'cross': ['cross'],\n",
       " 'a': ['a'],\n",
       " 'up': ['up'],\n",
       " 'amidst': ['amidst'],\n",
       " 'undersid': ['underside'],\n",
       " 'cor': ['core'],\n",
       " 'ov': ['over'],\n",
       " 'beyond': ['beyond'],\n",
       " 'atop': ['atop'],\n",
       " 'across': ['across'],\n",
       " 'against': ['against'],\n",
       " 'corn': ['corner'],\n",
       " 'down': ['down'],\n",
       " 'onto': ['onto'],\n",
       " 'right': ['right'],\n",
       " 'bas': ['base'],\n",
       " 'high': ['higher'],\n",
       " 'as': ['as'],\n",
       " 'via': ['via'],\n",
       " 'back': ['back'],\n",
       " 'nearest': ['nearest'],\n",
       " 'below': ['below'],\n",
       " 'follow': ['following'],\n",
       " 'within': ['within'],\n",
       " 'pri': ['prior'],\n",
       " 'behind': ['behind'],\n",
       " 'abov': ['above'],\n",
       " 'bef': ['before'],\n",
       " 'opposit': ['opposite'],\n",
       " 'und': ['under'],\n",
       " 'from': ['from'],\n",
       " 'benea': ['beneath'],\n",
       " 'out': ['out'],\n",
       " 'mean': ['means'],\n",
       " 'besid': ['beside'],\n",
       " 'heart': ['heart'],\n",
       " 'af': ['afore'],\n",
       " 'on': ['on'],\n",
       " 'aboard': ['aboard'],\n",
       " 'foot': ['foot'],\n",
       " 'insid': ['inside'],\n",
       " 'nigh': ['nigh'],\n",
       " 'virtu': ['virtue'],\n",
       " 'next': ['next'],\n",
       " 'the': ['the'],\n",
       " 'around': ['around'],\n",
       " 'of': ['of'],\n",
       " 'in': ['in'],\n",
       " 'far': ['far'],\n",
       " 'amid': ['amid'],\n",
       " 'adjac': ['adjacent'],\n",
       " 'undernea': ['underneath'],\n",
       " 'skin': ['skin'],\n",
       " 'flank': ['flank'],\n",
       " 'upon': ['upon'],\n",
       " 'surfac': ['surface'],\n",
       " 'middl': ['middle'],\n",
       " 'rim': ['rim'],\n",
       " 'fac': ['face'],\n",
       " 'astrid': ['astride'],\n",
       " 'clos': ['close']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stem_lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd5cd9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'away': ['away'],\n",
       " 'top': ['top'],\n",
       " 'by': ['by'],\n",
       " 'edg': ['edge'],\n",
       " 'after': ['after'],\n",
       " 'but': ['but'],\n",
       " 'end': ['end'],\n",
       " 'outsid': ['outside'],\n",
       " 'among': ['among'],\n",
       " 'into': ['into'],\n",
       " 'along': ['along'],\n",
       " 'upsid': ['upside'],\n",
       " 'for': ['for'],\n",
       " 'place': ['place'],\n",
       " 'bottom': ['bottom'],\n",
       " 'asid': ['aside'],\n",
       " 'betwixt': ['betwixt'],\n",
       " 'at': ['at'],\n",
       " 'ahead': ['ahead'],\n",
       " 'astern': ['astern'],\n",
       " 'center': ['center'],\n",
       " 'without': ['without'],\n",
       " 'front': ['front'],\n",
       " 'near': ['near'],\n",
       " 'with': ['with'],\n",
       " 'rear': ['rear'],\n",
       " 'apart': ['apart'],\n",
       " 'except': ['except'],\n",
       " 'past': ['past'],\n",
       " 'off': ['off'],\n",
       " 'tween': ['tween'],\n",
       " 'throughout': ['throughout'],\n",
       " 'alongsid': ['alongside'],\n",
       " 'toward': ['toward', 'towards'],\n",
       " 'amongst': ['amongst'],\n",
       " 'side': ['side'],\n",
       " 'left': ['left'],\n",
       " 'through': ['through'],\n",
       " 'between': ['between'],\n",
       " 'plus': ['plus'],\n",
       " 'to': ['to'],\n",
       " 'subsequ': ['subsequent'],\n",
       " 'addit': ['addition'],\n",
       " 'cross': ['cross'],\n",
       " 'a': ['a'],\n",
       " 'up': ['up'],\n",
       " 'amidst': ['amidst'],\n",
       " 'undersid': ['underside'],\n",
       " 'core': ['core'],\n",
       " 'over': ['over'],\n",
       " 'beyond': ['beyond'],\n",
       " 'atop': ['atop'],\n",
       " 'across': ['across'],\n",
       " 'against': ['against'],\n",
       " 'corner': ['corner'],\n",
       " 'down': ['down'],\n",
       " 'onto': ['onto'],\n",
       " 'right': ['right'],\n",
       " 'base': ['base'],\n",
       " 'higher': ['higher'],\n",
       " 'as': ['as'],\n",
       " 'via': ['via'],\n",
       " 'back': ['back'],\n",
       " 'nearest': ['nearest'],\n",
       " 'below': ['below'],\n",
       " 'follow': ['following'],\n",
       " 'within': ['within'],\n",
       " 'prior': ['prior'],\n",
       " 'behind': ['behind'],\n",
       " 'abov': ['above'],\n",
       " 'befor': ['before'],\n",
       " 'opposit': ['opposite'],\n",
       " 'under': ['under'],\n",
       " 'from': ['from'],\n",
       " 'beneath': ['beneath'],\n",
       " 'out': ['out'],\n",
       " 'mean': ['means'],\n",
       " 'besid': ['beside'],\n",
       " 'heart': ['heart'],\n",
       " 'afor': ['afore'],\n",
       " 'on': ['on'],\n",
       " 'aboard': ['aboard'],\n",
       " 'foot': ['foot'],\n",
       " 'insid': ['inside'],\n",
       " 'nearer': ['nearer'],\n",
       " 'nigh': ['nigh'],\n",
       " 'virtu': ['virtue'],\n",
       " 'next': ['next'],\n",
       " 'the': ['the'],\n",
       " 'around': ['around'],\n",
       " 'of': ['of'],\n",
       " 'in': ['in'],\n",
       " 'far': ['far'],\n",
       " 'amid': ['amid'],\n",
       " 'adjac': ['adjacent'],\n",
       " 'underneath': ['underneath'],\n",
       " 'skin': ['skin'],\n",
       " 'flank': ['flank'],\n",
       " 'upon': ['upon'],\n",
       " 'surfac': ['surface'],\n",
       " 'middl': ['middle'],\n",
       " 'rim': ['rim'],\n",
       " 'face': ['face'],\n",
       " 'astrid': ['astride'],\n",
       " 'close': ['close']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stem_snowball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561dd234",
   "metadata": {},
   "source": [
    "## Get atomic morphemes with ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1b96d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens not decomposed:\n",
      "top\n",
      "atop\n",
      "corner\n",
      "by\n",
      "edge\n",
      "onto\n",
      "after\n",
      "but\n",
      "end\n",
      "into\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "print(\"Unique tokens not decomposed:\")\n",
    "for i in unique_tokens_not_decomposed:\n",
    "    print(i)\n",
    "    c += 1\n",
    "    if c == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5861a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_ngrams(tokens, n):\n",
    "\n",
    "    ngrams_list = []\n",
    "    ngram_map = {}\n",
    "    \n",
    "    for token in tokens:\n",
    "        for gram in ngrams(list(token), n):\n",
    "            # check if gram is valid suffix or prefix in english with wordnet\n",
    "            \n",
    "            \n",
    "            ngrams_list.append(''.join(gram))\n",
    "            \n",
    "            g = ''.join(gram)\n",
    "            ngram_map.setdefault(g, []).append(token)\n",
    "    return ngrams_list, ngram_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f3aa003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(count: 12) | id: ['outside', 'upside', 'aside', 'alongside', 'side', 'amidst', 'underside', 'beside', 'inside', 'amid', 'middle', 'astride'] \n",
      "(count: 12) | de: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'underside', 'under', 'beside', 'inside', 'underneath', 'astride'] \n",
      "(count: 11) | ar: ['near', 'rear', 'apart', 'toward', 'nearest', 'towards', 'heart', 'aboard', 'nearer', 'around', 'far'] \n",
      "(count: 10) | er: ['after', 'astern', 'center', 'underside', 'over', 'corner', 'higher', 'under', 'nearer', 'underneath'] \n",
      "(count: 10) | on: ['among', 'along', 'front', 'alongside', 'amongst', 'addition', 'beyond', 'onto', 'on', 'upon'] \n",
      "(count: 9) | si: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'opposite', 'beside', 'inside'] \n",
      "(count: 9) | ea: ['ahead', 'near', 'rear', 'nearest', 'beneath', 'means', 'heart', 'nearer', 'underneath'] \n",
      "(count: 8) | to: ['top', 'into', 'bottom', 'toward', 'to', 'atop', 'onto', 'towards'] \n",
      "(count: 8) | in: ['into', 'against', 'following', 'within', 'behind', 'inside', 'in', 'skin'] \n",
      "(count: 8) | be: ['betwixt', 'between', 'beyond', 'below', 'behind', 'before', 'beneath', 'beside'] \n",
      "(count: 8) | th: ['without', 'with', 'throughout', 'through', 'within', 'beneath', 'the', 'underneath'] \n",
      "(count: 7) | en: ['end', 'center', 'tween', 'between', 'subsequent', 'beneath', 'adjacent'] \n",
      "(count: 7) | nd: ['end', 'underside', 'beyond', 'behind', 'under', 'around', 'underneath'] \n",
      "(count: 7) | ou: ['outside', 'without', 'throughout', 'throughout', 'through', 'out', 'around'] \n",
      "(count: 7) | st: ['astern', 'past', 'amongst', 'amidst', 'against', 'nearest', 'astride'] \n",
      "(count: 7) | ro: ['front', 'throughout', 'through', 'cross', 'across', 'from', 'around'] \n",
      "(count: 7) | ne: ['near', 'corner', 'nearest', 'beneath', 'nearer', 'next', 'underneath'] \n",
      "(count: 6) | nt: ['into', 'center', 'front', 'subsequent', 'onto', 'adjacent'] \n",
      "(count: 6) | or: ['for', 'core', 'corner', 'prior', 'before', 'afore'] \n",
      "(count: 6) | ac: ['place', 'across', 'back', 'adjacent', 'surface', 'face'] \n"
     ]
    }
   ],
   "source": [
    "# get bigrams of letters from each token\n",
    "bigrams_list, bigram_map = get_char_ngrams(unique_tokens, 2)\n",
    "bigram_counts = Counter(bigrams_list)\n",
    "most_common_bigrams = bigram_counts.most_common(20)\n",
    "\n",
    "for bigram, count in most_common_bigrams:\n",
    "    mapping = bigram_map.get(bigram, [])\n",
    "    print(f\"(count: {count}) | {bigram}: {mapping} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb0852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4400bd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ide: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'beside', 'inside', 'astride'] (count: 9)\n",
      "sid: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'beside', 'inside'] (count: 8)\n",
      "nea: ['near', 'nearest', 'beneath', 'nearer', 'underneath'] (count: 5)\n",
      "ear: ['near', 'rear', 'nearest', 'heart', 'nearer'] (count: 5)\n",
      "out: ['outside', 'without', 'throughout', 'out'] (count: 4)\n",
      "ong: ['among', 'along', 'alongside', 'amongst'] (count: 4)\n",
      "ace: ['place', 'adjacent', 'surface', 'face'] (count: 4)\n",
      "und: ['underside', 'under', 'around', 'underneath'] (count: 4)\n",
      "ter: ['after', 'astern', 'center'] (count: 3)\n",
      "for: ['for', 'before', 'afore'] (count: 3)\n",
      "ast: ['astern', 'past', 'astride'] (count: 3)\n",
      "ent: ['center', 'subsequent', 'adjacent'] (count: 3)\n",
      "wit: ['without', 'with', 'within'] (count: 3)\n",
      "ith: ['without', 'with', 'within'] (count: 3)\n",
      "rou: ['throughout', 'through', 'around'] (count: 3)\n",
      "ard: ['toward', 'towards', 'aboard'] (count: 3)\n",
      "mid: ['amidst', 'amid', 'middle'] (count: 3)\n",
      "nde: ['underside', 'under', 'underneath'] (count: 3)\n",
      "der: ['underside', 'under', 'underneath'] (count: 3)\n",
      "ore: ['core', 'before', 'afore'] (count: 3)\n"
     ]
    }
   ],
   "source": [
    "trigrams_list, trigram_map = get_char_ngrams(unique_tokens, 3)\n",
    "trigram_counts = Counter(trigrams_list)\n",
    "most_common_trigrams = trigram_counts.most_common(20)\n",
    "\n",
    "for trigram, count in most_common_trigrams:\n",
    "    mapping = trigram_map.get(trigram, [])\n",
    "    print(f\"{trigram}: {mapping} (count: {count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9405f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'beside', 'inside'] (count: 8)\n",
      "with: ['without', 'with', 'within'] (count: 3)\n",
      "near: ['near', 'nearest', 'nearer'] (count: 3)\n",
      "unde: ['underside', 'under', 'underneath'] (count: 3)\n",
      "nder: ['underside', 'under', 'underneath'] (count: 3)\n",
      "amon: ['among', 'amongst'] (count: 2)\n",
      "mong: ['among', 'amongst'] (count: 2)\n",
      "alon: ['along', 'alongside'] (count: 2)\n",
      "long: ['along', 'alongside'] (count: 2)\n",
      "betw: ['betwixt', 'between'] (count: 2)\n",
      "cent: ['center', 'adjacent'] (count: 2)\n",
      "hout: ['without', 'throughout'] (count: 2)\n",
      "twee: ['tween', 'between'] (count: 2)\n",
      "ween: ['tween', 'between'] (count: 2)\n",
      "thro: ['throughout', 'through'] (count: 2)\n",
      "hrou: ['throughout', 'through'] (count: 2)\n",
      "roug: ['throughout', 'through'] (count: 2)\n",
      "ough: ['throughout', 'through'] (count: 2)\n",
      "ongs: ['alongside', 'amongst'] (count: 2)\n",
      "towa: ['toward', 'towards'] (count: 2)\n"
     ]
    }
   ],
   "source": [
    "fourgrams_list, fourgram_map = get_char_ngrams(unique_tokens, 4)\n",
    "fourgram_counts = Counter(fourgrams_list)\n",
    "most_common_fourgrams = fourgram_counts.most_common(20)\n",
    "\n",
    "for fourgram, count in most_common_fourgrams:\n",
    "    mapping = fourgram_map.get(fourgram, [])\n",
    "    print(f\"{fourgram}: {mapping} (count: {count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d793c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Code snippet to check whether an nletter string acts \n",
    "# as a prefix/suffix in WordNets English lexicon\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Make sure wordnet is downloaded:\n",
    "# nltk.download(\"wordnet\")\n",
    "\n",
    "lemmas = set(wn.all_lemma_names())\n",
    "\n",
    "def find_affix_pairs(gram):\n",
    "    g = gram.lower()\n",
    "    suffix = []\n",
    "    prefix = []\n",
    "    for w in lemmas:\n",
    "        if w.endswith(g) and len(w) > len(g):\n",
    "            base = w[:-len(g)]\n",
    "            if base in lemmas:\n",
    "                suffix.append((base, w))\n",
    "        if w.startswith(g) and len(w) > len(g):\n",
    "            base = w[len(g):]\n",
    "            if base in lemmas:\n",
    "                prefix.append((w, base))\n",
    "    return (prefix, suffix) if (prefix or suffix) else None\n",
    "\n",
    "def get_common_affix(ngram_list, n):\n",
    "    for bg in ngram_list:\n",
    "        found = find_affix_pairs(bg)\n",
    "        if not found:\n",
    "            print(f\"{n}gram '{bg}' does NOT appear as a productive affix.\\n\")\n",
    "            continue\n",
    "\n",
    "        prefix, suffix = found\n",
    "\n",
    "        if suffix:\n",
    "            print(f\"{n}gram '{bg}' as SUFFIX:\")\n",
    "            for base, suffixed in suffix[:10]:\n",
    "                print(f\"   {base}  {suffixed}\")\n",
    "            print(f\"  ({len(suffix)} total)\\n\")\n",
    "\n",
    "        if prefix:\n",
    "            print(f\"{n}gram '{bg}' as PREFIX:\")\n",
    "            for prefixed, base in prefix[:10]:\n",
    "                print(f\"   {prefixed}  {base}\")\n",
    "            print(f\"  ({len(prefix)} total)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b3386e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2gram 'id' as SUFFIX:\n",
      "   pa  paid\n",
      "   nsa  nsaid\n",
      "   fet  fetid\n",
      "   sol  solid\n",
      "   ar  arid\n",
      "   inla  inlaid\n",
      "   ov  ovid\n",
      "   re  reid\n",
      "   p  pid\n",
      "   ma  maid\n",
      "  (62 total)\n",
      "\n",
      "2gram 'id' as PREFIX:\n",
      "   ido  o\n",
      "   ides  es\n",
      "   idf  f\n",
      "   idle  le\n",
      "   idea  ea\n",
      "   identity  entity\n",
      "   idp  p\n",
      "   iddm  dm\n",
      "   idling  ling\n",
      "   idun  un\n",
      "  (12 total)\n",
      "\n",
      "2gram 'de' as SUFFIX:\n",
      "   ce  cede\n",
      "   ri  ride\n",
      "   ba  bade\n",
      "   abo  abode\n",
      "   man  mande\n",
      "   ai  aide\n",
      "   phyllo  phyllode\n",
      "   chi  chide\n",
      "   fa  fade\n",
      "   gui  guide\n",
      "  (42 total)\n",
      "\n",
      "2gram 'de' as PREFIX:\n",
      "   devisor  visor\n",
      "   deal  al\n",
      "   denomination  nomination\n",
      "   delegation  legation\n",
      "   degauss  gauss\n",
      "   decay  cay\n",
      "   debut  but\n",
      "   decoder  coder\n",
      "   deconstructivism  constructivism\n",
      "   depopulate  populate\n",
      "  (461 total)\n",
      "\n",
      "2gram 'ar' as SUFFIX:\n",
      "   son  sonar\n",
      "   chad  chadar\n",
      "   column  columnar\n",
      "   ge  gear\n",
      "   huss  hussar\n",
      "   inst  instar\n",
      "   line  linear\n",
      "   gu  guar\n",
      "   tart  tartar\n",
      "   astragal  astragalar\n",
      "  (80 total)\n",
      "\n",
      "2gram 'ar' as PREFIX:\n",
      "   arkansan  kansan\n",
      "   arrange  range\n",
      "   ardea  dea\n",
      "   array  ray\n",
      "   arrester  rester\n",
      "   arco  co\n",
      "   arrest  rest\n",
      "   arhus  hus\n",
      "   arson  son\n",
      "   arid  id\n",
      "  (79 total)\n",
      "\n",
      "2gram 'er' as SUFFIX:\n",
      "   teetotal  teetotaler\n",
      "   crapshoot  crapshooter\n",
      "   stand  stander\n",
      "   down  downer\n",
      "   tamp  tamper\n",
      "   molt  molter\n",
      "   roar  roarer\n",
      "   guess  guesser\n",
      "   tam  tamer\n",
      "   probation  probationer\n",
      "  (1427 total)\n",
      "\n",
      "2gram 'er' as PREFIX:\n",
      "   erne  ne\n",
      "   eragrostis  agrostis\n",
      "   erie  ie\n",
      "   ert  t\n",
      "   era  a\n",
      "   erodium  odium\n",
      "   errand  rand\n",
      "   erin  in\n",
      "   erect  ect\n",
      "   erode  ode\n",
      "  (22 total)\n",
      "\n",
      "2gram 'on' as SUFFIX:\n",
      "   gris  grison\n",
      "   po  poon\n",
      "   johns  johnson\n",
      "   pashto  pashtoon\n",
      "   pomp  pompon\n",
      "   ir  iron\n",
      "   mo  moon\n",
      "   ka  kaon\n",
      "   mac  macon\n",
      "   actin  actinon\n",
      "  (171 total)\n",
      "\n",
      "2gram 'on' as PREFIX:\n",
      "   onus  us\n",
      "   onion  ion\n",
      "   onstage  stage\n",
      "   ongoing  going\n",
      "   onset  set\n",
      "   once  ce\n",
      "   onshore  shore\n",
      "   onward  ward\n",
      "   oni  i\n",
      "   onlooker  looker\n",
      "  (16 total)\n",
      "\n",
      "2gram 'si' as SUFFIX:\n",
      "   ni  nisi\n",
      "   pep  pepsi\n",
      "   man  mansi\n",
      "   tut  tutsi\n",
      "   i  isi\n",
      "   far  farsi\n",
      "   par  parsi\n",
      "   p  psi\n",
      "   sc  scsi\n",
      "  (9 total)\n",
      "\n",
      "2gram 'si' as PREFIX:\n",
      "   sidelight  delight\n",
      "   siva  va\n",
      "   sidle  dle\n",
      "   sion  on\n",
      "   sids  ds\n",
      "   simoon  moon\n",
      "   simon  mon\n",
      "   siberia  beria\n",
      "   siwan  wan\n",
      "   sing  ng\n",
      "  (52 total)\n",
      "\n",
      "2gram 'ea' as SUFFIX:\n",
      "   corn  cornea\n",
      "   tineoid  tineoidea\n",
      "   med  medea\n",
      "   phoronid  phoronidea\n",
      "   pang  pangea\n",
      "   id  idea\n",
      "   kor  korea\n",
      "   napa  napaea\n",
      "   sabin  sabinea\n",
      "   caesar  caesarea\n",
      "  (56 total)\n",
      "\n",
      "2gram 'ea' as PREFIX:\n",
      "   eas  s\n",
      "   earn  rn\n",
      "   easing  sing\n",
      "   eat  t\n",
      "   eared  red\n",
      "   ease  se\n",
      "   ear  r\n",
      "   eating  ting\n",
      "   eastern  stern\n",
      "   eatable  table\n",
      "  (10 total)\n",
      "\n",
      "2gram 'to' as SUFFIX:\n",
      "   ko  koto\n",
      "   grot  grotto\n",
      "   pro  proto\n",
      "   dit  ditto\n",
      "   get_on  get_onto\n",
      "   dig_in  dig_into\n",
      "   na  nato\n",
      "   pot  potto\n",
      "   pan  panto\n",
      "   pas  pasto\n",
      "  (48 total)\n",
      "\n",
      "2gram 'to' as PREFIX:\n",
      "   today  day\n",
      "   tone  ne\n",
      "   torus  rus\n",
      "   tour  ur\n",
      "   toad  ad\n",
      "   too  o\n",
      "   tonga  nga\n",
      "   toda  da\n",
      "   toed  ed\n",
      "   tomb  mb\n",
      "  (56 total)\n",
      "\n",
      "2gram 'in' as SUFFIX:\n",
      "   buffer  bufferin\n",
      "   jacob  jacobin\n",
      "   augment  augmentin\n",
      "   tall  tallin\n",
      "   sat  satin\n",
      "   puff  puffin\n",
      "   f  fin\n",
      "   ra  rain\n",
      "   ops  opsin\n",
      "   digital  digitalin\n",
      "  (110 total)\n",
      "\n",
      "2gram 'in' as PREFIX:\n",
      "   inhumanely  humanely\n",
      "   infrequently  frequently\n",
      "   ineligibility  eligibility\n",
      "   inconsideration  consideration\n",
      "   insinuate  sinuate\n",
      "   instep  step\n",
      "   instill  still\n",
      "   infallibility  fallibility\n",
      "   incorrectly  correctly\n",
      "   inefficiency  efficiency\n",
      "  (693 total)\n",
      "\n",
      "2gram 'be' as SUFFIX:\n",
      "   vi  vibe\n",
      "   ro  robe\n",
      "   ado  adobe\n",
      "   micro  microbe\n",
      "   danu  danube\n",
      "   n  nbe\n",
      "   lu  lube\n",
      "   se  sebe\n",
      "   cu  cube\n",
      "   gy  gybe\n",
      "  (26 total)\n",
      "\n",
      "2gram 'be' as PREFIX:\n",
      "   berate  rate\n",
      "   bema  ma\n",
      "   bespangle  spangle\n",
      "   bewilder  wilder\n",
      "   befuddle  fuddle\n",
      "   beda  da\n",
      "   bey  y\n",
      "   bedimmed  dimmed\n",
      "   bedroll  droll\n",
      "   bestir  stir\n",
      "  (151 total)\n",
      "\n",
      "2gram 'th' as SUFFIX:\n",
      "   call_for  call_forth\n",
      "   wye  wyeth\n",
      "   ro  roth\n",
      "   four  fourth\n",
      "   quadrillion  quadrillionth\n",
      "   go  goth\n",
      "   heal  health\n",
      "   36  36th\n",
      "   pa  path\n",
      "   47  47th\n",
      "  (151 total)\n",
      "\n",
      "2gram 'th' as PREFIX:\n",
      "   theft  eft\n",
      "   tho  o\n",
      "   throw  row\n",
      "   thwart  wart\n",
      "   thc  c\n",
      "   thallium  allium\n",
      "   theta  eta\n",
      "   thrill  rill\n",
      "   thane  ane\n",
      "   throb  rob\n",
      "  (49 total)\n",
      "\n",
      "2gram 'en' as SUFFIX:\n",
      "   rum  rumen\n",
      "   silk  silken\n",
      "   stiff  stiffen\n",
      "   deep  deepen\n",
      "   lind  linden\n",
      "   chick  chicken\n",
      "   hark  harken\n",
      "   fast  fasten\n",
      "   behold  beholden\n",
      "   f  fen\n",
      "  (144 total)\n",
      "\n",
      "2gram 'en' as PREFIX:\n",
      "   enchondroma  chondroma\n",
      "   encode  code\n",
      "   entangle  tangle\n",
      "   enclothe  clothe\n",
      "   enlisting  listing\n",
      "   ensis  sis\n",
      "   enkindle  kindle\n",
      "   envision  vision\n",
      "   entrance  trance\n",
      "   enchant  chant\n",
      "  (142 total)\n",
      "\n",
      "2gram 'nd' as SUFFIX:\n",
      "   se  send\n",
      "   opera  operand\n",
      "   42  42nd\n",
      "   po  pond\n",
      "   ha  hand\n",
      "   e  end\n",
      "   ba  band\n",
      "   te  tend\n",
      "   la  land\n",
      "   le  lend\n",
      "  (44 total)\n",
      "\n",
      "2gram 'ou' as SUFFIX:\n",
      "   carib  caribou\n",
      "   s  sou\n",
      "   bay  bayou\n",
      "   i  iou\n",
      "   tat  tatou\n",
      "   th  thou\n",
      "  (6 total)\n",
      "\n",
      "2gram 'ou' as PREFIX:\n",
      "   outing  ting\n",
      "   outwit  twit\n",
      "   outrigger  trigger\n",
      "   ouse  se\n",
      "   ousting  sting\n",
      "   out  t\n",
      "  (6 total)\n",
      "\n",
      "2gram 'st' as SUFFIX:\n",
      "   41  41st\n",
      "   ni  nist\n",
      "   inge  ingest\n",
      "   ne  nest\n",
      "   m  mst\n",
      "   mid  midst\n",
      "   maoi  maoist\n",
      "   mahdi  mahdist\n",
      "   li  list\n",
      "   gi  gist\n",
      "  (71 total)\n",
      "\n",
      "2gram 'st' as PREFIX:\n",
      "   stoat  oat\n",
      "   stamp  amp\n",
      "   strings  rings\n",
      "   strive  rive\n",
      "   stitching  itching\n",
      "   stripping  ripping\n",
      "   struck  ruck\n",
      "   strife  rife\n",
      "   std  d\n",
      "   stillness  illness\n",
      "  (110 total)\n",
      "\n",
      "2gram 'ro' as SUFFIX:\n",
      "   tore  torero\n",
      "   ti  tiro\n",
      "   c  cro\n",
      "   cast  castro\n",
      "   mi  miro\n",
      "   dine  dinero\n",
      "   bole  bolero\n",
      "   brace  bracero\n",
      "   p  pro\n",
      "   mo  moro\n",
      "  (28 total)\n",
      "\n",
      "2gram 'ro' as PREFIX:\n",
      "   romanic  manic\n",
      "   roth  th\n",
      "   robe  be\n",
      "   rostand  stand\n",
      "   rotc  tc\n",
      "   rope  pe\n",
      "   rowing  wing\n",
      "   rounder  under\n",
      "   route  ute\n",
      "   rodent  dent\n",
      "  (68 total)\n",
      "\n",
      "2gram 'ne' as SUFFIX:\n",
      "   dy  dyne\n",
      "   ni  nine\n",
      "   vali  valine\n",
      "   pi  pine\n",
      "   age  agene\n",
      "   er  erne\n",
      "   capo  capone\n",
      "   overdo  overdone\n",
      "   chi  chine\n",
      "   co  cone\n",
      "  (85 total)\n",
      "\n",
      "2gram 'ne' as PREFIX:\n",
      "   nepa  pa\n",
      "   nee  e\n",
      "   neuropathy  uropathy\n",
      "   nepali  pali\n",
      "   nett  tt\n",
      "   neurology  urology\n",
      "   nec  c\n",
      "   next  xt\n",
      "   nepal  pal\n",
      "   negate  gate\n",
      "  (32 total)\n",
      "\n",
      "2gram 'nt' as SUFFIX:\n",
      "   resurge  resurgent\n",
      "   sc  scnt\n",
      "   depone  deponent\n",
      "   pa  pant\n",
      "   late  latent\n",
      "   reside  resident\n",
      "   opera  operant\n",
      "   solve  solvent\n",
      "   phosphoresce  phosphorescent\n",
      "   reminisce  reminiscent\n",
      "  (118 total)\n",
      "\n",
      "2gram 'nt' as PREFIX:\n",
      "   nth  h\n",
      "  (1 total)\n",
      "\n",
      "2gram 'or' as SUFFIX:\n",
      "   adjust  adjustor\n",
      "   demean  demeanor\n",
      "   debt  debtor\n",
      "   hum  humor\n",
      "   transact  transactor\n",
      "   reflect  reflector\n",
      "   clang  clangor\n",
      "   assess  assessor\n",
      "   exposit  expositor\n",
      "   elect  elector\n",
      "  (175 total)\n",
      "\n",
      "2gram 'or' as PREFIX:\n",
      "   orbison  bison\n",
      "   orology  ology\n",
      "   oracular  acular\n",
      "   orate  ate\n",
      "   orpin  pin\n",
      "   orad  ad\n",
      "   orbiter  biter\n",
      "   orgy  gy\n",
      "   ore  e\n",
      "   orbit  bit\n",
      "  (25 total)\n",
      "\n",
      "2gram 'ac' as SUFFIX:\n",
      "   sum  sumac\n",
      "   tomb  tombac\n",
      "   p  pac\n",
      "   m  mac\n",
      "   l  lac\n",
      "   shell  shellac\n",
      "   n  nac\n",
      "   w  wac\n",
      "   v  vac\n",
      "   lin  linac\n",
      "  (11 total)\n",
      "\n",
      "2gram 'ac' as PREFIX:\n",
      "   accredited  credited\n",
      "   acerose  erose\n",
      "   accost  cost\n",
      "   accustom  custom\n",
      "   acanthus  anthus\n",
      "   accountable  countable\n",
      "   acarid  arid\n",
      "   acrid  rid\n",
      "   actress  tress\n",
      "   accumulative  cumulative\n",
      "  (57 total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram = []\n",
    "for i in most_common_bigrams:\n",
    "    bigram.append(i[0])\n",
    "    \n",
    "get_common_affix(bigram, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afbb259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3gram 'ide' as SUFFIX:\n",
      "   rings  ringside\n",
      "   r  ride\n",
      "   a  aide\n",
      "   res  reside\n",
      "   ways  wayside\n",
      "   burns  burnside\n",
      "   fluor  fluoride\n",
      "   ore  oreide\n",
      "   az  azide\n",
      "   gu  guide\n",
      "  (39 total)\n",
      "\n",
      "3gram 'ide' as PREFIX:\n",
      "   ides  s\n",
      "   idea  a\n",
      "   ideal  al\n",
      "   ideology  ology\n",
      "   ideate  ate\n",
      "   ideally  ally\n",
      "  (6 total)\n",
      "\n",
      "3gram 'sid' as SUFFIX:\n",
      "   ha  hasid\n",
      "   cap  capsid\n",
      "   re  resid\n",
      "  (3 total)\n",
      "\n",
      "3gram 'sid' as PREFIX:\n",
      "   sidle  le\n",
      "   sidney  ney\n",
      "   sids  s\n",
      "   sidalcea  alcea\n",
      "   sida  a\n",
      "   side  e\n",
      "   sidon  on\n",
      "  (7 total)\n",
      "\n",
      "3gram 'nea' as SUFFIX:\n",
      "   gui  guinea\n",
      "   genus_ara  genus_aranea\n",
      "   us  usnea\n",
      "   ti  tinea\n",
      "   ara  aranea\n",
      "  (5 total)\n",
      "\n",
      "3gram 'nea' as PREFIX:\n",
      "   neat  t\n",
      "   neap  p\n",
      "   neaten  ten\n",
      "   near  r\n",
      "   nearest  rest\n",
      "  (5 total)\n",
      "\n",
      "3gram 'ear' as SUFFIX:\n",
      "   g  gear\n",
      "   goody  goodyear\n",
      "   wheat  wheatear\n",
      "   lin  linear\n",
      "   s  sear\n",
      "   h  hear\n",
      "   w  wear\n",
      "   cl  clear\n",
      "   d  dear\n",
      "   end  endear\n",
      "  (20 total)\n",
      "\n",
      "3gram 'ear' as PREFIX:\n",
      "   earshot  shot\n",
      "   earpiece  piece\n",
      "   earphone  phone\n",
      "   earn  n\n",
      "   earlobe  lobe\n",
      "   earmuff  muff\n",
      "   earl  l\n",
      "   earring  ring\n",
      "   earreach  reach\n",
      "   earplug  plug\n",
      "  (27 total)\n",
      "\n",
      "3gram 'out' as SUFFIX:\n",
      "   cook  cookout\n",
      "   dug  dugout\n",
      "   strike  strikeout\n",
      "   rag  ragout\n",
      "   work  workout\n",
      "   check  checkout\n",
      "   l  lout\n",
      "   close  closeout\n",
      "   fold  foldout\n",
      "   g  gout\n",
      "  (56 total)\n",
      "\n",
      "3gram 'out' as PREFIX:\n",
      "   outright  right\n",
      "   outride  ride\n",
      "   outline  line\n",
      "   outcaste  caste\n",
      "   outflowing  flowing\n",
      "   outspan  span\n",
      "   outsmart  smart\n",
      "   outcall  call\n",
      "   outfall  fall\n",
      "   outbid  bid\n",
      "  (117 total)\n",
      "\n",
      "3gram 'ong' as SUFFIX:\n",
      "   pr  prong\n",
      "   parts  partsong\n",
      "   b  bong\n",
      "   hm  hmong\n",
      "   folks  folksong\n",
      "   bel  belong\n",
      "   camp  campong\n",
      "   th  thong\n",
      "   d  dong\n",
      "   mek  mekong\n",
      "  (19 total)\n",
      "\n",
      "3gram 'ace' as SUFFIX:\n",
      "   l  lace\n",
      "   r  race\n",
      "   m  mace\n",
      "   f  face\n",
      "   p  pace\n",
      "   enl  enlace\n",
      "   sol  solace\n",
      "   alt  altace\n",
      "   bull  bullace\n",
      "   pal  palace\n",
      "  (22 total)\n",
      "\n",
      "3gram 'ace' as PREFIX:\n",
      "   acerose  rose\n",
      "   acetonic  tonic\n",
      "   acedia  dia\n",
      "   acetic  tic\n",
      "   acerate  rate\n",
      "   acerb  rb\n",
      "   acetone  tone\n",
      "   acetabular  tabular\n",
      "   acer  r\n",
      "   acetate  tate\n",
      "  (12 total)\n",
      "\n",
      "3gram 'und' as SUFFIX:\n",
      "   redo  redound\n",
      "   expo  expound\n",
      "   ma  maund\n",
      "   abo  abound\n",
      "   so  sound\n",
      "   ro  round\n",
      "   rot  rotund\n",
      "   f  fund\n",
      "   mo  mound\n",
      "   ho  hound\n",
      "  (14 total)\n",
      "\n",
      "3gram 'und' as PREFIX:\n",
      "   undrape  rape\n",
      "   undo  o\n",
      "   undraped  raped\n",
      "   undset  set\n",
      "   undergo  ergo\n",
      "   undone  one\n",
      "   undermine  ermine\n",
      "   under  er\n",
      "  (8 total)\n",
      "\n",
      "3gram 'ter' as SUFFIX:\n",
      "   mol  molter\n",
      "   plat  platter\n",
      "   rebut  rebutter\n",
      "   ut  utter\n",
      "   lat  latter\n",
      "   put  putter\n",
      "   tit  titter\n",
      "   split  splitter\n",
      "   cot  cotter\n",
      "   bun  bunter\n",
      "  (163 total)\n",
      "\n",
      "3gram 'ter' as PREFIX:\n",
      "   tercentenary  centenary\n",
      "   termite  mite\n",
      "   teras  as\n",
      "   term  m\n",
      "   terrace  race\n",
      "   teres  es\n",
      "   tern  n\n",
      "   ternary  nary\n",
      "   tera  a\n",
      "   tertry  try\n",
      "  (17 total)\n",
      "\n",
      "3gram 'for' as SUFFIX:\n",
      "   there  therefor\n",
      "  (1 total)\n",
      "\n",
      "3gram 'for' as PREFIX:\n",
      "   fork  k\n",
      "   forgiving  giving\n",
      "   form  m\n",
      "   forswearing  swearing\n",
      "   forrad  rad\n",
      "   forester  ester\n",
      "   forgather  gather\n",
      "   foram  am\n",
      "   format  mat\n",
      "   foramen  amen\n",
      "  (51 total)\n",
      "\n",
      "3gram 'ast' as SUFFIX:\n",
      "   lamb  lambast\n",
      "   be  beast\n",
      "   bomb  bombast\n",
      "   e  east\n",
      "   le  least\n",
      "   v  vast\n",
      "   n  nast\n",
      "   p  past\n",
      "   cl  clast\n",
      "   f  fast\n",
      "  (21 total)\n",
      "\n",
      "3gram 'ast' as PREFIX:\n",
      "   astern  ern\n",
      "   astraddle  raddle\n",
      "   astaire  aire\n",
      "   astir  ir\n",
      "   astana  ana\n",
      "   astor  or\n",
      "   aster  er\n",
      "   astute  ute\n",
      "   astasia  asia\n",
      "   astray  ray\n",
      "  (11 total)\n",
      "\n",
      "3gram 'ent' as SUFFIX:\n",
      "   coexist  coexistent\n",
      "   lat  latent\n",
      "   resid  resident\n",
      "   respond  respondent\n",
      "   noc  nocent\n",
      "   ev  event\n",
      "   retard  retardent\n",
      "   p  pent\n",
      "   pot  potent\n",
      "   adsorb  adsorbent\n",
      "  (77 total)\n",
      "\n",
      "3gram 'ent' as PREFIX:\n",
      "   entrant  rant\n",
      "   entangle  angle\n",
      "   entailment  ailment\n",
      "   entrails  rails\n",
      "   entomb  omb\n",
      "   entire  ire\n",
      "   enter  er\n",
      "   enticing  icing\n",
      "   entwine  wine\n",
      "   entangled  angled\n",
      "  (18 total)\n",
      "\n",
      "3gram 'wit' as SUFFIX:\n",
      "   dim  dimwit\n",
      "   pe  pewit\n",
      "   out  outwit\n",
      "   t  twit\n",
      "   nit  nitwit\n",
      "   pee  peewit\n",
      "   god  godwit\n",
      "  (7 total)\n",
      "\n",
      "3gram 'wit' as PREFIX:\n",
      "   within  hin\n",
      "   withe  he\n",
      "   witting  ting\n",
      "   witness  ness\n",
      "   witless  less\n",
      "   wits  s\n",
      "  (6 total)\n",
      "\n",
      "3gram 'ith' as SUFFIX:\n",
      "   cr  crith\n",
      "   k  kith\n",
      "   p  pith\n",
      "   zen  zenith\n",
      "   sm  smith\n",
      "   fecal  fecalith\n",
      "   br  brith\n",
      "   faecal  faecalith\n",
      "   fa  faith\n",
      "   holler  hollerith\n",
      "  (11 total)\n",
      "\n",
      "3gram 'rou' as PREFIX:\n",
      "   rouge  ge\n",
      "   roux  x\n",
      "   routine  tine\n",
      "   route  te\n",
      "   round  nd\n",
      "   rouse  se\n",
      "   roumania  mania\n",
      "   roulade  lade\n",
      "   rous  s\n",
      "   rout  t\n",
      "  (12 total)\n",
      "\n",
      "3gram 'ard' as SUFFIX:\n",
      "   bay  bayard\n",
      "   must  mustard\n",
      "   boll  bollard\n",
      "   l  lard\n",
      "   y  yard\n",
      "   steely  steelyard\n",
      "   sw  sward\n",
      "   mall  mallard\n",
      "   buzz  buzzard\n",
      "   tab  tabard\n",
      "  (54 total)\n",
      "\n",
      "3gram 'ard' as PREFIX:\n",
      "   ardea  ea\n",
      "   ardor  or\n",
      "   ardeb  eb\n",
      "   ards  s\n",
      "   arda  a\n",
      "  (5 total)\n",
      "\n",
      "3gram 'mid' as SUFFIX:\n",
      "   aga  agamid\n",
      "   cos  cosmid\n",
      "   des  desmid\n",
      "   ti  timid\n",
      "  (4 total)\n",
      "\n",
      "3gram 'mid' as PREFIX:\n",
      "   midgrass  grass\n",
      "   midrib  rib\n",
      "   midway  way\n",
      "   midweekly  weekly\n",
      "   midweek  week\n",
      "   midland  land\n",
      "   midvein  vein\n",
      "   midmost  most\n",
      "   midiron  iron\n",
      "   midas  as\n",
      "  (38 total)\n",
      "\n",
      "3gram 'nde' as SUFFIX:\n",
      "   ma  mande\n",
      "   giro  gironde\n",
      "  (2 total)\n",
      "\n",
      "3gram 'der' as SUFFIX:\n",
      "   ci  cider\n",
      "   deco  decoder\n",
      "   german  germander\n",
      "   rejoin  rejoinder\n",
      "   lea  leader\n",
      "   tin  tinder\n",
      "   win  winder\n",
      "   min  minder\n",
      "   sen  sender\n",
      "   sun  sunder\n",
      "  (70 total)\n",
      "\n",
      "3gram 'der' as PREFIX:\n",
      "   derv  v\n",
      "   derain  ain\n",
      "   derby  by\n",
      "   derate  ate\n",
      "   derailment  ailment\n",
      "   derail  ail\n",
      "   derringer  ringer\n",
      "   derrick  rick\n",
      "   derma  ma\n",
      "  (9 total)\n",
      "\n",
      "3gram 'ore' as SUFFIX:\n",
      "   eyes  eyesore\n",
      "   y  yore\n",
      "   s  sore\n",
      "   lah  lahore\n",
      "   p  pore\n",
      "   ash  ashore\n",
      "   sc  score\n",
      "   tag  tagore\n",
      "   ad  adore\n",
      "   mo  moore\n",
      "  (27 total)\n",
      "\n",
      "3gram 'ore' as PREFIX:\n",
      "   oreo  o\n",
      "   oread  ad\n",
      "  (2 total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram = []\n",
    "for i in most_common_trigrams:\n",
    "    trigram.append(i[0])\n",
    "    \n",
    "# 2. Test a few common trigrams\n",
    "get_common_affix(trigram, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4be87aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4gram 'side' as SUFFIX:\n",
      "   up  upside\n",
      "   ring  ringside\n",
      "   re  reside\n",
      "   mountain  mountainside\n",
      "   way  wayside\n",
      "   over  overside\n",
      "   river  riverside\n",
      "   burn  burnside\n",
      "   dock  dockside\n",
      "   lake  lakeside\n",
      "  (41 total)\n",
      "\n",
      "4gram 'side' as PREFIX:\n",
      "   sidelight  light\n",
      "   sidereal  real\n",
      "   sidearm  arm\n",
      "   sideburn  burn\n",
      "   sidestroke  stroke\n",
      "   sidesaddle  saddle\n",
      "   sideslip  slip\n",
      "   sideline  line\n",
      "   sideward  ward\n",
      "   siderite  rite\n",
      "  (28 total)\n",
      "\n",
      "4gram 'with' as SUFFIX:\n",
      "   here  herewith\n",
      "   there  therewith\n",
      "   forth  forthwith\n",
      "  (3 total)\n",
      "\n",
      "4gram 'with' as PREFIX:\n",
      "   withdrawn  drawn\n",
      "   within  in\n",
      "   withal  al\n",
      "   withdraw  draw\n",
      "   withhold  hold\n",
      "   withholder  holder\n",
      "   withstand  stand\n",
      "   withe  e\n",
      "   withdrawing_room  drawing_room\n",
      "   withy  y\n",
      "  (14 total)\n",
      "\n",
      "4gram 'near' as SUFFIX:\n",
      "   li  linear\n",
      "  (1 total)\n",
      "\n",
      "4gram 'near' as PREFIX:\n",
      "   nearsighted  sighted\n",
      "   nearer  er\n",
      "   nearsightedness  sightedness\n",
      "   nearside  side\n",
      "   nearby  by\n",
      "   nearness  ness\n",
      "   nearest  est\n",
      "  (7 total)\n",
      "\n",
      "4gram 'unde' as PREFIX:\n",
      "   underage  rage\n",
      "   undeterminable  terminable\n",
      "   undefinable  finable\n",
      "   underevaluation  revaluation\n",
      "   undeserving  serving\n",
      "   undesigned  signed\n",
      "   undecomposed  composed\n",
      "   under  r\n",
      "  (8 total)\n",
      "\n",
      "4gram 'nder' as SUFFIX:\n",
      "   re  render\n",
      "   ti  tinder\n",
      "   wi  winder\n",
      "   mi  minder\n",
      "   se  sender\n",
      "   la  lander\n",
      "   fe  fender\n",
      "   pa  pander\n",
      "   ge  gender\n",
      "   cola  colander\n",
      "  (32 total)\n",
      "\n",
      "4gram 'amon' as SUFFIX:\n",
      "   d  damon\n",
      "   card  cardamon\n",
      "  (2 total)\n",
      "\n",
      "4gram 'mong' as SUFFIX:\n",
      "   h  hmong\n",
      "  (1 total)\n",
      "\n",
      "4gram 'mong' as PREFIX:\n",
      "   mongo  o\n",
      "   monger  er\n",
      "  (2 total)\n",
      "\n",
      "4gram 'alon' as SUFFIX:\n",
      "   h  halon\n",
      "   s  salon\n",
      "   t  talon\n",
      "  (3 total)\n",
      "\n",
      "4gram 'alon' as PREFIX:\n",
      "   alonso  so\n",
      "   alone  e\n",
      "   along  g\n",
      "  (3 total)\n",
      "\n",
      "4gram 'long' as SUFFIX:\n",
      "   live  livelong\n",
      "   day  daylong\n",
      "   ob  oblong\n",
      "   pro  prolong\n",
      "   age  agelong\n",
      "   be  belong\n",
      "   night  nightlong\n",
      "   week  weeklong\n",
      "   year  yearlong\n",
      "   head  headlong\n",
      "  (16 total)\n",
      "\n",
      "4gram 'long' as PREFIX:\n",
      "   longlegs  legs\n",
      "   longstanding  standing\n",
      "   longness  ness\n",
      "   longhand  hand\n",
      "   longfellow  fellow\n",
      "   longwise  wise\n",
      "   longbeard  beard\n",
      "   longan  an\n",
      "   longwool  wool\n",
      "   longshot  shot\n",
      "  (22 total)\n",
      "\n",
      "4gram 'betw' does NOT appear as a productive affix.\n",
      "\n",
      "4gram 'cent' as SUFFIX:\n",
      "   no  nocent\n",
      "   do  docent\n",
      "   de  decent\n",
      "   ac  accent\n",
      "   s  scent\n",
      "   as  ascent\n",
      "   re  recent\n",
      "   des  descent\n",
      "   pubes  pubescent\n",
      "   lu  lucent\n",
      "  (10 total)\n",
      "\n",
      "4gram 'cent' as PREFIX:\n",
      "   centrally  rally\n",
      "   centimo  imo\n",
      "   cental  al\n",
      "   centas  as\n",
      "   centavo  avo\n",
      "   centare  are\n",
      "   center  er\n",
      "   centrum  rum\n",
      "   centre  re\n",
      "   centrex  rex\n",
      "  (10 total)\n",
      "\n",
      "4gram 'hout' as SUFFIX:\n",
      "   ma  mahout\n",
      "   s  shout\n",
      "  (2 total)\n",
      "\n",
      "4gram 'twee' as PREFIX:\n",
      "   tweet  t\n",
      "   tweed  d\n",
      "   tweedle  dle\n",
      "   tweedy  dy\n",
      "  (4 total)\n",
      "\n",
      "4gram 'ween' as SUFFIX:\n",
      "   bet  between\n",
      "  (1 total)\n",
      "\n",
      "4gram 'ween' as PREFIX:\n",
      "   weenie  ie\n",
      "   weeny  y\n",
      "  (2 total)\n",
      "\n",
      "4gram 'thro' as PREFIX:\n",
      "   throw  w\n",
      "   throb  b\n",
      "   throne  ne\n",
      "   throng  ng\n",
      "   throe  e\n",
      "   throat  at\n",
      "   throes  es\n",
      "  (7 total)\n",
      "\n",
      "4gram 'hrou' does NOT appear as a productive affix.\n",
      "\n",
      "4gram 'roug' as PREFIX:\n",
      "   rouge  e\n",
      "   rouged  ed\n",
      "   rough  h\n",
      "   roughen  hen\n",
      "  (4 total)\n",
      "\n",
      "4gram 'ough' as SUFFIX:\n",
      "   th  though\n",
      "   furl  furlough\n",
      "   r  rough\n",
      "   thor  thorough\n",
      "   t  tough\n",
      "   s  sough\n",
      "   l  lough\n",
      "   sl  slough\n",
      "   d  dough\n",
      "   b  bough\n",
      "  (12 total)\n",
      "\n",
      "4gram 'ongs' as SUFFIX:\n",
      "   t  tongs\n",
      "  (1 total)\n",
      "\n",
      "4gram 'towa' as PREFIX:\n",
      "   towage  ge\n",
      "  (1 total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fourgram = []\n",
    "for i in most_common_fourgrams:\n",
    "    fourgram.append(i[0])\n",
    "\n",
    "# 3. Test a few common fourgrams\n",
    "get_common_affix(fourgram, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e6765",
   "metadata": {},
   "source": [
    "## Checking atomic morph with wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c0e6b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: suffix? True, prefix? True\n",
      "  examples suffix  ([('pa', 'paid'), ('b', 'bid'), ('ac', 'acid'), ('s', 'sid'), ('rash', 'rashid'), ('v', 'vid'), ('maj', 'majid'), ('sol', 'solid'), ('d', 'did'), ('wal', 'walid'), ('r', 'rid'), ('sa', 'said'), ('usa', 'usaid'), ('l', 'lid'), ('ar', 'arid'), ('ham', 'hamid'), ('had', 'hadid'), ('liv', 'livid'), ('metro', 'metroid'), ('qua', 'quaid'), ('ov', 'ovid'), ('k', 'kid'), ('re', 'reid'), ('ra', 'raid'), ('lip', 'lipid'), ('a', 'aid'), ('rab', 'rabid'), ('shah', 'shahid'), ('w', 'wid'), ('p', 'pid'), ('ma', 'maid'), ('flu', 'fluid'), ('pla', 'plaid'), ('m', 'mid'), ('sl', 'slid'), ('cov', 'covid'), ('la', 'laid'), ('av', 'avid'), ('e', 'eid'), ('qu', 'quid'), ('val', 'valid'), ('devo', 'devoid'), ('luc', 'lucid'), ('sk', 'skid'), ('medica', 'medicaid'), ('tim', 'timid'), ('bra', 'braid'), ('h', 'hid'), ('viv', 'vivid'), ('gr', 'grid'), ('rf', 'rfid'), ('dav', 'david'), ('hum', 'humid'), ('en', 'enid'), ('rap', 'rapid'), ('sta', 'staid'), ('far', 'farid'), ('cup', 'cupid'), ('vo', 'void'), ('dru', 'druid'), ('rig', 'rigid'), ('am', 'amid'), ('ib', 'ibid'), ('c', 'cid'), ('leon', 'leonid')],) \n",
      " 65 times\n",
      "  examples prefix  [('idly', 'ly'), ('ides', 'es'), ('idf', 'f'), ('idle', 'le'), ('idea', 'ea')] \n",
      " 19 times\n",
      "\n",
      "de: suffix? True, prefix? True\n",
      "  examples suffix  ([('hy', 'hyde'), ('ce', 'cede'), ('abi', 'abide'), ('ri', 'ride'), ('ry', 'ryde'), ('nu', 'nude'), ('dio', 'diode'), ('ba', 'bade'), ('tra', 'trade'), ('gar', 'garde'), ('gran', 'grande'), ('eva', 'evade'), ('abo', 'abode'), ('gra', 'grade'), ('ai', 'aide'), ('hor', 'horde'), ('sue', 'suede'), ('sha', 'shade'), ('hi', 'hide'), ('electro', 'electrode'), ('be', 'bede'), ('fa', 'fade'), ('lau', 'laude'), ('mo', 'mode'), ('k', 'kde'), ('sla', 'slade'), ('pri', 'pride'), ('no', 'node'), ('mon', 'monde'), ('lo', 'lode'), ('sta', 'stade'), ('ru', 'rude'), ('du', 'dude'), ('ju', 'jude'), ('vi', 'vide'), ('lor', 'lorde'), ('ma', 'made'), ('para', 'parade'), ('bri', 'bride'), ('rho', 'rhode'), ('con', 'conde'), ('cru', 'crude'), ('ja', 'jade'), ('gui', 'guide'), ('bo', 'bode'), ('wil', 'wilde'), ('da', 'dade'), ('serena', 'serenade'), ('de', 'dede'), ('wa', 'wade'), ('i', 'ide'), ('co', 'code'), ('ol', 'olde'), ('marina', 'marinade'), ('bi', 'bide'), ('ano', 'anode'), ('ver', 'verde'), ('lin', 'linde'), ('a', 'ade'), ('chara', 'charade'), ('si', 'side'), ('mea', 'meade'), ('asi', 'aside'), ('ca', 'cade'), ('ti', 'tide'), ('wi', 'wide'), ('rea', 'reade'), ('gla', 'glade'), ('mau', 'maude'), ('goo', 'goode'), ('sa', 'sade'), ('allen', 'allende'), ('deco', 'decode'), ('swe', 'swede'), ('bla', 'blade'), ('ro', 'rode'), ('spa', 'spade'), ('fi', 'fide'), ('o', 'ode')],) \n",
      " 79 times\n",
      "  examples prefix  [('deg', 'g'), ('deus', 'us'), ('deck', 'ck'), ('dead', 'ad'), ('deal', 'al')] \n",
      " 292 times\n",
      "\n",
      "ar: suffix? True, prefix? True\n",
      "  examples suffix  ([('son', 'sonar'), ('th', 'thar'), ('reb', 'rebar'), ('ge', 'gear'), ('d', 'dar'), ('fe', 'fear'), ('s', 'sar'), ('sam', 'samar'), ('she', 'shear'), ('line', 'linear'), ('bo', 'boar'), ('hag', 'hagar'), ('farr', 'farrar'), ('sol', 'solar'), ('tart', 'tartar'), ('k', 'kar'), ('mill', 'millar'), ('band', 'bandar'), ('l', 'lar'), ('um', 'umar'), ('sme', 'smear'), ('r', 'rar'), ('se', 'sear'), ('sag', 'sagar'), ('pix', 'pixar'), ('alt', 'altar'), ('doll', 'dollar'), ('coll', 'collar'), ('lid', 'lidar'), ('din', 'dinar'), ('ces', 'cesar'), ('sp', 'spar'), ('re', 'rear'), ('osc', 'oscar'), ('g', 'gar'), ('m', 'mar'), ('li', 'liar'), ('he', 'hear'), ('dew', 'dewar'), ('pol', 'polar'), ('c', 'car'), ('uncle', 'unclear'), ('shank', 'shankar'), ('f', 'far'), ('nag', 'nagar'), ('so', 'soar'), ('we', 'wear'), ('cle', 'clear'), ('ein', 'einar'), ('ag', 'agar'), ('bash', 'bashar'), ('plant', 'plantar'), ('mort', 'mortar'), ('y', 'yar'), ('de', 'dear'), ('dem', 'demar'), ('le', 'lear'), ('t', 'tar'), ('n', 'nar'), ('iv', 'ivar'), ('spe', 'spear'), ('w', 'war'), ('ro', 'roar'), ('ne', 'near'), ('af', 'afar'), ('cell', 'cellar'), ('lam', 'lamar'), ('aj', 'ajar'), ('cz', 'czar'), ('j', 'jar'), ('plan', 'planar'), ('am', 'amar'), ('pil', 'pilar'), ('vic', 'vicar'), ('bri', 'briar'), ('st', 'star'), ('om', 'omar'), ('p', 'par'), ('gunn', 'gunnar'), ('ans', 'ansar'), ('cig', 'cigar'), ('bigg', 'biggar'), ('te', 'tear'), ('consul', 'consular'), ('mol', 'molar'), ('ch', 'char'), ('rad', 'radar'), ('tam', 'tamar'), ('a', 'aar'), ('dak', 'dakar'), ('baz', 'bazar'), ('tat', 'tatar'), ('ye', 'year'), ('be', 'bear'), ('pill', 'pillar'), ('ts', 'tsar'), ('hang', 'hangar'), ('bab', 'babar'), ('pe', 'pear'), ('e', 'ear'), ('fri', 'friar'), ('swe', 'swear'), ('h', 'har'), ('v', 'var'), ('sc', 'scar'), ('o', 'oar'), ('sark', 'sarkar'), ('b', 'bar'), ('lun', 'lunar')],) \n",
      " 109 times\n",
      "  examples prefix  [('arbor', 'bor'), ('arrange', 'range'), ('arcade', 'cade'), ('aron', 'on'), ('arc', 'c')] \n",
      " 106 times\n",
      "\n",
      "er: suffix? True, prefix? True\n",
      "  examples suffix  ([('lean', 'leaner'), ('down', 'downer'), ('harsh', 'harsher'), ('bull', 'buller'), ('om', 'omer'), ('platt', 'platter'), ('supp', 'supper'), ('tam', 'tamer'), ('sprint', 'sprinter'), ('less', 'lesser'), ('zealand', 'zealander'), ('show', 'shower'), ('math', 'mather'), ('hill', 'hiller'), ('shiv', 'shiver'), ('coop', 'cooper'), ('rain', 'rainer'), ('common', 'commoner'), ('molest', 'molester'), ('fish', 'fisher'), ('jet', 'jeter'), ('click', 'clicker'), ('cater', 'caterer'), ('convert', 'converter'), ('respond', 'responder'), ('link', 'linker'), ('putt', 'putter'), ('foy', 'foyer'), ('found', 'founder'), ('work', 'worker'), ('sav', 'saver'), ('jewell', 'jeweller'), ('cid', 'cider'), ('pap', 'paper'), ('hat', 'hater'), ('bust', 'buster'), ('southern', 'southerner'), ('poop', 'pooper'), ('crush', 'crusher'), ('fest', 'fester'), ('palm', 'palmer'), ('eth', 'ether'), ('tas', 'taser'), ('barb', 'barber'), ('cod', 'coder'), ('hamburg', 'hamburger'), ('dumb', 'dumber'), ('creep', 'creeper'), ('webb', 'webber'), ('piet', 'pieter'), ('island', 'islander'), ('infield', 'infielder'), ('trawl', 'trawler'), ('bit', 'biter'), ('deep', 'deeper'), ('stroll', 'stroller'), ('coast', 'coaster'), ('geez', 'geezer'), ('s', 'ser'), ('help', 'helper'), ('clos', 'closer'), ('finish', 'finisher'), ('seat', 'seater'), ('sang', 'sanger'), ('weld', 'welder'), ('dim', 'dimer'), ('drink', 'drinker'), ('deck', 'decker'), ('sniff', 'sniffer'), ('min', 'miner'), ('cant', 'canter'), ('ste', 'steer'), ('execution', 'executioner'), ('oth', 'other'), ('join', 'joiner'), ('ch', 'cher'), ('pet', 'peter'), ('view', 'viewer'), ('clear', 'clearer'), ('herd', 'herder'), ('golf', 'golfer'), ('talk', 'talker'), ('gam', 'gamer'), ('papi', 'papier'), ('lead', 'leader'), ('amb', 'amber'), ('k', 'ker'), ('mang', 'manger'), ('gow', 'gower'), ('brew', 'brewer'), ('hack', 'hacker'), ('forrest', 'forrester'), ('hov', 'hover'), ('adjust', 'adjuster'), ('soft', 'softer'), ('moth', 'mother'), ('boost', 'booster'), ('butt', 'butter'), ('inn', 'inner'), ('numb', 'number'), ('bright', 'brighter'), ('open', 'opener'), ('trott', 'trotter'), ('install', 'installer'), ('fuck', 'fucker'), ('mean', 'meaner'), ('dream', 'dreamer'), ('export', 'exporter'), ('soon', 'sooner'), ('with', 'wither'), ('bark', 'barker'), ('mos', 'moser'), ('cricket', 'cricketer'), ('fly', 'flyer'), ('travel', 'traveler'), ('rein', 'reiner'), ('wank', 'wanker'), ('mah', 'maher'), ('javi', 'javier'), ('must', 'muster'), ('tig', 'tiger'), ('twist', 'twister'), ('tru', 'truer'), ('point', 'pointer'), ('punt', 'punter'), ('mull', 'muller'), ('narrow', 'narrower'), ('attack', 'attacker'), ('tim', 'timer'), ('xavi', 'xavier'), ('pick', 'picker'), ('wind', 'winder'), ('reef', 'reefer'), ('hunt', 'hunter'), ('outfield', 'outfielder'), ('near', 'nearer'), ('grind', 'grinder'), ('pay', 'payer'), ('nic', 'nicer'), ('cock', 'cocker'), ('ent', 'enter'), ('teach', 'teacher'), ('inform', 'informer'), ('lug', 'luger'), ('g', 'ger'), ('refresh', 'refresher'), ('foot', 'footer'), ('row', 'rower'), ('rac', 'racer'), ('sob', 'sober'), ('sink', 'sinker'), ('d', 'der'), ('sweet', 'sweeter'), ('proud', 'prouder'), ('send', 'sender'), ('still', 'stiller'), ('fold', 'folder'), ('holi', 'holier'), ('field', 'fielder'), ('bigg', 'bigger'), ('rid', 'rider'), ('watch', 'watcher'), ('borrow', 'borrower'), ('t', 'ter'), ('tink', 'tinker'), ('keel', 'keeler'), ('small', 'smaller'), ('gunn', 'gunner'), ('land', 'lander'), ('slid', 'slider'), ('add', 'adder'), ('flow', 'flower'), ('pull', 'puller'), ('ord', 'order'), ('fix', 'fixer'), ('wall', 'waller'), ('crawl', 'crawler'), ('troop', 'trooper'), ('bloom', 'bloomer'), ('gre', 'greer'), ('kerb', 'kerber'), ('scoot', 'scooter'), ('football', 'footballer'), ('labour', 'labourer'), ('de', 'deer'), ('forest', 'forester'), ('rout', 'router'), ('grand', 'grander'), ('lust', 'luster'), ('adapt', 'adapter'), ('pitch', 'pitcher'), ('def', 'defer'), ('lend', 'lender'), ('sing', 'singer'), ('bold', 'bolder'), ('holland', 'hollander'), ('fend', 'fender'), ('cool', 'cooler'), ('los', 'loser'), ('cook', 'cooker'), ('cast', 'caster'), ('rent', 'renter'), ('fry', 'fryer'), ('harvest', 'harvester'), ('bonn', 'bonner'), ('dock', 'docker'), ('raid', 'raider'), ('household', 'householder'), ('reform', 'reformer'), ('pac', 'pacer'), ('highlight', 'highlighter'), ('flick', 'flicker'), ('shear', 'shearer'), ('pretend', 'pretender'), ('walt', 'walter'), ('snip', 'sniper'), ('shallow', 'shallower'), ('ris', 'riser'), ('sting', 'stinger'), ('wild', 'wilder'), ('engine', 'engineer'), ('int', 'inter'), ('eat', 'eater'), ('prison', 'prisoner'), ('bowl', 'bowler'), ('div', 'diver'), ('drift', 'drifter'), ('feed', 'feeder'), ('bomb', 'bomber'), ('raft', 'rafter'), ('block', 'blocker'), ('lau', 'lauer'), ('chart', 'charter'), ('shin', 'shiner'), ('cat', 'cater'), ('j', 'jer'), ('adl', 'adler'), ('ald', 'alder'), ('witch', 'witcher'), ('wien', 'wiener'), ('bad', 'bader'), ('farm', 'farmer'), ('w', 'wer'), ('warn', 'warner'), ('boil', 'boiler'), ('box', 'boxer'), ('employ', 'employer'), ('falcon', 'falconer'), ('sign', 'signer'), ('keep', 'keeper'), ('remind', 'reminder'), ('contain', 'container'), ('extend', 'extender'), ('ranch', 'rancher'), ('review', 'reviewer'), ('clean', 'cleaner'), ('mong', 'monger'), ('sweat', 'sweater'), ('conceal', 'concealer'), ('my', 'myer'), ('float', 'floater'), ('hook', 'hooker'), ('dov', 'dover'), ('sick', 'sicker'), ('a', 'aer'), ('round', 'rounder'), ('highland', 'highlander'), ('com', 'comer'), ('green', 'greener'), ('support', 'supporter'), ('sau', 'sauer'), ('destroy', 'destroyer'), ('tenn', 'tenner'), ('young', 'younger'), ('tight', 'tighter'), ('whisk', 'whisker'), ('hub', 'huber'), ('cork', 'corker'), ('light', 'lighter'), ('great', 'greater'), ('be', 'beer'), ('mat', 'mater'), ('thrust', 'thruster'), ('ba', 'baer'), ('new', 'newer'), ('od', 'oder'), ('own', 'owner'), ('poach', 'poacher'), ('writ', 'writer'), ('condition', 'conditioner'), ('crock', 'crocker'), ('bleach', 'bleacher'), ('thick', 'thicker'), ('dorm', 'dormer'), ('form', 'former'), ('interpret', 'interpreter'), ('mist', 'mister'), ('didi', 'didier'), ('ham', 'hamer'), ('y', 'yer'), ('arch', 'archer'), ('h', 'her'), ('garb', 'garber'), ('invert', 'inverter'), ('heal', 'healer'), ('pleas', 'pleaser'), ('est', 'ester'), ('spray', 'sprayer'), ('jail', 'jailer'), ('tuck', 'tucker'), ('commission', 'commissioner'), ('bay', 'bayer'), ('tank', 'tanker'), ('rar', 'rarer'), ('lin', 'liner'), ('hark', 'harker'), ('high', 'higher'), ('meek', 'meeker'), ('labor', 'laborer'), ('ott', 'otter'), ('puff', 'puffer'), ('western', 'westerner'), ('bau', 'bauer'), ('sh', 'sher'), ('retail', 'retailer'), ('grad', 'grader'), ('rudd', 'rudder'), ('ball', 'baller'), ('mill', 'miller'), ('pe', 'peer'), ('shock', 'shocker'), ('ev', 'ever'), ('ung', 'unger'), ('find', 'finder'), ('track', 'tracker'), ('keen', 'keener'), ('lag', 'lager'), ('blatt', 'blatter'), ('desert', 'deserter'), ('pow', 'power'), ('ub', 'uber'), ('strain', 'strainer'), ('fill', 'filler'), ('straight', 'straighter'), ('post', 'poster'), ('usurp', 'usurper'), ('pension', 'pensioner'), ('hard', 'harder'), ('broad', 'broader'), ('roost', 'rooster'), ('vip', 'viper'), ('hab', 'haber'), ('skew', 'skewer'), ('build', 'builder'), ('sneak', 'sneaker'), ('ton', 'toner'), ('laud', 'lauder'), ('beat', 'beater'), ('kickstart', 'kickstarter'), ('vouch', 'voucher'), ('care', 'career'), ('ay', 'ayer'), ('bear', 'bearer'), ('redeem', 'redeemer'), ('cent', 'center'), ('fresh', 'fresher'), ('pag', 'pager'), ('walk', 'walker'), ('tough', 'tougher'), ('tweet', 'tweeter'), ('draw', 'drawer'), ('hoy', 'hoyer'), ('report', 'reporter'), ('night', 'nighter'), ('chest', 'chester'), ('wid', 'wider'), ('blast', 'blaster'), ('stretch', 'stretcher'), ('kiss', 'kisser'), ('hijack', 'hijacker'), ('merc', 'mercer'), ('conf', 'confer'), ('rik', 'riker'), ('loud', 'louder'), ('break', 'breaker'), ('ladd', 'ladder'), ('finch', 'fincher'), ('port', 'porter'), ('spe', 'speer'), ('climb', 'climber'), ('merci', 'mercier'), ('wag', 'wager'), ('blitz', 'blitzer'), ('go', 'goer'), ('beck', 'becker'), ('berg', 'berger'), ('quiet', 'quieter'), ('surf', 'surfer'), ('defend', 'defender'), ('am', 'amer'), ('ov', 'over'), ('weird', 'weirder'), ('mov', 'mover'), ('publish', 'publisher'), ('cream', 'creamer'), ('fasten', 'fastener'), ('listen', 'listener'), ('string', 'stringer'), ('breed', 'breeder'), ('beak', 'beaker'), ('hold', 'holder'), ('interview', 'interviewer'), ('heartbreak', 'heartbreaker'), ('dy', 'dyer'), ('warm', 'warmer'), ('low', 'lower'), ('start', 'starter'), ('trapp', 'trapper'), ('slow', 'slower'), ('me', 'meer'), ('behold', 'beholder'), ('speak', 'speaker'), ('mark', 'marker'), ('hang', 'hanger'), ('sew', 'sewer'), ('crowd', 'crowder'), ('reap', 'reaper'), ('strang', 'stranger'), ('lift', 'lifter'), ('sharp', 'sharper'), ('strict', 'stricter'), ('hung', 'hunger'), ('extinguish', 'extinguisher'), ('same', 'sameer'), ('steep', 'steeper'), ('fenn', 'fenner'), ('market', 'marketer'), ('murder', 'murderer'), ('diff', 'differ'), ('mei', 'meier'), ('play', 'player'), ('firm', 'firmer'), ('pound', 'pounder'), ('elm', 'elmer'), ('spoon', 'spooner'), ('smelt', 'smelter'), ('rock', 'rocker'), ('paint', 'painter'), ('tow', 'tower'), ('load', 'loader'), ('stiff', 'stiffer'), ('tun', 'tuner'), ('dup', 'duper'), ('nev', 'never'), ('rough', 'rougher'), ('matt', 'matter'), ('calm', 'calmer'), ('truck', 'trucker'), ('mis', 'miser'), ('quart', 'quarter'), ('kick', 'kicker'), ('cram', 'cramer'), ('mix', 'mixer'), ('halt', 'halter'), ('command', 'commander'), ('repeat', 'repeater'), ('bo', 'boer'), ('york', 'yorker'), ('contend', 'contender'), ('us', 'user'), ('stalk', 'stalker'), ('sab', 'saber'), ('scrap', 'scraper'), ('din', 'diner'), ('thrill', 'thriller'), ('test', 'tester'), ('jewel', 'jeweler'), ('east', 'easter'), ('b', 'ber'), ('pars', 'parser'), ('prim', 'primer'), ('fib', 'fiber'), ('ash', 'asher'), ('se', 'seer'), ('bend', 'bender'), ('count', 'counter'), ('jest', 'jester'), ('heath', 'heather'), ('train', 'trainer'), ('smooth', 'smoother'), ('wat', 'water'), ('kidd', 'kidder'), ('batt', 'batter'), ('spoil', 'spoiler'), ('flank', 'flanker'), ('digg', 'digger'), ('pest', 'pester'), ('wing', 'winger'), ('cow', 'cower'), ('aft', 'after'), ('inf', 'infer'), ('messi', 'messier'), ('lay', 'layer'), ('fab', 'faber'), ('lang', 'langer'), ('butch', 'butcher'), ('wait', 'waiter'), ('tend', 'tender'), ('widow', 'widower'), ('saf', 'safer'), ('haus', 'hauser'), ('design', 'designer'), ('orbit', 'orbiter'), ('aug', 'auger'), ('berlin', 'berliner'), ('tak', 'taker'), ('v', 'ver'), ('loos', 'looser'), ('ac', 'acer'), ('rush', 'rusher'), ('slack', 'slacker'), ('bon', 'boner'), ('tick', 'ticker'), ('pray', 'prayer'), ('horn', 'horner'), ('fre', 'freer'), ('fin', 'finer'), ('backpack', 'backpacker'), ('boom', 'boomer'), ('solid', 'solider'), ('kohl', 'kohler'), ('black', 'blacker'), ('mail', 'mailer'), ('hamm', 'hammer'), ('rapp', 'rapper'), ('gross', 'grosser'), ('cap', 'caper'), ('litt', 'litter'), ('alt', 'alter'), ('rang', 'ranger'), ('suck', 'sucker'), ('wear', 'wearer'), ('jenn', 'jenner'), ('full', 'fuller'), ('mak', 'maker'), ('sweep', 'sweeper'), ('pi', 'pier'), ('short', 'shorter'), ('splint', 'splinter'), ('las', 'laser'), ('comfort', 'comforter'), ('chas', 'chaser'), ('school', 'schooler'), ('trail', 'trailer'), ('sleep', 'sleeper'), ('hall', 'haller'), ('well', 'weller'), ('print', 'printer'), ('rug', 'ruger'), ('freight', 'freighter'), ('fad', 'fader'), ('dress', 'dresser'), ('jump', 'jumper'), ('tap', 'taper'), ('neu', 'neuer'), ('wander', 'wanderer'), ('bows', 'bowser'), ('fell', 'feller'), ('marin', 'mariner'), ('sinn', 'sinner'), ('she', 'sheer'), ('turn', 'turner'), ('and', 'ander'), ('rich', 'richer'), ('staff', 'staffer'), ('hatch', 'hatcher'), ('bey', 'beyer'), ('poor', 'poorer'), ('retain', 'retainer'), ('cart', 'carter'), ('met', 'meter'), ('ell', 'eller'), ('lon', 'loner'), ('beam', 'beamer'), ('seal', 'sealer'), ('sold', 'solder'), ('think', 'thinker'), ('perform', 'performer'), ('suffer', 'sufferer'), ('teas', 'teaser'), ('offend', 'offender'), ('chang', 'changer'), ('camp', 'camper'), ('scream', 'screamer'), ('strong', 'stronger'), ('pass', 'passer'), ('thay', 'thayer'), ('fowl', 'fowler'), ('krug', 'kruger'), ('both', 'bother'), ('stick', 'sticker'), ('wheel', 'wheeler'), ('ski', 'skier'), ('le', 'leer'), ('quick', 'quicker'), ('cheat', 'cheater'), ('roll', 'roller'), ('wis', 'wiser'), ('pos', 'poser'), ('transport', 'transporter'), ('sweeten', 'sweetener'), ('prop', 'proper'), ('earn', 'earner'), ('follow', 'follower'), ('back', 'backer'), ('cold', 'colder'), ('whit', 'whiter'), ('slash', 'slasher'), ('th', 'ther'), ('slay', 'slayer'), ('spring', 'springer'), ('press', 'presser'), ('pip', 'piper'), ('bak', 'baker'), ('entertain', 'entertainer'), ('spread', 'spreader'), ('pal', 'paler'), ('trad', 'trader'), ('absorb', 'absorber'), ('adopt', 'adopter'), ('kissing', 'kissinger'), ('spend', 'spender'), ('may', 'mayer'), ('que', 'queer'), ('photograph', 'photographer'), ('diet', 'dieter'), ('swing', 'swinger'), ('sell', 'seller'), ('nad', 'nader'), ('list', 'lister'), ('dry', 'dryer'), ('blow', 'blower'), ('task', 'tasker'), ('kind', 'kinder'), ('lav', 'laver'), ('tri', 'trier'), ('terri', 'terrier'), ('out', 'outer'), ('gaff', 'gaffer'), ('broth', 'brother'), ('shad', 'shader'), ('car', 'carer'), ('throw', 'thrower'), ('sup', 'super'), ('dri', 'drier'), ('trumpet', 'trumpeter'), ('lock', 'locker'), ('crack', 'cracker'), ('det', 'deter'), ('lib', 'liber'), ('import', 'importer'), ('beech', 'beecher'), ('transform', 'transformer'), ('lit', 'liter'), ('book', 'booker'), ('fast', 'faster'), ('web', 'weber'), ('few', 'fewer'), ('blend', 'blender'), ('thrash', 'thrasher'), ('grub', 'gruber'), ('wick', 'wicker'), ('read', 'reader'), ('launch', 'launcher'), ('broadcast', 'broadcaster'), ('present', 'presenter'), ('bank', 'banker'), ('und', 'under'), ('leak', 'leaker'), ('liv', 'liver'), ('off', 'offer'), ('corn', 'corner'), ('discover', 'discoverer'), ('fam', 'famer'), ('comment', 'commenter'), ('leg', 'leger'), ('ang', 'anger'), ('burg', 'burger'), ('gather', 'gatherer'), ('damp', 'damper'), ('grow', 'grower'), ('hawk', 'hawker'), ('seek', 'seeker'), ('frankfurt', 'frankfurter'), ('wash', 'washer'), ('bart', 'barter'), ('dwell', 'dweller'), ('petition', 'petitioner'), ('wand', 'wander'), ('smart', 'smarter'), ('tat', 'tater'), ('pack', 'packer'), ('ref', 'refer'), ('mow', 'mower'), ('n', 'ner'), ('conn', 'conner'), ('heat', 'heater'), ('midfield', 'midfielder'), ('mild', 'milder'), ('hell', 'heller'), ('custom', 'customer'), ('ti', 'tier'), ('cleans', 'cleanser'), ('should', 'shoulder'), ('end', 'ender'), ('lest', 'lester'), ('ling', 'linger'), ('brows', 'browser'), ('mai', 'maier'), ('whisper', 'whisperer'), ('call', 'caller'), ('kemp', 'kemper'), ('burn', 'burner'), ('wreck', 'wrecker'), ('wip', 'wiper'), ('recruit', 'recruiter'), ('p', 'per'), ('shift', 'shifter'), ('garden', 'gardener'), ('mutt', 'mutter'), ('record', 'recorder'), ('weak', 'weaker'), ('buy', 'buyer'), ('tell', 'teller'), ('sand', 'sander'), ('head', 'header'), ('ring', 'ringer'), ('charm', 'charmer'), ('protest', 'protester'), ('bunk', 'bunker'), ('dispatch', 'dispatcher'), ('bump', 'bumper'), ('fight', 'fighter'), ('deal', 'dealer'), ('f', 'fer'), ('mess', 'messer'), ('resell', 'reseller'), ('research', 'researcher'), ('mann', 'manner'), ('tub', 'tuber'), ('steam', 'steamer'), ('firefight', 'firefighter'), ('tall', 'taller'), ('kill', 'killer'), ('m', 'mer'), ('breath', 'breather'), ('hoard', 'hoarder'), ('abn', 'abner'), ('dens', 'denser'), ('till', 'tiller'), ('park', 'parker'), ('cov', 'cover'), ('buzz', 'buzzer'), ('lat', 'later'), ('shoot', 'shooter'), ('foreign', 'foreigner'), ('ast', 'aster'), ('nutt', 'nutter'), ('push', 'pusher'), ('hand', 'hander'), ('board', 'boarder'), ('dark', 'darker'), ('plant', 'planter'), ('fair', 'fairer'), ('learn', 'learner'), ('boy', 'boyer'), ('dust', 'duster'), ('cheap', 'cheaper'), ('dang', 'danger'), ('old', 'older'), ('buff', 'buffer'), ('wav', 'waver'), ('iv', 'iver'), ('lev', 'lever'), ('stream', 'streamer'), ('salt', 'salter'), ('bang', 'banger'), ('hind', 'hinder'), ('long', 'longer'), ('temp', 'temper'), ('thatch', 'thatcher'), ('hom', 'homer'), ('ve', 'veer'), ('bow', 'bower'), ('hoop', 'hooper'), ('kitchen', 'kitchener'), ('plumb', 'plumber'), ('stein', 'steiner'), ('rath', 'rather'), ('platform', 'platformer'), ('kell', 'keller'), ('toast', 'toaster'), ('cut', 'cuter'), ('campaign', 'campaigner'), ('thi', 'thier'), ('brain', 'brainer'), ('che', 'cheer'), ('preach', 'preacher'), ('eras', 'eraser'), ('oust', 'ouster'), ('christoph', 'christopher'), ('develop', 'developer'), ('punish', 'punisher'), ('harp', 'harper'), ('ruck', 'rucker'), ('pint', 'pinter'), ('winn', 'winner'), ('pond', 'ponder'), ('do', 'doer'), ('rog', 'roger'), ('check', 'checker'), ('bind', 'binder'), ('catch', 'catcher'), ('mast', 'master'), ('robb', 'robber')],) \n",
      " 825 times\n",
      "  examples prefix  [('ere', 'e'), ('err', 'r'), ('ernest', 'nest'), ('eras', 'as'), ('erm', 'm')] \n",
      " 29 times\n",
      "\n",
      "on: suffix? True, prefix? True\n",
      "  examples suffix  ([('gibb', 'gibbon'), ('m', 'mon'), ('js', 'json'), ('add', 'addon'), ('carb', 'carbon'), ('p', 'pon'), ('tr', 'tron'), ('po', 'poon'), ('ar', 'aron'), ('johns', 'johnson'), ('land', 'landon'), ('sanders', 'sanderson'), ('al', 'alon'), ('men', 'menon'), ('tend', 'tendon'), ('bent', 'benton'), ('piers', 'pierson'), ('steps', 'stepson'), ('ors', 'orson'), ('rec', 'recon'), ('walt', 'walton'), ('dutt', 'dutton'), ('apr', 'apron'), ('cond', 'condon'), ('k', 'kon'), ('xe', 'xeon'), ('ir', 'iron'), ('coup', 'coupon'), ('illuminati', 'illumination'), ('mo', 'moon'), ('hens', 'henson'), ('ode', 'odeon'), ('ther', 'theron'), ('clint', 'clinton'), ('calder', 'calderon'), ('mac', 'macon'), ('mari', 'marion'), ('ars', 'arson'), ('felt', 'felton'), ('eg', 'egon'), ('si', 'sion'), ('ellis', 'ellison'), ('comm', 'common'), ('eds', 'edson'), ('av', 'avon'), ('grands', 'grandson'), ('e', 'eon'), ('col', 'colon'), ('berger', 'bergeron'), ('aeg', 'aegon'), ('gods', 'godson'), ('cray', 'crayon'), ('tet', 'teton'), ('rip', 'ripon'), ('trent', 'trenton'), ('taunt', 'taunton'), ('n', 'non'), ('hilt', 'hilton'), ('ye', 'yeon'), ('up', 'upon'), ('s', 'son'), ('man', 'manon'), ('bac', 'bacon'), ('ic', 'icon'), ('dam', 'damon'), ('bos', 'boson'), ('drago', 'dragoon'), ('fel', 'felon'), ('oni', 'onion'), ('jens', 'jenson'), ('yang', 'yangon'), ('overt', 'overton'), ('mais', 'maison'), ('brett', 'bretton'), ('newt', 'newton'), ('gall', 'gallon'), ('wag', 'wagon'), ('mass', 'masson'), ('dem', 'demon'), ('am', 'amon'), ('yo', 'yoon'), ('i', 'ion'), ('jacobs', 'jacobson'), ('tim', 'timon'), ('graft', 'grafton'), ('rent', 'renton'), ('y', 'yon'), ('sams', 'samson'), ('woods', 'woodson'), ('kw', 'kwon'), ('pers', 'person'), ('mans', 'manson'), ('addis', 'addison'), ('marl', 'marlon'), ('robs', 'robson'), ('bart', 'barton'), ('j', 'jon'), ('richards', 'richardson'), ('bor', 'boron'), ('melt', 'melton'), ('less', 'lesson'), ('rad', 'radon'), ('brand', 'brandon'), ('dill', 'dillon'), ('ex', 'exon'), ('drag', 'dragon'), ('di', 'dion'), ('ast', 'aston'), ('hint', 'hinton'), ('kent', 'kenton'), ('surge', 'surgeon'), ('roberts', 'robertson'), ('dent', 'denton'), ('an', 'anon'), ('jays', 'jayson'), ('quint', 'quinton'), ('stevens', 'stevenson'), ('buff', 'buffon'), ('act', 'acton'), ('harris', 'harrison'), ('luz', 'luzon'), ('fall', 'fallon'), ('cars', 'carson'), ('el', 'elon'), ('ae', 'aeon'), ('h', 'hon'), ('fergus', 'ferguson'), ('colt', 'colton'), ('unis', 'unison'), ('dicks', 'dickson'), ('sci', 'scion'), ('bo', 'boon'), ('butt', 'button'), ('hendricks', 'hendrickson'), ('dev', 'devon'), ('masters', 'masterson'), ('mas', 'mason'), ('sim', 'simon'), ('lars', 'larson'), ('cm', 'cmon'), ('uni', 'union'), ('group', 'groupon'), ('ho', 'hoon'), ('pat', 'paton'), ('clarks', 'clarkson'), ('ec', 'econ'), ('vern', 'vernon'), ('west', 'weston'), ('holt', 'holton'), ('no', 'noon'), ('ga', 'gaon'), ('harm', 'harmon'), ('list', 'liston'), ('plato', 'platoon'), ('w', 'won'), ('morris', 'morrison'), ('c', 'con'), ('hans', 'hanson'), ('hutchins', 'hutchinson'), ('prot', 'proton'), ('nix', 'nixon'), ('brit', 'briton'), ('g', 'gon'), ('bat', 'baton'), ('burt', 'burton'), ('go', 'goon'), ('britt', 'britton'), ('there', 'thereon'), ('set', 'seton'), ('seas', 'season'), ('loud', 'loudon'), ('jacks', 'jackson'), ('want', 'wanton'), ('ori', 'orion'), ('jas', 'jason'), ('ant', 'anton'), ('domini', 'dominion'), ('fut', 'futon'), ('jo', 'joon'), ('br', 'bron'), ('mel', 'melon'), ('cord', 'cordon'), ('davis', 'davison'), ('milli', 'million'), ('singlet', 'singleton'), ('wilt', 'wilton'), ('nichols', 'nicholson'), ('eps', 'epson'), ('adams', 'adamson'), ('atkins', 'atkinson'), ('peters', 'peterson'), ('cart', 'carton'), ('ne', 'neon'), ('james', 'jameson'), ('her', 'heron'), ('alt', 'alton'), ('anders', 'anderson'), ('je', 'jeon'), ('mah', 'mahon'), ('robins', 'robinson'), ('hur', 'huron'), ('jeffers', 'jefferson'), ('bis', 'bison'), ('bolt', 'bolton'), ('wilkins', 'wilkinson'), ('sax', 'saxon'), ('heat', 'heaton'), ('shim', 'shimon'), ('bar', 'baron'), ('grays', 'grayson'), ('bright', 'brighton'), ('pauls', 'paulson'), ('ball', 'ballon'), ('pars', 'parson'), ('car', 'caron'), ('can', 'canon'), ('weld', 'weldon'), ('edmonds', 'edmondson'), ('east', 'easton'), ('et', 'eton'), ('b', 'bon'), ('v', 'von'), ('so', 'soon'), ('r', 'ron'), ('gab', 'gabon'), ('davids', 'davidson'), ('lo', 'loon'), ('do', 'doon'), ('ani', 'anion'), ('hutt', 'hutton'), ('swans', 'swanson'), ('co', 'coon'), ('ray', 'rayon'), ('ly', 'lyon'), ('sal', 'salon'), ('denis', 'denison'), ('part', 'parton'), ('th', 'thon'), ('laws', 'lawson'), ('lem', 'lemon'), ('ans', 'anson'), ('t', 'ton'), ('mutt', 'mutton'), ('rest', 'reston'), ('milt', 'milton'), ('mini', 'minion'), ('brought', 'broughton'), ('to', 'toon'), ('mort', 'morton'), ('aar', 'aaron'), ('seat', 'seaton'), ('lint', 'linton'), ('sol', 'solon'), ('mor', 'moron'), ('coco', 'cocoon'), ('dix', 'dixon'), ('lago', 'lagoon'), ('l', 'lon'), ('beat', 'beaton'), ('the', 'theon'), ('nik', 'nikon'), ('wheat', 'wheaton'), ('tal', 'talon'), ('pears', 'pearson'), ('le', 'leon'), ('ti', 'tion'), ('cant', 'canton'), ('ram', 'ramon'), ('yuk', 'yukon'), ('stephens', 'stephenson'), ('li', 'lion'), ('d', 'don'), ('eat', 'eaton'), ('ax', 'axon'), ('williams', 'williamson'), ('bret', 'breton'), ('dennis', 'dennison'), ('barr', 'barron'), ('zi', 'zion'), ('arg', 'argon'), ('ox', 'oxon'), ('rat', 'raton')],) \n",
      " 282 times\n",
      "  examples prefix  [('onscreen', 'screen'), ('onward', 'ward'), ('oni', 'i'), ('onto', 'to'), ('onus', 'us')] \n",
      " 27 times\n",
      "\n",
      "si: suffix? True, prefix? True\n",
      "  examples suffix  ([('tut', 'tutsi'), ('i', 'isi'), ('mes', 'messi'), ('o', 'osi'), ('d', 'dsi'), ('far', 'farsi'), ('p', 'psi'), ('qua', 'quasi'), ('pep', 'pepsi'), ('ros', 'rossi'), ('si', 'sisi'), ('m', 'msi'), ('sta', 'stasi'), ('de', 'desi'), ('na', 'nasi'), ('c', 'csi'), ('h', 'hsi'), ('sc', 'scsi'), ('s', 'ssi'), ('a', 'asi'), ('mor', 'morsi'), ('an', 'ansi'), ('r', 'rsi')],) \n",
      " 23 times\n",
      "  examples prefix  [('sil', 'l'), ('silas', 'las'), ('siesta', 'esta'), ('sid', 'd'), ('sited', 'ted')] \n",
      " 80 times\n",
      "\n",
      "ea: suffix? True, prefix? True\n",
      "  examples suffix  ([('corn', 'cornea'), ('f', 'fea'), ('n', 'nea'), ('i', 'iea'), ('t', 'tea'), ('med', 'medea'), ('c', 'cea'), ('corr', 'correa'), ('id', 'idea'), ('w', 'wea'), ('h', 'hea'), ('kor', 'korea'), ('jud', 'judea'), ('s', 'sea'), ('ur', 'urea'), ('fl', 'flea'), ('th', 'thea'), ('e', 'eea'), ('r', 'rea'), ('l', 'lea'), ('pl', 'plea'), ('m', 'mea'), ('b', 'bea'), ('hos', 'hosea'), ('ar', 'area'), ('swans', 'swansea'), ('p', 'pea'), ('sh', 'shea'), ('batters', 'battersea'), ('ia', 'iaea'), ('crim', 'crimea'), ('d', 'dea'), ('rh', 'rhea'), ('br', 'brea'), ('y', 'yea'), ('g', 'gea'), ('ik', 'ikea')],) \n",
      " 37 times\n",
      "  examples prefix  [('ealing', 'ling'), ('early', 'rly'), ('eased', 'sed'), ('eas', 's'), ('easy', 'sy')] \n",
      " 30 times\n",
      "\n",
      "to: suffix? True, prefix? True\n",
      "  examples suffix  ([('hither', 'hitherto'), ('sa', 'sato'), ('tan', 'tanto'), ('chris', 'christo'), ('be', 'beto'), ('sai', 'saito'), ('to', 'toto'), ('yama', 'yamato'), ('on', 'onto'), ('e', 'eto'), ('pro', 'proto'), ('dit', 'ditto'), ('a', 'ato'), ('toma', 'tomato'), ('vi', 'vito'), ('go', 'goto'), ('gus', 'gusto'), ('ti', 'tito'), ('so', 'soto'), ('beni', 'benito'), ('nie', 'nieto'), ('un', 'unto'), ('na', 'nato'), ('ben', 'bento'), ('rena', 'renato'), ('g', 'gto'), ('up', 'upto'), ('p', 'pto'), ('ton', 'tonto'), ('mo', 'moto'), ('mako', 'makoto'), ('san', 'santo'), ('ka', 'kato'), ('kan', 'kanto'), ('ama', 'amato'), ('fac', 'facto'), ('shin', 'shinto'), ('lot', 'lotto'), ('pho', 'photo'), ('ca', 'cato'), ('c', 'cto'), ('mot', 'motto'), ('i', 'ito'), ('le', 'leto'), ('pes', 'pesto'), ('pres', 'presto'), ('pin', 'pinto'), ('pla', 'plato'), ('al', 'alto'), ('cris', 'cristo'), ('por', 'porto'), ('modes', 'modesto'), ('s', 'sto'), ('ke', 'keto'), ('au', 'auto'), ('w', 'wto'), ('kyo', 'kyoto'), ('ve', 'veto'), ('in', 'into'), ('ot', 'otto'), ('tin', 'tinto'), ('can', 'canto'), ('qui', 'quito'), ('devi', 'devito'), ('there', 'thereto')],) \n",
      " 65 times\n",
      "  examples prefix  [('told', 'ld'), ('toma', 'ma'), ('tomorrow', 'morrow'), ('today', 'day'), ('toning', 'ning')] \n",
      " 124 times\n",
      "\n",
      "in: suffix? True, prefix? True\n",
      "  examples suffix  ([('tint', 'tintin'), ('roll', 'rollin'), ('sla', 'slain'), ('start', 'startin'), ('bev', 'bevin'), ('bullet', 'bulletin'), ('fall', 'fallin'), ('ja', 'jain'), ('h', 'hin'), ('cum', 'cumin'), ('mak', 'makin'), ('sat', 'satin'), ('freak', 'freakin'), ('puff', 'puffin'), ('f', 'fin'), ('ra', 'rain'), ('frick', 'frickin'), ('marl', 'marlin'), ('cry', 'cryin'), ('album', 'albumin'), ('qu', 'quin'), ('tra', 'train'), ('aga', 'again'), ('col', 'colin'), ('gra', 'grain'), ('tur', 'turin'), ('watch', 'watchin'), ('mar', 'marin'), ('roma', 'romain'), ('park', 'parkin'), ('sk', 'skin'), ('ga', 'gain'), ('ka', 'kain'), ('ron', 'ronin'), ('tripp', 'trippin'), ('log', 'login'), ('la', 'lain'), ('villa', 'villain'), ('pa', 'pain'), ('feel', 'feelin'), ('jump', 'jumpin'), ('with', 'within'), ('ia', 'iain'), ('pal', 'palin'), ('dunk', 'dunkin'), ('y', 'yin'), ('hold', 'holdin'), ('od', 'odin'), ('blow', 'blowin'), ('salad', 'saladin'), ('v', 'vin'), ('liv', 'livin'), ('gr', 'grin'), ('d', 'din'), ('aust', 'austin'), ('putt', 'puttin'), ('mess', 'messin'), ('west', 'westin'), ('rank', 'rankin'), ('here', 'herein'), ('sav', 'savin'), ('sar', 'sarin'), ('sing', 'singin'), ('tonk', 'tonkin'), ('t', 'tin'), ('rab', 'rabin'), ('adrenal', 'adrenalin'), ('ball', 'ballin'), ('god', 'godin'), ('cook', 'cookin'), ('see', 'seein'), ('hav', 'havin'), ('there', 'therein'), ('lew', 'lewin'), ('ben', 'benin'), ('ak', 'akin'), ('arm', 'armin'), ('say', 'sayin'), ('griff', 'griffin'), ('walk', 'walkin'), ('keep', 'keepin'), ('w', 'win'), ('eat', 'eatin'), ('ala', 'alain'), ('jo', 'join'), ('l', 'lin'), ('r', 'rin'), ('rob', 'robin'), ('ol', 'olin'), ('dolph', 'dolphin'), ('where', 'wherein'), ('bra', 'brain'), ('carl', 'carlin'), ('chill', 'chillin'), ('fight', 'fightin'), ('ma', 'main'), ('ste', 'stein'), ('sta', 'stain'), ('marv', 'marvin'), ('constant', 'constantin'), ('eo', 'eoin'), ('p', 'pin'), ('kick', 'kickin'), ('go', 'goin'), ('ask', 'askin'), ('twa', 'twain'), ('coll', 'collin'), ('k', 'kin'), ('usa', 'usain'), ('hero', 'heroin'), ('sp', 'spin'), ('tell', 'tellin'), ('check', 'checkin'), ('lev', 'levin'), ('kill', 'killin'), ('pla', 'plain'), ('rock', 'rockin'), ('re', 'rein'), ('ca', 'cain'), ('len', 'lenin'), ('irv', 'irvin'), ('terra', 'terrain'), ('thor', 'thorin'), ('j', 'jin'), ('sh', 'shin'), ('call', 'callin'), ('com', 'comin'), ('tw', 'twin'), ('er', 'erin'), ('morn', 'mornin'), ('rusk', 'ruskin'), ('pull', 'pullin'), ('mal', 'malin'), ('mor', 'morin'), ('za', 'zain'), ('se', 'sein'), ('b', 'bin'), ('g', 'gin'), ('dust', 'dustin'), ('put', 'putin'), ('m', 'min'), ('lat', 'latin'), ('ha', 'hain'), ('think', 'thinkin'), ('n', 'nin'), ('play', 'playin'), ('orr', 'orrin'), ('cha', 'chain'), ('lora', 'lorain'), ('try', 'tryin'), ('linked', 'linkedin'), ('kev', 'kevin'), ('va', 'vain'), ('chop', 'chopin'), ('spa', 'spain'), ('fe', 'fein'), ('be', 'bein'), ('gro', 'groin'), ('bask', 'baskin'), ('s', 'sin'), ('res', 'resin'), ('drink', 'drinkin'), ('work', 'workin'), ('me', 'mein'), ('lark', 'larkin'), ('look', 'lookin'), ('hang', 'hangin'), ('he', 'hein'), ('curt', 'curtin'), ('ve', 'vein'), ('talk', 'talkin'), ('marg', 'margin'), ('beg', 'begin'), ('break', 'breakin'), ('em', 'emin'), ('michel', 'michelin'), ('ly', 'lyin'), ('stay', 'stayin'), ('august', 'augustin'), ('atta', 'attain'), ('ed', 'edin'), ('cab', 'cabin'), ('rid', 'ridin'), ('shoot', 'shootin'), ('link', 'linkin'), ('a', 'ain'), ('co', 'coin'), ('bas', 'basin'), ('dar', 'darin'), ('orig', 'origin'), ('dev', 'devin'), ('tak', 'takin'), ('mart', 'martin'), ('th', 'thin'), ('e', 'ein'), ('muff', 'muffin'), ('bitch', 'bitchin'), ('chap', 'chapin'), ('anton', 'antonin'), ('hard', 'hardin'), ('wait', 'waitin'), ('plug', 'plugin'), ('lo', 'loin'), ('crisp', 'crispin'), ('anak', 'anakin'), ('ba', 'bain'), ('rub', 'rubin'), ('act', 'actin'), ('ru', 'ruin'), ('do', 'doin'), ('just', 'justin'), ('q', 'qin'), ('x', 'xin'), ('c', 'cin'), ('br', 'brin'), ('rod', 'rodin'), ('fuck', 'fuckin'), ('am', 'amin'), ('ch', 'chin'), ('kar', 'karin'), ('adm', 'admin'), ('mov', 'movin')],) \n",
      " 222 times\n",
      "  examples prefix  [('infrequently', 'frequently'), ('injustice', 'justice'), ('inflows', 'flows'), ('instill', 'still'), ('inequity', 'equity')] \n",
      " 324 times\n",
      "\n",
      "be: suffix? True, prefix? True\n",
      "  examples suffix  ([('m', 'mbe'), ('vi', 'vibe'), ('pro', 'probe'), ('ro', 'robe'), ('tri', 'tribe'), ('ado', 'adobe'), ('micro', 'microbe'), ('bri', 'bribe'), ('be', 'bebe'), ('a', 'abe'), ('tu', 'tube'), ('ga', 'gabe'), ('ru', 'rube'), ('lo', 'lobe'), ('t', 'tbe'), ('ba', 'babe'), ('c', 'cbe'), ('lu', 'lube'), ('cu', 'cube'), ('bee', 'beebe'), ('wanna', 'wannabe'), ('uri', 'uribe'), ('glo', 'globe'), ('ko', 'kobe'), ('to', 'tobe'), ('may', 'maybe'), ('o', 'obe')],) \n",
      " 27 times\n",
      "  examples prefix  [('beef', 'ef'), ('beal', 'al'), ('beit', 'it'), ('bevin', 'vin'), ('best', 'st')] \n",
      " 143 times\n",
      "\n",
      "th: suffix? True, prefix? True\n",
      "  examples suffix  ([('eleven', 'eleventh'), ('wye', 'wyeth'), ('boo', 'booth'), ('eighteen', 'eighteenth'), ('kei', 'keith'), ('sixteen', 'sixteenth'), ('my', 'myth'), ('mou', 'mouth'), ('edi', 'edith'), ('bir', 'birth'), ('wid', 'width'), ('ro', 'roth'), ('o', 'oth'), ('four', 'fourth'), ('7', '7th'), ('8', '8th'), ('go', 'goth'), ('heal', 'health'), ('pa', 'path'), ('n', 'nth'), ('nea', 'neath'), ('dar', 'darth'), ('wi', 'with'), ('loa', 'loath'), ('nineteen', 'nineteenth'), ('bar', 'barth'), ('fir', 'firth'), ('bro', 'broth'), ('dea', 'death'), ('wir', 'wirth'), ('shea', 'sheath'), ('fro', 'froth'), ('seventeen', 'seventeenth'), ('brea', 'breath'), ('bo', 'both'), ('4', '4th'), ('lei', 'leith'), ('steal', 'stealth'), ('ca', 'cath'), ('gar', 'garth'), ('me', 'meth'), ('ha', 'hath'), ('lili', 'lilith'), ('au', 'auth'), ('bread', 'breadth'), ('oa', 'oath'), ('a', 'ath'), ('seven', 'seventh'), ('na', 'nath'), ('hundred', 'hundredth'), ('thirteen', 'thirteenth'), ('tru', 'truth'), ('six', 'sixth'), ('si', 'sith'), ('gare', 'gareth'), ('bly', 'blyth'), ('you', 'youth'), ('ra', 'rath'), ('sou', 'south'), ('6', '6th'), ('ka', 'kath'), ('mea', 'meath'), ('fifteen', 'fifteenth'), ('mo', 'moth'), ('hadi', 'hadith'), ('warm', 'warmth'), ('fourteen', 'fourteenth'), ('ber', 'berth'), ('nor', 'north'), ('s', 'sth'), ('outgrow', 'outgrowth'), ('fai', 'faith'), ('se', 'seth'), ('mon', 'month'), ('5', '5th'), ('ba', 'bath'), ('come', 'cometh'), ('dear', 'dearth'), ('ma', 'math'), ('ru', 'ruth'), ('wor', 'worth'), ('clo', 'cloth'), ('fil', 'filth'), ('tee', 'teeth'), ('hear', 'hearth'), ('hea', 'heath'), ('w', 'wth'), ('syn', 'synth'), ('million', 'millionth'), ('grow', 'growth'), ('nin', 'ninth'), ('for', 'forth'), ('do', 'doth'), ('dep', 'depth'), ('fri', 'frith'), ('ear', 'earth'), ('sai', 'saith'), ('per', 'perth'), ('slo', 'sloth'), ('to', 'toth'), ('e', 'eth'), ('judi', 'judith'), ('mir', 'mirth'), ('ten', 'tenth'), ('be', 'beth'), ('i', 'ith'), ('too', 'tooth'), ('give', 'giveth'), ('9', '9th')],) \n",
      " 109 times\n",
      "  examples prefix  [('three', 'ree'), ('theft', 'eft'), ('thrice', 'rice'), ('tho', 'o'), ('things', 'ings')] \n",
      " 94 times\n",
      "\n",
      "en: suffix? True, prefix? True\n",
      "  examples suffix  ([('gard', 'garden'), ('hal', 'halen'), ('kitt', 'kitten'), ('rav', 'raven'), ('silk', 'silken'), ('tak', 'taken'), ('deep', 'deepen'), ('ov', 'oven'), ('lik', 'liken'), ('niels', 'nielsen'), ('te', 'teen'), ('yu', 'yuen'), ('cull', 'cullen'), ('lind', 'linden'), ('om', 'omen'), ('c', 'cen'), ('sv', 'sven'), ('ste', 'steen'), ('chick', 'chicken'), ('all', 'allen'), ('hsi', 'hsien'), ('hel', 'helen'), ('fuck', 'fucken'), ('frank', 'franken'), ('orig', 'origen'), ('lin', 'linen'), ('wid', 'widen'), ('th', 'then'), ('ox', 'oxen'), ('fast', 'fasten'), ('aud', 'auden'), ('behold', 'beholden'), ('cov', 'coven'), ('stat', 'staten'), ('m', 'men'), ('cord', 'corden'), ('wald', 'walden'), ('f', 'fen'), ('wool', 'woolen'), ('ev', 'even'), ('weak', 'weaken'), ('ell', 'ellen'), ('sunk', 'sunken'), ('ca', 'caen'), ('brad', 'braden'), ('robb', 'robben'), ('aust', 'austen'), ('ew', 'ewen'), ('christ', 'christen'), ('hast', 'hasten'), ('thick', 'thicken'), ('y', 'yen'), ('or', 'oren'), ('she', 'sheen'), ('fresh', 'freshen'), ('wi', 'wien'), ('r', 'ren'), ('rog', 'rogen'), ('ros', 'rosen'), ('h', 'hen'), ('barr', 'barren'), ('d', 'den'), ('s', 'sen'), ('ess', 'essen'), ('ad', 'aden'), ('liv', 'liven'), ('loos', 'loosen'), ('rub', 'ruben'), ('jens', 'jensen'), ('sharp', 'sharpen'), ('drunk', 'drunken'), ('gall', 'gallen'), ('height', 'heighten'), ('g', 'gen'), ('lum', 'lumen'), ('wr', 'wren'), ('yell', 'yellen'), ('jal', 'jalen'), ('ar', 'aren'), ('vivi', 'vivien'), ('list', 'listen'), ('threat', 'threaten'), ('steph', 'stephen'), ('glut', 'gluten'), ('bad', 'baden'), ('less', 'lessen'), ('co', 'coen'), ('be', 'been'), ('britt', 'britten'), ('ram', 'ramen'), ('zh', 'zhen'), ('j', 'jen'), ('wood', 'wooden'), ('w', 'wen'), ('tok', 'token'), ('oft', 'often'), ('ti', 'tien'), ('juli', 'julien'), ('de', 'deen'), ('straight', 'straighten'), ('bur', 'buren'), ('kam', 'kamen'), ('gosh', 'goshen'), ('batt', 'batten'), ('e', 'een'), ('sweet', 'sweeten'), ('bi', 'bien'), ('mull', 'mullen'), ('hans', 'hansen'), ('asp', 'aspen'), ('pauls', 'paulsen'), ('fall', 'fallen'), ('quick', 'quicken'), ('op', 'open'), ('hold', 'holden'), ('dore', 'doreen'), ('had', 'haden'), ('tough', 'toughen'), ('gl', 'glen'), ('dark', 'darken'), ('b', 'ben'), ('er', 'eren'), ('li', 'lien'), ('hav', 'haven'), ('bod', 'boden'), ('heath', 'heathen'), ('bright', 'brighten'), ('ald', 'alden'), ('sor', 'soren'), ('sir', 'siren'), ('witt', 'witten'), ('p', 'pen'), ('gre', 'green'), ('sh', 'shen'), ('earth', 'earthen'), ('wok', 'woken'), ('z', 'zen'), ('gold', 'golden'), ('lad', 'laden'), ('light', 'lighten'), ('short', 'shorten'), ('hard', 'harden'), ('berg', 'bergen'), ('aid', 'aiden'), ('eb', 'eben'), ('seam', 'seamen'), ('gal', 'galen'), ('t', 'ten'), ('mort', 'morten'), ('k', 'ken'), ('kar', 'karen'), ('ke', 'keen'), ('br', 'bren'), ('ow', 'owen'), ('deutsch', 'deutschen'), ('cow', 'cowen'), ('ris', 'risen'), ('poll', 'pollen'), ('mart', 'marten'), ('old', 'olden'), ('vix', 'vixen'), ('length', 'lengthen'), ('damp', 'dampen'), ('se', 'seen'), ('lars', 'larsen'), ('v', 'ven'), ('soft', 'soften'), ('mads', 'madsen'), ('anders', 'andersen'), ('ed', 'eden'), ('hag', 'hagen'), ('que', 'queen'), ('fright', 'frighten'), ('sem', 'semen'), ('tight', 'tighten'), ('ward', 'warden'), ('peters', 'petersen'), ('lor', 'loren'), ('wh', 'when'), ('ali', 'alien'), ('maid', 'maiden'), ('chi', 'chien'), ('ard', 'arden'), ('rip', 'ripen'), ('gw', 'gwen'), ('beat', 'beaten'), ('jacobs', 'jacobsen'), ('ch', 'chen'), ('gott', 'gotten'), ('am', 'amen'), ('strength', 'strengthen'), ('aris', 'arisen'), ('ibs', 'ibsen'), ('prov', 'proven'), ('eat', 'eaten'), ('l', 'len'), ('shrunk', 'shrunken'), ('bid', 'biden'), ('bow', 'bowen'), ('broad', 'broaden')],) \n",
      " 200 times\n",
      "  examples prefix  [('enchanting', 'chanting'), ('encircled', 'circled'), ('encode', 'code'), ('entrusted', 'trusted'), ('enix', 'ix')] \n",
      " 114 times\n",
      "\n",
      "nd: suffix? True, prefix? True\n",
      "  examples suffix  ([('dura', 'durand'), ('se', 'send'), ('sta', 'stand'), ('ame', 'amend'), ('fo', 'fond'), ('fie', 'fiend'), ('spe', 'spend'), ('d', 'dnd'), ('po', 'pond'), ('fu', 'fund'), ('liga', 'ligand'), ('ha', 'hand'), ('ki', 'kind'), ('mou', 'mound'), ('ra', 'rand'), ('ble', 'blend'), ('bola', 'boland'), ('gra', 'grand'), ('e', 'end'), ('a', 'and'), ('ba', 'band'), ('hou', 'hound'), ('fe', 'fend'), ('te', 'tend'), ('tre', 'trend'), ('conte', 'contend'), ('me', 'mend'), ('la', 'land'), ('arma', 'armand'), ('le', 'lend'), ('holla', 'holland'), ('divide', 'dividend'), ('bridge', 'bridgend'), ('bra', 'brand'), ('be', 'bend'), ('comma', 'command'), ('i', 'ind'), ('bla', 'bland'), ('u', 'und'), ('si', 'sind'), ('hi', 'hind'), ('isla', 'island'), ('bi', 'bind'), ('abou', 'abound'), ('revere', 'reverend'), ('li', 'lind'), ('week', 'weeknd'), ('bu', 'bund'), ('sou', 'sound'), ('co', 'cond'), ('wi', 'wind'), ('na', 'nand'), ('bou', 'bound'), ('wa', 'wand'), ('sa', 'sand'), ('remi', 'remind'), ('cha', 'chand'), ('comme', 'commend'), ('fou', 'found'), ('2', '2nd'), ('lu', 'lund'), ('ber', 'bernd'), ('s', 'snd'), ('bo', 'bond'), ('mi', 'mind'), ('ana', 'anand'), ('fi', 'find'), ('stipe', 'stipend'), ('ri', 'rind'), ('gla', 'gland')],) \n",
      " 70 times\n",
      "  examples prefix  [('nda', 'a'), ('ndc', 'c'), ('ndtv', 'tv'), ('ndp', 'p')] \n",
      " 4 times\n",
      "\n",
      "ou: suffix? True, prefix? True\n",
      "  examples suffix  ([('n', 'nou'), ('angel', 'angelou'), ('ab', 'abou'), ('ch', 'chou'), ('bay', 'bayou'), ('b', 'bou'), ('l', 'lou'), ('s', 'sou'), ('y', 'you'), ('sh', 'shou'), ('c', 'cou'), ('d', 'dou'), ('t', 'tou'), ('v', 'vou'), ('zh', 'zhou'), ('h', 'hou'), ('f', 'fou'), ('m', 'mou'), ('th', 'thou')],) \n",
      " 19 times\n",
      "  examples prefix  [('oui', 'i'), ('ours', 'rs'), ('ouch', 'ch'), ('ousting', 'sting'), ('ould', 'ld')] \n",
      " 12 times\n",
      "\n",
      "st: suffix? True, prefix? True\n",
      "  examples suffix  ([('strange', 'strangest'), ('te', 'test'), ('na', 'nast'), ('be', 'best'), ('simple', 'simplest'), ('puri', 'purist'), ('ze', 'zest'), ('ju', 'just'), ('cute', 'cutest'), ('p', 'pst'), ('pa', 'past'), ('among', 'amongst'), ('d', 'dst'), ('ho', 'host'), ('ha', 'hast'), ('h', 'hst'), ('repo', 'repost'), ('ni', 'nist'), ('wai', 'waist'), ('que', 'quest'), ('tru', 'trust'), ('ae', 'aest'), ('con', 'const'), ('olde', 'oldest'), ('ru', 'rust'), ('true', 'truest'), ('inge', 'ingest'), ('conte', 'contest'), ('cy', 'cyst'), ('little', 'littlest'), ('hur', 'hurst'), ('faire', 'fairest'), ('ince', 'incest'), ('bea', 'beast'), ('ne', 'nest'), ('g', 'gst'), ('c', 'cst'), ('m', 'mst'), ('pe', 'pest'), ('mid', 'midst'), ('cru', 'crust'), ('s', 'sst'), ('au', 'aust'), ('li', 'list'), ('ve', 'vest'), ('di', 'dist'), ('o', 'ost'), ('wide', 'widest'), ('lo', 'lost'), ('contra', 'contrast'), ('do', 'dost'), ('gi', 'gist'), ('mi', 'mist'), ('hone', 'honest'), ('dive', 'divest'), ('moi', 'moist'), ('provo', 'provost'), ('co', 'cost'), ('hei', 'heist'), ('boo', 'boost'), ('ea', 'east'), ('u', 'ust'), ('lu', 'lust'), ('sharpe', 'sharpest'), ('fa', 'fast'), ('l', 'lst'), ('safe', 'safest'), ('roa', 'roast'), ('la', 'last'), ('again', 'against'), ('fierce', 'fiercest'), ('amid', 'amidst'), ('brave', 'bravest'), ('ca', 'cast'), ('fea', 'feast'), ('du', 'dust'), ('ang', 'angst'), ('1', '1st'), ('sure', 'surest'), ('ps', 'psst'), ('jihadi', 'jihadist'), ('try', 'tryst'), ('in', 'inst'), ('bu', 'bust'), ('ma', 'mast'), ('wor', 'worst'), ('re', 'rest'), ('wise', 'wisest'), ('mari', 'marist'), ('nice', 'nicest'), ('le', 'lest'), ('large', 'largest'), ('lowe', 'lowest'), ('b', 'bst'), ('gu', 'gust'), ('hor', 'horst'), ('coa', 'coast'), ('mu', 'must'), ('pro', 'prost'), ('hi', 'hist'), ('thicke', 'thickest'), ('cre', 'crest'), ('ou', 'oust'), ('we', 'west'), ('che', 'chest'), ('bur', 'burst'), ('fine', 'finest'), ('yea', 'yeast'), ('late', 'latest'), ('fe', 'fest'), ('rare', 'rarest'), ('ba', 'bast'), ('boa', 'boast'), ('bla', 'blast'), ('lea', 'least'), ('i', 'ist'), ('tempe', 'tempest'), ('desi', 'desist'), ('a', 'ast'), ('pure', 'purest'), ('va', 'vast'), ('close', 'closest'), ('sincere', 'sincerest'), ('e', 'est'), ('wilde', 'wildest'), ('fore', 'forest'), ('as', 'asst'), ('po', 'post'), ('fro', 'frost'), ('mole', 'molest'), ('toa', 'toast'), ('hear', 'hearst'), ('mo', 'most'), ('mode', 'modest'), ('fir', 'first'), ('thru', 'thrust'), ('dur', 'durst'), ('hoi', 'hoist'), ('roo', 'roost'), ('grande', 'grandest'), ('brea', 'breast'), ('je', 'jest'), ('cri', 'crist'), ('fi', 'fist'), ('yo', 'yost')],) \n",
      " 145 times\n",
      "  examples prefix  [('strangers', 'rangers'), ('stamp', 'amp'), ('stand', 'and'), ('strings', 'rings'), ('stubs', 'ubs')] \n",
      " 182 times\n",
      "\n",
      "ro: suffix? True, prefix? True\n",
      "  examples suffix  ([('ag', 'agro'), ('ichi', 'ichiro'), ('mun', 'munro'), ('ta', 'taro'), ('hi', 'hiro'), ('spi', 'spiro'), ('csi', 'csiro'), ('fer', 'ferro'), ('gi', 'giro'), ('ae', 'aero'), ('pie', 'piero'), ('guerre', 'guerrero'), ('elect', 'electro'), ('ret', 'retro'), ('c', 'cro'), ('aust', 'austro'), ('pet', 'petro'), ('sombre', 'sombrero'), ('bo', 'boro'), ('af', 'afro'), ('cast', 'castro'), ('mac', 'macro'), ('tru', 'truro'), ('mi', 'miro'), ('pe', 'pero'), ('a', 'aro'), ('gop', 'gopro'), ('out', 'outro'), ('piet', 'pietro'), ('mic', 'micro'), ('mau', 'mauro'), ('fa', 'faro'), ('rome', 'romero'), ('ni', 'niro'), ('ve', 'vero'), ('shi', 'shiro'), ('ze', 'zero'), ('ute', 'utero'), ('to', 'toro'), ('cent', 'centro'), ('g', 'gro'), ('eu', 'euro'), ('o', 'oro'), ('ped', 'pedro'), ('pot', 'potro'), ('alva', 'alvaro'), ('neg', 'negro'), ('met', 'metro'), ('sand', 'sandro'), ('int', 'intro'), ('f', 'fro'), ('ast', 'astro'), ('nit', 'nitro'), ('ne', 'nero'), ('th', 'thro'), ('he', 'hero'), ('gy', 'gyro'), ('p', 'pro'), ('ca', 'caro'), ('b', 'bro'), ('neu', 'neuro'), ('cai', 'cairo'), ('py', 'pyro'), ('vit', 'vitro'), ('mo', 'moro'), ('monte', 'montero')],) \n",
      " 66 times\n",
      "  examples prefix  [('rovers', 'vers'), ('roof', 'of'), ('roth', 'th'), ('roald', 'ald'), ('rock', 'ck')] \n",
      " 144 times\n",
      "\n",
      "ne: suffix? True, prefix? True\n",
      "  examples suffix  ([('dia', 'diane'), ('kai', 'kaine'), ('cra', 'crane'), ('malo', 'malone'), ('forego', 'foregone'), ('argon', 'argonne'), ('ni', 'nine'), ('ire', 'irene'), ('pla', 'plane'), ('marian', 'marianne'), ('bor', 'borne'), ('pi', 'pine'), ('sho', 'shone'), ('to', 'tone'), ('thro', 'throne'), ('tow', 'towne'), ('thor', 'thorne'), ('keto', 'ketone'), ('ho', 'hone'), ('ina', 'inane'), ('medici', 'medicine'), ('maxi', 'maxine'), ('laver', 'laverne'), ('hor', 'horne'), ('pai', 'paine'), ('capo', 'capone'), ('ber', 'berne'), ('sto', 'stone'), ('bo', 'bone'), ('ne', 'nene'), ('overdo', 'overdone'), ('ac', 'acne'), ('an', 'anne'), ('tu', 'tune'), ('lean', 'leanne'), ('vivien', 'vivienne'), ('rai', 'raine'), ('alo', 'alone'), ('pho', 'phone'), ('outdo', 'outdone'), ('ravi', 'ravine'), ('noo', 'noone'), ('kristi', 'kristine'), ('jay', 'jayne'), ('co', 'cone'), ('joan', 'joanne'), ('levi', 'levine'), ('way', 'wayne'), ('war', 'warne'), ('boo', 'boone'), ('mar', 'marne'), ('sha', 'shane'), ('pro', 'prone'), ('shi', 'shine'), ('uri', 'urine'), ('dun', 'dunne'), ('no', 'none'), ('lay', 'layne'), ('marti', 'martine'), ('cli', 'cline'), ('susan', 'susanne'), ('falco', 'falcone'), ('ka', 'kane'), ('mi', 'mine'), ('ca', 'cane'), ('dion', 'dionne'), ('do', 'done'), ('ba', 'bane'), ('sa', 'sane'), ('la', 'lane'), ('brow', 'browne'), ('ja', 'jane'), ('za', 'zane'), ('sco', 'scone'), ('a', 'ane'), ('i', 'ine'), ('u', 'une'), ('vi', 'vine'), ('redo', 'redone'), ('devi', 'devine'), ('fi', 'fine'), ('pauli', 'pauline'), ('bon', 'bonne'), ('li', 'line'), ('hay', 'hayne'), ('pu', 'pune'), ('e', 'ene'), ('go', 'gone'), ('lai', 'laine'), ('re', 'rene'), ('condo', 'condone'), ('so', 'sone'), ('wi', 'wine'), ('clo', 'clone'), ('wa', 'wane'), ('thi', 'thine'), ('leo', 'leone'), ('cro', 'crone'), ('delphi', 'delphine'), ('christi', 'christine'), ('bri', 'brine'), ('da', 'dane'), ('jean', 'jeanne'), ('lor', 'lorne'), ('ami', 'amine'), ('tha', 'thane'), ('ci', 'cine'), ('coy', 'coyne'), ('ver', 'verne'), ('dua', 'duane'), ('car', 'carne'), ('spi', 'spine'), ('shay', 'shayne'), ('arse', 'arsene'), ('ma', 'mane'), ('mil', 'milne'), ('may', 'mayne'), ('julian', 'julianne'), ('ru', 'rune'), ('cai', 'caine'), ('o', 'one'), ('kee', 'keene'), ('be', 'bene'), ('rho', 'rhone'), ('mari', 'marine'), ('ar', 'arne'), ('ge', 'gene'), ('hei', 'heine'), ('undo', 'undone'), ('ale', 'alene'), ('ty', 'tyne'), ('ju', 'june'), ('sei', 'seine'), ('aria', 'ariane'), ('du', 'dune'), ('ali', 'aline'), ('ti', 'tine'), ('shri', 'shrine'), ('pa', 'pane'), ('pay', 'payne'), ('adrien', 'adrienne'), ('di', 'dine'), ('alkali', 'alkaline'), ('undergo', 'undergone'), ('dea', 'deane'), ('lyn', 'lynne'), ('seri', 'serine'), ('don', 'donne'), ('ton', 'tonne'), ('dian', 'dianne'), ('si', 'sine'), ('ato', 'atone'), ('huma', 'humane'), ('ei', 'eine'), ('zo', 'zone'), ('zi', 'zine'), ('mai', 'maine'), ('va', 'vane'), ('lo', 'lone')],) \n",
      " 159 times\n",
      "  examples prefix  [('nep', 'p'), ('nem', 'm'), ('news', 'ws'), ('newest', 'west'), ('negated', 'gated')] \n",
      " 77 times\n",
      "\n",
      "nt: suffix? True, prefix? True\n",
      "  examples suffix  ([('could', 'couldnt'), ('bu', 'bunt'), ('shu', 'shunt'), ('has', 'hasnt'), ('were', 'werent'), ('pa', 'pant'), ('adhere', 'adherent'), ('compete', 'competent'), ('di', 'dint'), ('late', 'latent'), ('adama', 'adamant'), ('reside', 'resident'), ('mi', 'mint'), ('e', 'ent'), ('age', 'agent'), ('tau', 'taunt'), ('cli', 'clint'), ('converge', 'convergent'), ('tyra', 'tyrant'), ('re', 'rent'), ('ste', 'stent'), ('was', 'wasnt'), ('conte', 'content'), ('solve', 'solvent'), ('fai', 'faint'), ('do', 'dont'), ('lear', 'learnt'), ('reminisce', 'reminiscent'), ('hi', 'hint'), ('is', 'isnt'), ('have', 'havent'), ('would', 'wouldnt'), ('gia', 'giant'), ('bra', 'brant'), ('eve', 'event'), ('ra', 'rant'), ('se', 'sent'), ('prude', 'prudent'), ('pe', 'pent'), ('precede', 'precedent'), ('ka', 'kant'), ('vince', 'vincent'), ('dura', 'durant'), ('sla', 'slant'), ('wo', 'wont'), ('torre', 'torrent'), ('sa', 'sant'), ('stu', 'stunt'), ('sca', 'scant'), ('stride', 'strident'), ('mo', 'mont'), ('cha', 'chant'), ('rode', 'rodent'), ('regime', 'regiment'), ('blu', 'blunt'), ('cu', 'cunt'), ('flue', 'fluent'), ('i', 'int'), ('t', 'tnt'), ('ava', 'avant'), ('insta', 'instant'), ('pate', 'patent'), ('me', 'ment'), ('w', 'wnt'), ('hydra', 'hydrant'), ('au', 'aunt'), ('preside', 'president'), ('fro', 'front'), ('qua', 'quant'), ('be', 'bent'), ('pu', 'punt'), ('confide', 'confident'), ('we', 'went'), ('bur', 'burnt'), ('vaca', 'vacant'), ('ke', 'kent'), ('diverge', 'divergent'), ('fonda', 'fondant'), ('ce', 'cent'), ('pi', 'pint'), ('did', 'didnt'), ('ca', 'cant'), ('decade', 'decadent'), ('pri', 'print'), ('should', 'shouldnt'), ('tre', 'trent'), ('pai', 'paint'), ('te', 'tent'), ('fo', 'font'), ('gru', 'grunt'), ('luce', 'lucent'), ('emerge', 'emergent'), ('tale', 'talent'), ('gra', 'grant'), ('spe', 'spent'), ('le', 'lent'), ('urge', 'urgent'), ('pare', 'parent'), ('lame', 'lament'), ('does', 'doesnt'), ('o', 'ont'), ('sai', 'saint'), ('wa', 'want'), ('ai', 'aint'), ('hu', 'hunt'), ('c', 'cnt'), ('li', 'lint'), ('indulge', 'indulgent'), ('ga', 'gant'), ('cove', 'covent'), ('provide', 'provident'), ('po', 'pont'), ('cou', 'count'), ('a', 'ant'), ('are', 'arent'), ('u', 'unt'), ('poi', 'point'), ('de', 'dent'), ('bru', 'brunt'), ('qui', 'quint'), ('ge', 'gent'), ('co', 'cont'), ('sti', 'stint'), ('pla', 'plant'), ('ti', 'tint'), ('comme', 'comment'), ('tai', 'taint'), ('mou', 'mount'), ('ve', 'vent'), ('mea', 'meant')],) \n",
      " 130 times\n",
      "  examples prefix  [('nth', 'h'), ('ntsb', 'sb'), ('nta', 'a'), ('ntsc', 'sc'), ('nts', 's')] \n",
      " 5 times\n",
      "\n",
      "or: suffix? True, prefix? True\n",
      "  examples suffix  ([('arb', 'arbor'), ('demean', 'demeanor'), ('k', 'kor'), ('f', 'for'), ('pry', 'pryor'), ('n', 'nor'), ('debt', 'debtor'), ('audit', 'auditor'), ('train', 'trainor'), ('connect', 'connector'), ('hum', 'humor'), ('l', 'lor'), ('reflect', 'reflector'), ('assess', 'assessor'), ('j', 'jor'), ('convey', 'conveyor'), ('elect', 'elector'), ('no', 'noor'), ('edit', 'editor'), ('sav', 'savor'), ('sand', 'sandor'), ('invent', 'inventor'), ('ig', 'igor'), ('sign', 'signor'), ('b', 'bor'), ('success', 'successor'), ('council', 'councilor'), ('do', 'door'), ('compress', 'compressor'), ('effect', 'effector'), ('arm', 'armor'), ('govern', 'governor'), ('mot', 'motor'), ('inject', 'injector'), ('may', 'mayor'), ('fav', 'favor'), ('lab', 'labor'), ('bang', 'bangor'), ('col', 'color'), ('greg', 'gregor'), ('indo', 'indoor'), ('construct', 'constructor'), ('tim', 'timor'), ('m', 'mor'), ('tab', 'tabor'), ('tut', 'tutor'), ('suit', 'suitor'), ('intercept', 'interceptor'), ('th', 'thor'), ('man', 'manor'), ('credit', 'creditor'), ('conn', 'connor'), ('counsel', 'counselor'), ('c', 'cor'), ('auth', 'author'), ('ten', 'tenor'), ('stat', 'stator'), ('iv', 'ivor'), ('p', 'por'), ('invest', 'investor'), ('di', 'dior'), ('prospect', 'prospector'), ('gat', 'gator'), ('lib', 'libor'), ('po', 'poor'), ('err', 'error'), ('fl', 'flor'), ('select', 'selector'), ('d', 'dor'), ('vo', 'voor'), ('con', 'conor'), ('sculpt', 'sculptor'), ('predict', 'predictor'), ('defect', 'defector'), ('dec', 'decor'), ('past', 'pastor'), ('contract', 'contractor'), ('flo', 'floor'), ('sect', 'sector'), ('tum', 'tumor'), ('pri', 'prior'), ('don', 'donor'), ('oppress', 'oppressor'), ('h', 'hor'), ('vis', 'visor'), ('profess', 'professor'), ('nest', 'nestor'), ('resist', 'resistor'), ('trait', 'traitor'), ('joh', 'johor'), ('extract', 'extractor'), ('conquer', 'conqueror'), ('lux', 'luxor'), ('winds', 'windsor'), ('od', 'odor'), ('accept', 'acceptor'), ('act', 'actor'), ('visit', 'visitor'), ('conduct', 'conductor'), ('solicit', 'solicitor'), ('ment', 'mentor'), ('tens', 'tensor'), ('inhibit', 'inhibitor'), ('hod', 'hodor'), ('s', 'sor'), ('adapt', 'adaptor'), ('rum', 'rumor'), ('v', 'vor'), ('cant', 'cantor'), ('collect', 'collector'), ('survey', 'surveyor'), ('direct', 'director'), ('val', 'valor'), ('tract', 'tractor'), ('outdo', 'outdoor'), ('sail', 'sailor'), ('capt', 'captor'), ('tail', 'tailor'), ('suppress', 'suppressor'), ('possess', 'possessor'), ('confess', 'confessor'), ('mo', 'moor'), ('t', 'tor'), ('sens', 'sensor'), ('project', 'projector'), ('clam', 'clamor'), ('am', 'amor'), ('min', 'minor'), ('g', 'gor'), ('hon', 'honor'), ('rig', 'rigor'), ('exhibit', 'exhibitor'), ('fed', 'fedor'), ('process', 'processor'), ('protect', 'protector'), ('maj', 'major'), ('ast', 'astor'), ('cond', 'condor'), ('cast', 'castor'), ('instruct', 'instructor'), ('fact', 'factor'), ('rot', 'rotor'), ('react', 'reactor'), ('inspect', 'inspector'), ('gab', 'gabor'), ('sen', 'senor'), ('detect', 'detector'), ('w', 'wor')],) \n",
      " 148 times\n",
      "  examples prefix  [('orc', 'c'), ('orson', 'son'), ('orlando', 'lando'), ('oregon', 'egon'), ('orange', 'ange')] \n",
      " 47 times\n",
      "\n",
      "ac: suffix? True, prefix? True\n",
      "  examples suffix  ([('j', 'jac'), ('n', 'nac'), ('r', 'rac'), ('cardi', 'cardiac'), ('z', 'zac'), ('br', 'brac'), ('w', 'wac'), ('lil', 'lilac'), ('iss', 'issac'), ('b', 'bac'), ('v', 'vac'), ('mani', 'maniac'), ('e', 'eac'), ('s', 'sac'), ('p', 'pac'), ('c', 'cac'), ('isa', 'isaac'), ('m', 'mac'), ('dir', 'dirac'), ('anz', 'anzac'), ('t', 'tac'), ('a', 'aac'), ('l', 'lac'), ('f', 'fac'), ('d', 'dac'), ('shell', 'shellac'), ('im', 'imac'), ('i', 'iac'), ('hv', 'hvac')],) \n",
      " 29 times\n",
      "  examples prefix  [('accredited', 'credited'), ('ache', 'he'), ('ach', 'h'), ('acid', 'id'), ('acl', 'l')] \n",
      " 61 times\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# Example: using wordfreq to test xy as a suffix or prefix\n",
    "# -----------------------------------------------\n",
    "\n",
    "from wordfreq import top_n_list\n",
    "\n",
    "def find_suffix_pairs_wordfreq(ngram, top_n=50000):\n",
    "    ngram = ngram.lower()\n",
    "    words = top_n_list(\"en\", n=top_n)\n",
    "    wordset = set(w.lower() for w in words)\n",
    "    pairs = []\n",
    "    for w in wordset:\n",
    "        if w.endswith(ngram) and len(w) > len(ngram):\n",
    "            base = w[:-len(ngram)]\n",
    "            if base in wordset:\n",
    "                pairs.append((base, w))\n",
    "    # return both the matching pairs and the total count\n",
    "    return pairs, \n",
    "\n",
    "def find_prefix_pairs_wordfreq(ngram, top_n=50000):\n",
    "    ngram = ngram.lower()\n",
    "    words = top_n_list(\"en\", n=top_n)\n",
    "    wordset = set(w.lower() for w in words)\n",
    "    pairs = []\n",
    "    count_w = 0\n",
    "    for w in wordset:\n",
    "        if w.startswith(ngram) and len(w) > len(ngram):\n",
    "            base = w[len(ngram):]\n",
    "            if base in wordset:\n",
    "                pairs.append((w, base))\n",
    "    return pairs\n",
    "\n",
    "def is_valid_suffix_wordfreq(ngram, top_n=50000):\n",
    "    return bool(find_suffix_pairs_wordfreq(ngram, top_n=top_n))\n",
    "\n",
    "def is_valid_prefix_wordfreq(ngram, top_n=50000):\n",
    "    return bool(find_prefix_pairs_wordfreq(ngram, top_n=top_n))\n",
    "\n",
    "def affix_validity_wordfreq(ngram, top_n=50000):\n",
    "    \"\"\"\n",
    "    Returns a dict with booleans for suffix and prefix productivity.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"suffix\": is_valid_suffix_wordfreq(ngram, top_n),\n",
    "        \"prefix\": is_valid_prefix_wordfreq(ngram, top_n)\n",
    "    }\n",
    "\n",
    "# 3. Test a few common bigrams:\n",
    "for bg in bigram:\n",
    "    val = affix_validity_wordfreq(bg, top_n=50000)\n",
    "    print(f\"{bg}: suffix? {val['suffix']}, prefix? {val['prefix']}\")\n",
    "    if val['suffix']:\n",
    "        print(f\"  examples suffix  {find_suffix_pairs_wordfreq(bg)[:1]} \\n {len(find_suffix_pairs_wordfreq(bg)[0])} times\")\n",
    "    if val['prefix']:\n",
    "        print(f\"  examples prefix  {find_prefix_pairs_wordfreq(bg)[:5]} \\n {len(find_prefix_pairs_wordfreq(bg))} times\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea132c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1753822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4aabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
