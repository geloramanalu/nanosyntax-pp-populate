{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e6a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import json\n",
    "import csv\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef62d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['above', 'across', 'against', 'along', 'among', 'around', 'away', 'behind', 'below', 'beside', 'between', 'beyond', 'down', 'in', 'in front of', 'inside', 'left', 'near', 'next to', 'off', 'on', 'out', 'outside', 'over', 'past', 'right', 'through', 'under', 'up', 'upon']\n"
     ]
    }
   ],
   "source": [
    "with open('pp_lexicon/atomic_p.json', 'r') as f:\n",
    "    pp = json.load(f)\n",
    "    \n",
    "# sort pp['atomic_p'].keys() alphabetically\n",
    "keys_sorted = sorted(pp['atomic_p'].keys())\n",
    "print(keys_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f2f3284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "497f8c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'above': ['above',\n",
       "  'supra',\n",
       "  'higher_up',\n",
       "  'in_a_higher_place',\n",
       "  'to_a_higher_place'],\n",
       " 'across': ['across', 'crosswise', 'crossways'],\n",
       " 'against': [],\n",
       " 'along': ['along', 'on'],\n",
       " 'among': [],\n",
       " 'around': ['about',\n",
       "  'around',\n",
       "  'approximately',\n",
       "  'close_to',\n",
       "  'just_about',\n",
       "  'some',\n",
       "  'roughly',\n",
       "  'more_or_less',\n",
       "  'or_so',\n",
       "  'round'],\n",
       " 'away': ['away', 'outside', 'off', 'forth', 'out', 'aside', 'by'],\n",
       " 'behind': ['buttocks',\n",
       "  'nates',\n",
       "  'arse',\n",
       "  'butt',\n",
       "  'backside',\n",
       "  'bum',\n",
       "  'buns',\n",
       "  'can',\n",
       "  'fundament',\n",
       "  'hindquarters',\n",
       "  'hind_end',\n",
       "  'keister',\n",
       "  'posterior',\n",
       "  'prat',\n",
       "  'rear',\n",
       "  'rear_end',\n",
       "  'rump',\n",
       "  'stern',\n",
       "  'seat',\n",
       "  'tail',\n",
       "  'tail_end',\n",
       "  'tooshie',\n",
       "  'tush',\n",
       "  'bottom',\n",
       "  'behind',\n",
       "  'derriere',\n",
       "  'fanny',\n",
       "  'ass',\n",
       "  'slow',\n",
       "  'behindhand',\n",
       "  'in_arrears'],\n",
       " 'below': ['below',\n",
       "  'at_a_lower_place',\n",
       "  'to_a_lower_place',\n",
       "  'beneath',\n",
       "  'infra',\n",
       "  'downstairs',\n",
       "  'down_the_stairs',\n",
       "  'on_a_lower_floor',\n",
       "  'under'],\n",
       " 'beside': [],\n",
       " 'between': ['between', 'betwixt', \"'tween\"],\n",
       " 'beyond': ['beyond'],\n",
       " 'down': ['down',\n",
       "  'down_feather',\n",
       "  'Down',\n",
       "  'John_L._H._Down',\n",
       "  'pile',\n",
       "  'toss_off',\n",
       "  'pop',\n",
       "  'bolt_down',\n",
       "  'belt_down',\n",
       "  'pour_down',\n",
       "  'drink_down',\n",
       "  'kill',\n",
       "  'devour',\n",
       "  'consume',\n",
       "  'go_through',\n",
       "  'shoot_down',\n",
       "  'land',\n",
       "  'knock_down',\n",
       "  'cut_down',\n",
       "  'push_down',\n",
       "  'pull_down',\n",
       "  'polish',\n",
       "  'refine',\n",
       "  'fine-tune',\n",
       "  'downward',\n",
       "  'down_pat',\n",
       "  'mastered',\n",
       "  'depressed',\n",
       "  'gloomy',\n",
       "  'grim',\n",
       "  'blue',\n",
       "  'dispirited',\n",
       "  'downcast',\n",
       "  'downhearted',\n",
       "  'down_in_the_mouth',\n",
       "  'low',\n",
       "  'low-spirited',\n",
       "  'downwards',\n",
       "  'downwardly'],\n",
       " 'in': ['inch',\n",
       "  'in',\n",
       "  'indium',\n",
       "  'In',\n",
       "  'atomic_number_49',\n",
       "  'Indiana',\n",
       "  'Hoosier_State',\n",
       "  'IN',\n",
       "  'inwards',\n",
       "  'inward'],\n",
       " 'in front of': [],\n",
       " 'inside': ['inside',\n",
       "  'interior',\n",
       "  'inner',\n",
       "  'privileged',\n",
       "  'indoors',\n",
       "  'within',\n",
       "  'inwardly',\n",
       "  'at_heart',\n",
       "  'at_bottom',\n",
       "  'deep_down',\n",
       "  'in_spite_of_appearance'],\n",
       " 'left': ['left',\n",
       "  'left_wing',\n",
       "  'left_hand',\n",
       "  'left_field',\n",
       "  'leftfield',\n",
       "  'leave',\n",
       "  'go_forth',\n",
       "  'go_away',\n",
       "  'leave_alone',\n",
       "  'leave_behind',\n",
       "  'exit',\n",
       "  'go_out',\n",
       "  'get_out',\n",
       "  'allow_for',\n",
       "  'allow',\n",
       "  'provide',\n",
       "  'result',\n",
       "  'lead',\n",
       "  'depart',\n",
       "  'pull_up_stakes',\n",
       "  'entrust',\n",
       "  'bequeath',\n",
       "  'will',\n",
       "  'impart',\n",
       "  'give',\n",
       "  'pass_on',\n",
       "  'forget',\n",
       "  'leftover',\n",
       "  'left_over',\n",
       "  'odd',\n",
       "  'remaining',\n",
       "  'unexpended',\n",
       "  'left-hand'],\n",
       " 'near': ['approach',\n",
       "  'near',\n",
       "  'come_on',\n",
       "  'go_up',\n",
       "  'draw_near',\n",
       "  'draw_close',\n",
       "  'come_near',\n",
       "  'close',\n",
       "  'nigh',\n",
       "  'cheeseparing',\n",
       "  'penny-pinching',\n",
       "  'skinny',\n",
       "  'dear',\n",
       "  'good',\n",
       "  'approximate',\n",
       "  'about',\n",
       "  'almost',\n",
       "  'most',\n",
       "  'nearly',\n",
       "  'virtually',\n",
       "  'well-nigh'],\n",
       " 'next to': [],\n",
       " 'off': ['murder',\n",
       "  'slay',\n",
       "  'hit',\n",
       "  'dispatch',\n",
       "  'bump_off',\n",
       "  'off',\n",
       "  'polish_off',\n",
       "  'remove',\n",
       "  'cancelled',\n",
       "  'sour',\n",
       "  'turned',\n",
       "  'away',\n",
       "  'forth'],\n",
       " 'on': ['on', 'along'],\n",
       " 'out': ['out',\n",
       "  'come_out_of_the_closet',\n",
       "  'come_out',\n",
       "  'extinct',\n",
       "  'forbidden',\n",
       "  'prohibited',\n",
       "  'proscribed',\n",
       "  'taboo',\n",
       "  'tabu',\n",
       "  'verboten',\n",
       "  'knocked_out',\n",
       "  'kayoed',\n",
       "  \"KO'd\",\n",
       "  'stunned',\n",
       "  'away'],\n",
       " 'outside': ['outside',\n",
       "  'exterior',\n",
       "  'external',\n",
       "  'extraneous',\n",
       "  'outdoor',\n",
       "  'out-of-door',\n",
       "  'international',\n",
       "  'remote',\n",
       "  'away',\n",
       "  'outdoors',\n",
       "  'out_of_doors',\n",
       "  'alfresco'],\n",
       " 'over': ['over',\n",
       "  'complete',\n",
       "  'concluded',\n",
       "  'ended',\n",
       "  'all_over',\n",
       "  'terminated',\n",
       "  \"o'er\"],\n",
       " 'past': ['past',\n",
       "  'past_times',\n",
       "  'yesteryear',\n",
       "  'past_tense',\n",
       "  'preceding',\n",
       "  'retiring',\n",
       "  'by'],\n",
       " 'right': ['right',\n",
       "  'right_field',\n",
       "  'rightfield',\n",
       "  'right_wing',\n",
       "  'right_hand',\n",
       "  'rightfulness',\n",
       "  'compensate',\n",
       "  'redress',\n",
       "  'correct',\n",
       "  'rectify',\n",
       "  'proper',\n",
       "  'right-hand',\n",
       "  'good',\n",
       "  'ripe',\n",
       "  'veracious',\n",
       "  'flop',\n",
       "  'properly',\n",
       "  'decently',\n",
       "  'decent',\n",
       "  'in_good_order',\n",
       "  'the_right_way',\n",
       "  'right_on',\n",
       "  'mighty',\n",
       "  'mightily',\n",
       "  'powerful',\n",
       "  'justly',\n",
       "  'correctly',\n",
       "  'aright'],\n",
       " 'through': ['done', 'through', 'through_with', 'through_and_through'],\n",
       " 'under': ['nether', 'under', 'below'],\n",
       " 'up': ['up', 'astir', 'improving', 'upward', 'upwards', 'upwardly'],\n",
       " 'upon': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_atomic_p = {}\n",
    "for key in keys_sorted:\n",
    "    # collect all lemma names in a flat list\n",
    "    all_lemmas = []\n",
    "    for syn in wn.synsets(key):\n",
    "        all_lemmas.extend(syn.lemma_names())\n",
    "    # remove duplicates while preserving order\n",
    "    synonyms_atomic_p[key] = list(dict.fromkeys(all_lemmas))\n",
    "\n",
    "# inspect result\n",
    "synonyms_atomic_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # synonyms atomic_p to json\n",
    "# with open('synonyms_atomic_p.json', 'w') as f:\n",
    "#     json.dump(synonyms_atomic_p, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f49238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atomic_p_prop(prop='', counter=5):\n",
    "# pp is a dict, access preposition as key\n",
    "    try:\n",
    "        if prop is not None and prop in ['isAtomicMorph', 'class', 'spellOutHEAD', 'path_p_morphology', 'measure_allowed']:\n",
    "            for key, value in pp['atomic_p'].items():\n",
    "                # print(f\"key: {key}\")\n",
    "                for el in value:\n",
    "                    if el == prop:\n",
    "                        print(f\"{key}: {pp['atomic_p'][key][el]} \")\n",
    "                        counter += 1\n",
    "                        if counter == 5:\n",
    "                            break\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} not found in atomic_p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b81715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_wordnet_wiki_pop = []\n",
    "with open('dictionaries/pp_wordnet_wiki_pop.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, quotechar='|', dialect='excel')\n",
    "    for row in reader:\n",
    "        if row['preposition'] == '':\n",
    "            continue\n",
    "        pp_wordnet_wiki_pop.append({\n",
    "            'preposition': row['preposition'],\n",
    "            'isAtomic': row.get('is_atomic'),\n",
    "            'isSpatial': row.get('is_spatial')\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7877221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pp_wordnet_wiki_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac005df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_wordnet_wiki_pop_spatial = [pp for pp in pp_wordnet_wiki_pop if pp['isSpatial'] == 'TRUE']\n",
    "len(pp_wordnet_wiki_pop_spatial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdb45a",
   "metadata": {},
   "source": [
    "## Get atomic morphemes from unique tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0990610",
   "metadata": {},
   "source": [
    "Unique tokens from the list of wikipedia, wordnet, and dictionaries preposition phrase individual words (as token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5578b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of unique_tokens before: 106\n",
      "numbers of non overlapping unique_tokens: 78\n",
      "top\n",
      "astride\n",
      "atop\n",
      "corner\n",
      "by\n",
      "edge\n",
      "onto\n",
      "after\n",
      "but\n",
      "end\n",
      "into\n",
      "upside\n",
      "for\n",
      "place\n",
      "base\n",
      "higher\n",
      "bottom\n",
      "as\n",
      "via\n",
      "aside\n",
      "back\n",
      "nearest\n",
      "betwixt\n",
      "at\n",
      "ahead\n",
      "astern\n",
      "following\n",
      "center\n",
      "within\n",
      "prior\n",
      "without\n",
      "front\n",
      "before\n",
      "opposite\n",
      "from\n",
      "beneath\n",
      "with\n",
      "rear\n",
      "means\n",
      "apart\n",
      "towards\n",
      "except\n",
      "heart\n",
      "afore\n",
      "tween\n",
      "aboard\n",
      "throughout\n",
      "foot\n",
      "nearer\n",
      "nigh\n",
      "alongside\n",
      "virtue\n",
      "next\n",
      "toward\n",
      "amongst\n",
      "side\n",
      "the\n",
      "of\n",
      "far\n",
      "amid\n",
      "adjacent\n",
      "underneath\n",
      "skin\n",
      "flank\n",
      "plus\n",
      "to\n",
      "subsequent\n",
      "addition\n",
      "cross\n",
      "surface\n",
      "a\n",
      "amidst\n",
      "underside\n",
      "middle\n",
      "core\n",
      "rim\n",
      "face\n",
      "close\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = set() # unique token is defined as set of unique words in preposition\n",
    "def tokenize_preposition(preposition):\n",
    "    return preposition.split(' ')\n",
    "\n",
    "# Example usage\n",
    "for pp in pp_wordnet_wiki_pop_spatial:\n",
    "    tokens = tokenize_preposition(pp['preposition'])\n",
    "    # print(f\"Tokens for '{pp['preposition']}': {tokens}\")    \n",
    "    unique_tokens.update(tokens)\n",
    "\n",
    "print(f\"length of unique_tokens before: {len(unique_tokens)}\")\n",
    "\n",
    "c = 0\n",
    "unique_tokens_copy = unique_tokens.copy()\n",
    "for k in keys_sorted:\n",
    "    if k in unique_tokens_copy:\n",
    "        unique_tokens_copy.remove(k)\n",
    "        c += 1\n",
    "        # print(f\"{k} is in unique tokens\")\n",
    "    else:\n",
    "        # print(f\"{k} is NOT in unique tokens\")\n",
    "        continue\n",
    "print(f\"numbers of non overlapping unique_tokens: {len(unique_tokens_copy)}\")\n",
    "\n",
    "for k in unique_tokens_copy:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d444a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export unique_tokens_copy as json\n",
    "# with open('pp_lexicon/unique_tokens_copy.json', 'w') as f:\n",
    "#     json.dump(list(unique_tokens_copy), f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b9cfc",
   "metadata": {},
   "source": [
    "## Decompose p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3164a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english_word(w):\n",
    "    w = w.lower()\n",
    "    return bool(wn.synsets(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baad4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_preposition(preposition, unique_tokens, method='substring'):\n",
    "    \n",
    "    result = {}\n",
    "    p = preposition.lower()\n",
    "\n",
    "    if method == 'substring':\n",
    "        for token in unique_tokens:\n",
    "            t = token.lower()\n",
    "            if p not in t:\n",
    "                continue\n",
    "\n",
    "            count = t.count(p)\n",
    "\n",
    "            remainder = t.replace(p, \"\", 1)\n",
    "\n",
    "            # if remainder == '':\n",
    "            #     continue\n",
    "            if is_english_word(p) and is_english_word(remainder):\n",
    "                result[token] = {\n",
    "                    'decomposition': [p, remainder],\n",
    "                    'occurrence': count\n",
    "            }\n",
    "\n",
    "        return result\n",
    "    \n",
    "        # if method == 'find_bigram':\n",
    "    \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60f0b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['above',\n",
       " 'across',\n",
       " 'against',\n",
       " 'along',\n",
       " 'among',\n",
       " 'around',\n",
       " 'away',\n",
       " 'behind',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'down',\n",
       " 'in',\n",
       " 'in front of',\n",
       " 'inside',\n",
       " 'left',\n",
       " 'near',\n",
       " 'next to',\n",
       " 'off',\n",
       " 'on',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'past',\n",
       " 'right',\n",
       " 'through',\n",
       " 'under',\n",
       " 'up',\n",
       " 'upon']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# atomic = list(keys_sorted['atomic_p'].keys())\n",
    "atomic = keys_sorted\n",
    "atomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc09f230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'aboard',\n",
       " 'addition',\n",
       " 'adjacent',\n",
       " 'afore',\n",
       " 'after',\n",
       " 'ahead',\n",
       " 'alongside',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amongst',\n",
       " 'apart',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'astern',\n",
       " 'astride',\n",
       " 'at',\n",
       " 'atop',\n",
       " 'back',\n",
       " 'base',\n",
       " 'before',\n",
       " 'beneath',\n",
       " 'betwixt',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'center',\n",
       " 'close',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'cross',\n",
       " 'edge',\n",
       " 'end',\n",
       " 'except',\n",
       " 'face',\n",
       " 'far',\n",
       " 'flank',\n",
       " 'following',\n",
       " 'foot',\n",
       " 'for',\n",
       " 'from',\n",
       " 'front',\n",
       " 'heart',\n",
       " 'higher',\n",
       " 'into',\n",
       " 'means',\n",
       " 'middle',\n",
       " 'nearer',\n",
       " 'nearest',\n",
       " 'next',\n",
       " 'nigh',\n",
       " 'of',\n",
       " 'onto',\n",
       " 'opposite',\n",
       " 'place',\n",
       " 'plus',\n",
       " 'prior',\n",
       " 'rear',\n",
       " 'rim',\n",
       " 'side',\n",
       " 'skin',\n",
       " 'subsequent',\n",
       " 'surface',\n",
       " 'the',\n",
       " 'throughout',\n",
       " 'to',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tween',\n",
       " 'underneath',\n",
       " 'underside',\n",
       " 'upside',\n",
       " 'via',\n",
       " 'virtue',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fb5094e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>token</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>along</td>\n",
       "      <td>alongside</td>\n",
       "      <td>[along, side]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>near</td>\n",
       "      <td>nearest</td>\n",
       "      <td>[near, est]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>near</td>\n",
       "      <td>nearer</td>\n",
       "      <td>[near, er]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>out</td>\n",
       "      <td>throughout</td>\n",
       "      <td>[out, through]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>through</td>\n",
       "      <td>throughout</td>\n",
       "      <td>[through, out]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>under</td>\n",
       "      <td>underside</td>\n",
       "      <td>[under, side]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>up</td>\n",
       "      <td>upside</td>\n",
       "      <td>[up, side]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preposition       token   decomposition  occurrence\n",
       "0       along   alongside   [along, side]           1\n",
       "1        near     nearest     [near, est]           1\n",
       "2        near      nearer      [near, er]           1\n",
       "3         out  throughout  [out, through]           1\n",
       "4     through  throughout  [through, out]           1\n",
       "5       under   underside   [under, side]           1\n",
       "6          up      upside      [up, side]           1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect all decompositions\n",
    "result_decompose = {}\n",
    "for pp in atomic:\n",
    "    if pp in unique_tokens:\n",
    "        comps = decompose_preposition(pp, unique_tokens_copy, method='substring')\n",
    "        if comps:\n",
    "            result_decompose[pp] = comps\n",
    "\n",
    "# turn it into a flat table\n",
    "rows = []\n",
    "for preposition, comps in result_decompose.items():\n",
    "    for token, details in comps.items():\n",
    "        rows.append({\n",
    "            'preposition': preposition,\n",
    "            'token': token,\n",
    "            'decomposition': details['decomposition'],\n",
    "            'occurrence': details['occurrence']\n",
    "        })\n",
    "\n",
    "# dataFrame of all decompositions\n",
    "df_decompose = pandas.DataFrame(rows)\n",
    "df_decompose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea05cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "ece68351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'er', 'est', 'out', 'side', 'through'}"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remainder_decomp = [el[1] for el in df_decompose['decomposition']]\n",
    "# remainder_decomp = set(remainder_decomp)\n",
    "# to_remove = {'so', 'pot', 'mus', 'pot', 'mus', 'ab'} #particles and morphemes that isnt valid\n",
    "# remainder_decomp = remainder_decomp - to_remove\n",
    "# remainder_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70cee548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of unique_tokens_not_decomposed: 72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'aboard',\n",
       " 'addition',\n",
       " 'adjacent',\n",
       " 'afore',\n",
       " 'after',\n",
       " 'ahead',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amongst',\n",
       " 'apart',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'astern',\n",
       " 'astride',\n",
       " 'at',\n",
       " 'atop',\n",
       " 'back',\n",
       " 'base',\n",
       " 'before',\n",
       " 'beneath',\n",
       " 'betwixt',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'center',\n",
       " 'close',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'cross',\n",
       " 'edge',\n",
       " 'end',\n",
       " 'except',\n",
       " 'face',\n",
       " 'far',\n",
       " 'flank',\n",
       " 'following',\n",
       " 'foot',\n",
       " 'for',\n",
       " 'from',\n",
       " 'front',\n",
       " 'heart',\n",
       " 'higher',\n",
       " 'into',\n",
       " 'means',\n",
       " 'middle',\n",
       " 'next',\n",
       " 'nigh',\n",
       " 'of',\n",
       " 'onto',\n",
       " 'opposite',\n",
       " 'place',\n",
       " 'plus',\n",
       " 'prior',\n",
       " 'rear',\n",
       " 'rim',\n",
       " 'side',\n",
       " 'skin',\n",
       " 'subsequent',\n",
       " 'surface',\n",
       " 'the',\n",
       " 'to',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tween',\n",
       " 'underneath',\n",
       " 'via',\n",
       " 'virtue',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tokens in df_decompose\n",
    "tokens_decompose = set()\n",
    "for token in df_decompose['token']:\n",
    "    tokens_decompose.add(token)\n",
    "\n",
    "unique_tokens_not_decomposed = unique_tokens_copy - tokens_decompose\n",
    "print(f\"length of unique_tokens_not_decomposed: {len(unique_tokens_not_decomposed)}\")\n",
    "unique_tokens_not_decomposed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d36227",
   "metadata": {},
   "source": [
    "There are 114 unique tokens of prepositional phrase that are not decomposed by atomic_ps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1526f5",
   "metadata": {},
   "source": [
    "## Stemming for checking atomic elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a5c1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "# Create instances of each stemmer\n",
    "porter   = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50646d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          index           0        1\n",
      "0          away        away     None\n",
      "1           top         top     None\n",
      "2            by          by     None\n",
      "3           edg        edge     None\n",
      "4         after       after     None\n",
      "5           but         but     None\n",
      "6           end         end     None\n",
      "7        outsid     outside     None\n",
      "8         among       among     None\n",
      "9          into        into     None\n",
      "10        along       along     None\n",
      "11        upsid      upside     None\n",
      "12          for         for     None\n",
      "13        place       place     None\n",
      "14       bottom      bottom     None\n",
      "15         asid       aside     None\n",
      "16      betwixt     betwixt     None\n",
      "17           at          at     None\n",
      "18        ahead       ahead     None\n",
      "19       astern      astern     None\n",
      "20       center      center     None\n",
      "21      without     without     None\n",
      "22        front       front     None\n",
      "23         near        near     None\n",
      "24         with        with     None\n",
      "25         rear        rear     None\n",
      "26        apart       apart     None\n",
      "27       except      except     None\n",
      "28         past        past     None\n",
      "29          off         off     None\n",
      "30        tween       tween     None\n",
      "31   throughout  throughout     None\n",
      "32     alongsid   alongside     None\n",
      "33       toward      toward  towards\n",
      "34      amongst     amongst     None\n",
      "35         side        side     None\n",
      "36         left        left     None\n",
      "37      through     through     None\n",
      "38      between     between     None\n",
      "39          plu        plus     None\n",
      "40           to          to     None\n",
      "41      subsequ  subsequent     None\n",
      "42        addit    addition     None\n",
      "43        cross       cross     None\n",
      "44            a           a     None\n",
      "45           up          up     None\n",
      "46       amidst      amidst     None\n",
      "47     undersid   underside     None\n",
      "48         core        core     None\n",
      "49         over        over     None\n",
      "50       beyond      beyond     None\n",
      "51         atop        atop     None\n",
      "52       across      across     None\n",
      "53      against     against     None\n",
      "54       corner      corner     None\n",
      "55         down        down     None\n",
      "56         onto        onto     None\n",
      "57        right       right     None\n",
      "58         base        base     None\n",
      "59       higher      higher     None\n",
      "60           as          as     None\n",
      "61          via         via     None\n",
      "62         back        back     None\n",
      "63      nearest     nearest     None\n",
      "64        below       below     None\n",
      "65       follow   following     None\n",
      "66       within      within     None\n",
      "67        prior       prior     None\n",
      "68       behind      behind     None\n",
      "69         abov       above     None\n",
      "70        befor      before     None\n",
      "71      opposit    opposite     None\n",
      "72        under       under     None\n",
      "73         from        from     None\n",
      "74      beneath     beneath     None\n",
      "75          out         out     None\n",
      "76         mean       means     None\n",
      "77        besid      beside     None\n",
      "78        heart       heart     None\n",
      "79         afor       afore     None\n",
      "80           on          on     None\n",
      "81       aboard      aboard     None\n",
      "82         foot        foot     None\n",
      "83        insid      inside     None\n",
      "84       nearer      nearer     None\n",
      "85         nigh        nigh     None\n",
      "86        virtu      virtue     None\n",
      "87         next        next     None\n",
      "88          the         the     None\n",
      "89       around      around     None\n",
      "90           of          of     None\n",
      "91           in          in     None\n",
      "92          far         far     None\n",
      "93         amid        amid     None\n",
      "94        adjac    adjacent     None\n",
      "95   underneath  underneath     None\n",
      "96         skin        skin     None\n",
      "97        flank       flank     None\n",
      "98         upon        upon     None\n",
      "99       surfac     surface     None\n",
      "100       middl      middle     None\n",
      "101         rim         rim     None\n",
      "102        face        face     None\n",
      "103      astrid     astride     None\n",
      "104       close       close     None\n"
     ]
    }
   ],
   "source": [
    "stemmer = [porter, lancaster, snowball]\n",
    "# build mapping token -> stem for each stemmer\n",
    "def build_stem_mapping(tokens, stemmer):\n",
    "    stem_mapping = {}\n",
    "    for token in tokens:\n",
    "        stem = stemmer.stem(token)\n",
    "        if stem not in stem_mapping:\n",
    "            stem_mapping[stem] = []\n",
    "        stem_mapping[stem].append(token)\n",
    "    return stem_mapping\n",
    "\n",
    "df_stem_porter = build_stem_mapping(unique_tokens, porter)\n",
    "df_stem_lancaster = build_stem_mapping(unique_tokens, lancaster)\n",
    "df_stem_snowball = build_stem_mapping(unique_tokens, snowball)\n",
    "# Convert the stem mappings to DataFrames\n",
    "df_stem_porter = pandas.DataFrame.from_dict(df_stem_porter, orient='index').reset_index()\n",
    "\n",
    "print(df_stem_porter.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b89189b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'away': ['away'],\n",
       " 'top': ['top'],\n",
       " 'by': ['by'],\n",
       " 'edg': ['edge'],\n",
       " 'aft': ['after'],\n",
       " 'but': ['but'],\n",
       " 'end': ['end'],\n",
       " 'outsid': ['outside'],\n",
       " 'among': ['among'],\n",
       " 'into': ['into'],\n",
       " 'along': ['along'],\n",
       " 'upsid': ['upside'],\n",
       " 'for': ['for'],\n",
       " 'plac': ['place'],\n",
       " 'bottom': ['bottom'],\n",
       " 'asid': ['aside'],\n",
       " 'betwixt': ['betwixt'],\n",
       " 'at': ['at'],\n",
       " 'ahead': ['ahead'],\n",
       " 'astern': ['astern'],\n",
       " 'cent': ['center'],\n",
       " 'without': ['without'],\n",
       " 'front': ['front'],\n",
       " 'near': ['near', 'nearer'],\n",
       " 'with': ['with'],\n",
       " 'rear': ['rear'],\n",
       " 'apart': ['apart'],\n",
       " 'exceiv': ['except'],\n",
       " 'past': ['past'],\n",
       " 'off': ['off'],\n",
       " 'tween': ['tween'],\n",
       " 'throughout': ['throughout'],\n",
       " 'alongsid': ['alongside'],\n",
       " 'toward': ['toward', 'towards'],\n",
       " 'amongst': ['amongst'],\n",
       " 'sid': ['side'],\n",
       " 'left': ['left'],\n",
       " 'through': ['through'],\n",
       " 'between': ['between'],\n",
       " 'plu': ['plus'],\n",
       " 'to': ['to'],\n",
       " 'subsequ': ['subsequent'],\n",
       " 'addit': ['addition'],\n",
       " 'cross': ['cross'],\n",
       " 'a': ['a'],\n",
       " 'up': ['up'],\n",
       " 'amidst': ['amidst'],\n",
       " 'undersid': ['underside'],\n",
       " 'cor': ['core'],\n",
       " 'ov': ['over'],\n",
       " 'beyond': ['beyond'],\n",
       " 'atop': ['atop'],\n",
       " 'across': ['across'],\n",
       " 'against': ['against'],\n",
       " 'corn': ['corner'],\n",
       " 'down': ['down'],\n",
       " 'onto': ['onto'],\n",
       " 'right': ['right'],\n",
       " 'bas': ['base'],\n",
       " 'high': ['higher'],\n",
       " 'as': ['as'],\n",
       " 'via': ['via'],\n",
       " 'back': ['back'],\n",
       " 'nearest': ['nearest'],\n",
       " 'below': ['below'],\n",
       " 'follow': ['following'],\n",
       " 'within': ['within'],\n",
       " 'pri': ['prior'],\n",
       " 'behind': ['behind'],\n",
       " 'abov': ['above'],\n",
       " 'bef': ['before'],\n",
       " 'opposit': ['opposite'],\n",
       " 'und': ['under'],\n",
       " 'from': ['from'],\n",
       " 'benea': ['beneath'],\n",
       " 'out': ['out'],\n",
       " 'mean': ['means'],\n",
       " 'besid': ['beside'],\n",
       " 'heart': ['heart'],\n",
       " 'af': ['afore'],\n",
       " 'on': ['on'],\n",
       " 'aboard': ['aboard'],\n",
       " 'foot': ['foot'],\n",
       " 'insid': ['inside'],\n",
       " 'nigh': ['nigh'],\n",
       " 'virtu': ['virtue'],\n",
       " 'next': ['next'],\n",
       " 'the': ['the'],\n",
       " 'around': ['around'],\n",
       " 'of': ['of'],\n",
       " 'in': ['in'],\n",
       " 'far': ['far'],\n",
       " 'amid': ['amid'],\n",
       " 'adjac': ['adjacent'],\n",
       " 'undernea': ['underneath'],\n",
       " 'skin': ['skin'],\n",
       " 'flank': ['flank'],\n",
       " 'upon': ['upon'],\n",
       " 'surfac': ['surface'],\n",
       " 'middl': ['middle'],\n",
       " 'rim': ['rim'],\n",
       " 'fac': ['face'],\n",
       " 'astrid': ['astride'],\n",
       " 'clos': ['close']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stem_lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd5cd9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'away': ['away'],\n",
       " 'top': ['top'],\n",
       " 'by': ['by'],\n",
       " 'edg': ['edge'],\n",
       " 'after': ['after'],\n",
       " 'but': ['but'],\n",
       " 'end': ['end'],\n",
       " 'outsid': ['outside'],\n",
       " 'among': ['among'],\n",
       " 'into': ['into'],\n",
       " 'along': ['along'],\n",
       " 'upsid': ['upside'],\n",
       " 'for': ['for'],\n",
       " 'place': ['place'],\n",
       " 'bottom': ['bottom'],\n",
       " 'asid': ['aside'],\n",
       " 'betwixt': ['betwixt'],\n",
       " 'at': ['at'],\n",
       " 'ahead': ['ahead'],\n",
       " 'astern': ['astern'],\n",
       " 'center': ['center'],\n",
       " 'without': ['without'],\n",
       " 'front': ['front'],\n",
       " 'near': ['near'],\n",
       " 'with': ['with'],\n",
       " 'rear': ['rear'],\n",
       " 'apart': ['apart'],\n",
       " 'except': ['except'],\n",
       " 'past': ['past'],\n",
       " 'off': ['off'],\n",
       " 'tween': ['tween'],\n",
       " 'throughout': ['throughout'],\n",
       " 'alongsid': ['alongside'],\n",
       " 'toward': ['toward', 'towards'],\n",
       " 'amongst': ['amongst'],\n",
       " 'side': ['side'],\n",
       " 'left': ['left'],\n",
       " 'through': ['through'],\n",
       " 'between': ['between'],\n",
       " 'plus': ['plus'],\n",
       " 'to': ['to'],\n",
       " 'subsequ': ['subsequent'],\n",
       " 'addit': ['addition'],\n",
       " 'cross': ['cross'],\n",
       " 'a': ['a'],\n",
       " 'up': ['up'],\n",
       " 'amidst': ['amidst'],\n",
       " 'undersid': ['underside'],\n",
       " 'core': ['core'],\n",
       " 'over': ['over'],\n",
       " 'beyond': ['beyond'],\n",
       " 'atop': ['atop'],\n",
       " 'across': ['across'],\n",
       " 'against': ['against'],\n",
       " 'corner': ['corner'],\n",
       " 'down': ['down'],\n",
       " 'onto': ['onto'],\n",
       " 'right': ['right'],\n",
       " 'base': ['base'],\n",
       " 'higher': ['higher'],\n",
       " 'as': ['as'],\n",
       " 'via': ['via'],\n",
       " 'back': ['back'],\n",
       " 'nearest': ['nearest'],\n",
       " 'below': ['below'],\n",
       " 'follow': ['following'],\n",
       " 'within': ['within'],\n",
       " 'prior': ['prior'],\n",
       " 'behind': ['behind'],\n",
       " 'abov': ['above'],\n",
       " 'befor': ['before'],\n",
       " 'opposit': ['opposite'],\n",
       " 'under': ['under'],\n",
       " 'from': ['from'],\n",
       " 'beneath': ['beneath'],\n",
       " 'out': ['out'],\n",
       " 'mean': ['means'],\n",
       " 'besid': ['beside'],\n",
       " 'heart': ['heart'],\n",
       " 'afor': ['afore'],\n",
       " 'on': ['on'],\n",
       " 'aboard': ['aboard'],\n",
       " 'foot': ['foot'],\n",
       " 'insid': ['inside'],\n",
       " 'nearer': ['nearer'],\n",
       " 'nigh': ['nigh'],\n",
       " 'virtu': ['virtue'],\n",
       " 'next': ['next'],\n",
       " 'the': ['the'],\n",
       " 'around': ['around'],\n",
       " 'of': ['of'],\n",
       " 'in': ['in'],\n",
       " 'far': ['far'],\n",
       " 'amid': ['amid'],\n",
       " 'adjac': ['adjacent'],\n",
       " 'underneath': ['underneath'],\n",
       " 'skin': ['skin'],\n",
       " 'flank': ['flank'],\n",
       " 'upon': ['upon'],\n",
       " 'surfac': ['surface'],\n",
       " 'middl': ['middle'],\n",
       " 'rim': ['rim'],\n",
       " 'face': ['face'],\n",
       " 'astrid': ['astride'],\n",
       " 'close': ['close']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stem_snowball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561dd234",
   "metadata": {},
   "source": [
    "## Get atomic morphemes with ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1b96d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens not decomposed:\n",
      "top\n",
      "atop\n",
      "corner\n",
      "by\n",
      "edge\n",
      "onto\n",
      "after\n",
      "but\n",
      "end\n",
      "into\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "print(\"Unique tokens not decomposed:\")\n",
    "for i in unique_tokens_not_decomposed:\n",
    "    print(i)\n",
    "    c += 1\n",
    "    if c == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5861a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_ngrams(tokens, n):\n",
    "\n",
    "    ngrams_list = []\n",
    "    ngram_map = {}\n",
    "    \n",
    "    for token in tokens:\n",
    "        for gram in ngrams(list(token), n):\n",
    "            # check if gram is valid suffix or prefix in english with wordnet\n",
    "            \n",
    "            \n",
    "            ngrams_list.append(''.join(gram))\n",
    "            \n",
    "            g = ''.join(gram)\n",
    "            ngram_map.setdefault(g, []).append(token)\n",
    "    return ngrams_list, ngram_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f3aa003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(count: 12) | id: ['outside', 'upside', 'aside', 'alongside', 'side', 'amidst', 'underside', 'beside', 'inside', 'amid', 'middle', 'astride'] \n",
      "(count: 12) | de: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'underside', 'under', 'beside', 'inside', 'underneath', 'astride'] \n",
      "(count: 11) | ar: ['near', 'rear', 'apart', 'toward', 'nearest', 'towards', 'heart', 'aboard', 'nearer', 'around', 'far'] \n",
      "(count: 10) | er: ['after', 'astern', 'center', 'underside', 'over', 'corner', 'higher', 'under', 'nearer', 'underneath'] \n",
      "(count: 10) | on: ['among', 'along', 'front', 'alongside', 'amongst', 'addition', 'beyond', 'onto', 'on', 'upon'] \n",
      "(count: 9) | si: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'opposite', 'beside', 'inside'] \n",
      "(count: 9) | ea: ['ahead', 'near', 'rear', 'nearest', 'beneath', 'means', 'heart', 'nearer', 'underneath'] \n",
      "(count: 8) | to: ['top', 'into', 'bottom', 'toward', 'to', 'atop', 'onto', 'towards'] \n",
      "(count: 8) | in: ['into', 'against', 'following', 'within', 'behind', 'inside', 'in', 'skin'] \n",
      "(count: 8) | be: ['betwixt', 'between', 'beyond', 'below', 'behind', 'before', 'beneath', 'beside'] \n",
      "(count: 8) | th: ['without', 'with', 'throughout', 'through', 'within', 'beneath', 'the', 'underneath'] \n",
      "(count: 7) | en: ['end', 'center', 'tween', 'between', 'subsequent', 'beneath', 'adjacent'] \n",
      "(count: 7) | nd: ['end', 'underside', 'beyond', 'behind', 'under', 'around', 'underneath'] \n",
      "(count: 7) | ou: ['outside', 'without', 'throughout', 'throughout', 'through', 'out', 'around'] \n",
      "(count: 7) | st: ['astern', 'past', 'amongst', 'amidst', 'against', 'nearest', 'astride'] \n",
      "(count: 7) | ro: ['front', 'throughout', 'through', 'cross', 'across', 'from', 'around'] \n",
      "(count: 7) | ne: ['near', 'corner', 'nearest', 'beneath', 'nearer', 'next', 'underneath'] \n",
      "(count: 6) | nt: ['into', 'center', 'front', 'subsequent', 'onto', 'adjacent'] \n",
      "(count: 6) | or: ['for', 'core', 'corner', 'prior', 'before', 'afore'] \n",
      "(count: 6) | ac: ['place', 'across', 'back', 'adjacent', 'surface', 'face'] \n"
     ]
    }
   ],
   "source": [
    "# get bigrams of letters from each token\n",
    "bigrams_list, bigram_map = get_char_ngrams(unique_tokens, 2)\n",
    "bigram_counts = Counter(bigrams_list)\n",
    "most_common_bigrams = bigram_counts.most_common(20)\n",
    "\n",
    "for bigram, count in most_common_bigrams:\n",
    "    mapping = bigram_map.get(bigram, [])\n",
    "    print(f\"(count: {count}) | {bigram}: {mapping} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb0852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4400bd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ide: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'beside', 'inside', 'astride'] (count: 9)\n",
      "sid: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'beside', 'inside'] (count: 8)\n",
      "nea: ['near', 'nearest', 'beneath', 'nearer', 'underneath'] (count: 5)\n",
      "ear: ['near', 'rear', 'nearest', 'heart', 'nearer'] (count: 5)\n",
      "out: ['outside', 'without', 'throughout', 'out'] (count: 4)\n",
      "ong: ['among', 'along', 'alongside', 'amongst'] (count: 4)\n",
      "ace: ['place', 'adjacent', 'surface', 'face'] (count: 4)\n",
      "und: ['underside', 'under', 'around', 'underneath'] (count: 4)\n",
      "ter: ['after', 'astern', 'center'] (count: 3)\n",
      "for: ['for', 'before', 'afore'] (count: 3)\n",
      "ast: ['astern', 'past', 'astride'] (count: 3)\n",
      "ent: ['center', 'subsequent', 'adjacent'] (count: 3)\n",
      "wit: ['without', 'with', 'within'] (count: 3)\n",
      "ith: ['without', 'with', 'within'] (count: 3)\n",
      "rou: ['throughout', 'through', 'around'] (count: 3)\n",
      "ard: ['toward', 'towards', 'aboard'] (count: 3)\n",
      "mid: ['amidst', 'amid', 'middle'] (count: 3)\n",
      "nde: ['underside', 'under', 'underneath'] (count: 3)\n",
      "der: ['underside', 'under', 'underneath'] (count: 3)\n",
      "ore: ['core', 'before', 'afore'] (count: 3)\n"
     ]
    }
   ],
   "source": [
    "trigrams_list, trigram_map = get_char_ngrams(unique_tokens, 3)\n",
    "trigram_counts = Counter(trigrams_list)\n",
    "most_common_trigrams = trigram_counts.most_common(20)\n",
    "\n",
    "for trigram, count in most_common_trigrams:\n",
    "    mapping = trigram_map.get(trigram, [])\n",
    "    print(f\"{trigram}: {mapping} (count: {count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9405f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side: ['outside', 'upside', 'aside', 'alongside', 'side', 'underside', 'beside', 'inside'] (count: 8)\n",
      "with: ['without', 'with', 'within'] (count: 3)\n",
      "near: ['near', 'nearest', 'nearer'] (count: 3)\n",
      "unde: ['underside', 'under', 'underneath'] (count: 3)\n",
      "nder: ['underside', 'under', 'underneath'] (count: 3)\n",
      "amon: ['among', 'amongst'] (count: 2)\n",
      "mong: ['among', 'amongst'] (count: 2)\n",
      "alon: ['along', 'alongside'] (count: 2)\n",
      "long: ['along', 'alongside'] (count: 2)\n",
      "betw: ['betwixt', 'between'] (count: 2)\n",
      "cent: ['center', 'adjacent'] (count: 2)\n",
      "hout: ['without', 'throughout'] (count: 2)\n",
      "twee: ['tween', 'between'] (count: 2)\n",
      "ween: ['tween', 'between'] (count: 2)\n",
      "thro: ['throughout', 'through'] (count: 2)\n",
      "hrou: ['throughout', 'through'] (count: 2)\n",
      "roug: ['throughout', 'through'] (count: 2)\n",
      "ough: ['throughout', 'through'] (count: 2)\n",
      "ongs: ['alongside', 'amongst'] (count: 2)\n",
      "towa: ['toward', 'towards'] (count: 2)\n"
     ]
    }
   ],
   "source": [
    "fourgrams_list, fourgram_map = get_char_ngrams(unique_tokens, 4)\n",
    "fourgram_counts = Counter(fourgrams_list)\n",
    "most_common_fourgrams = fourgram_counts.most_common(20)\n",
    "\n",
    "for fourgram, count in most_common_fourgrams:\n",
    "    mapping = fourgram_map.get(fourgram, [])\n",
    "    print(f\"{fourgram}: {mapping} (count: {count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d793c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Code snippet to check whether an n‐letter string acts \n",
    "# as a prefix/suffix in WordNet’s English lexicon\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Make sure wordnet is downloaded:\n",
    "# nltk.download(\"wordnet\")\n",
    "\n",
    "lemmas = set(wn.all_lemma_names())\n",
    "\n",
    "def find_affix_pairs(gram):\n",
    "    g = gram.lower()\n",
    "    suffix = []\n",
    "    prefix = []\n",
    "    for w in lemmas:\n",
    "        if w.endswith(g) and len(w) > len(g):\n",
    "            base = w[:-len(g)]\n",
    "            if base in lemmas:\n",
    "                suffix.append((base, w))\n",
    "        if w.startswith(g) and len(w) > len(g):\n",
    "            base = w[len(g):]\n",
    "            if base in lemmas:\n",
    "                prefix.append((w, base))\n",
    "    return (prefix, suffix) if (prefix or suffix) else None\n",
    "\n",
    "def get_common_affix(ngram_list, n):\n",
    "    for bg in ngram_list:\n",
    "        found = find_affix_pairs(bg)\n",
    "        if not found:\n",
    "            print(f\"{n}‐gram '{bg}' does NOT appear as a productive affix.\\n\")\n",
    "            continue\n",
    "\n",
    "        prefix, suffix = found\n",
    "\n",
    "        if suffix:\n",
    "            print(f\"{n}‐gram '{bg}' as SUFFIX:\")\n",
    "            for base, suffixed in suffix[:10]:\n",
    "                print(f\"  • {base} → {suffixed}\")\n",
    "            print(f\"  ({len(suffix)} total)\\n\")\n",
    "\n",
    "        if prefix:\n",
    "            print(f\"{n}‐gram '{bg}' as PREFIX:\")\n",
    "            for prefixed, base in prefix[:10]:\n",
    "                print(f\"  • {prefixed} → {base}\")\n",
    "            print(f\"  ({len(prefix)} total)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b3386e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2‐gram 'id' as SUFFIX:\n",
      "  • pa → paid\n",
      "  • nsa → nsaid\n",
      "  • fet → fetid\n",
      "  • sol → solid\n",
      "  • ar → arid\n",
      "  • inla → inlaid\n",
      "  • ov → ovid\n",
      "  • re → reid\n",
      "  • p → pid\n",
      "  • ma → maid\n",
      "  (62 total)\n",
      "\n",
      "2‐gram 'id' as PREFIX:\n",
      "  • ido → o\n",
      "  • ides → es\n",
      "  • idf → f\n",
      "  • idle → le\n",
      "  • idea → ea\n",
      "  • identity → entity\n",
      "  • idp → p\n",
      "  • iddm → dm\n",
      "  • idling → ling\n",
      "  • idun → un\n",
      "  (12 total)\n",
      "\n",
      "2‐gram 'de' as SUFFIX:\n",
      "  • ce → cede\n",
      "  • ri → ride\n",
      "  • ba → bade\n",
      "  • abo → abode\n",
      "  • man → mande\n",
      "  • ai → aide\n",
      "  • phyllo → phyllode\n",
      "  • chi → chide\n",
      "  • fa → fade\n",
      "  • gui → guide\n",
      "  (42 total)\n",
      "\n",
      "2‐gram 'de' as PREFIX:\n",
      "  • devisor → visor\n",
      "  • deal → al\n",
      "  • denomination → nomination\n",
      "  • delegation → legation\n",
      "  • degauss → gauss\n",
      "  • decay → cay\n",
      "  • debut → but\n",
      "  • decoder → coder\n",
      "  • deconstructivism → constructivism\n",
      "  • depopulate → populate\n",
      "  (461 total)\n",
      "\n",
      "2‐gram 'ar' as SUFFIX:\n",
      "  • son → sonar\n",
      "  • chad → chadar\n",
      "  • column → columnar\n",
      "  • ge → gear\n",
      "  • huss → hussar\n",
      "  • inst → instar\n",
      "  • line → linear\n",
      "  • gu → guar\n",
      "  • tart → tartar\n",
      "  • astragal → astragalar\n",
      "  (80 total)\n",
      "\n",
      "2‐gram 'ar' as PREFIX:\n",
      "  • arkansan → kansan\n",
      "  • arrange → range\n",
      "  • ardea → dea\n",
      "  • array → ray\n",
      "  • arrester → rester\n",
      "  • arco → co\n",
      "  • arrest → rest\n",
      "  • arhus → hus\n",
      "  • arson → son\n",
      "  • arid → id\n",
      "  (79 total)\n",
      "\n",
      "2‐gram 'er' as SUFFIX:\n",
      "  • teetotal → teetotaler\n",
      "  • crapshoot → crapshooter\n",
      "  • stand → stander\n",
      "  • down → downer\n",
      "  • tamp → tamper\n",
      "  • molt → molter\n",
      "  • roar → roarer\n",
      "  • guess → guesser\n",
      "  • tam → tamer\n",
      "  • probation → probationer\n",
      "  (1427 total)\n",
      "\n",
      "2‐gram 'er' as PREFIX:\n",
      "  • erne → ne\n",
      "  • eragrostis → agrostis\n",
      "  • erie → ie\n",
      "  • ert → t\n",
      "  • era → a\n",
      "  • erodium → odium\n",
      "  • errand → rand\n",
      "  • erin → in\n",
      "  • erect → ect\n",
      "  • erode → ode\n",
      "  (22 total)\n",
      "\n",
      "2‐gram 'on' as SUFFIX:\n",
      "  • gris → grison\n",
      "  • po → poon\n",
      "  • johns → johnson\n",
      "  • pashto → pashtoon\n",
      "  • pomp → pompon\n",
      "  • ir → iron\n",
      "  • mo → moon\n",
      "  • ka → kaon\n",
      "  • mac → macon\n",
      "  • actin → actinon\n",
      "  (171 total)\n",
      "\n",
      "2‐gram 'on' as PREFIX:\n",
      "  • onus → us\n",
      "  • onion → ion\n",
      "  • onstage → stage\n",
      "  • ongoing → going\n",
      "  • onset → set\n",
      "  • once → ce\n",
      "  • onshore → shore\n",
      "  • onward → ward\n",
      "  • oni → i\n",
      "  • onlooker → looker\n",
      "  (16 total)\n",
      "\n",
      "2‐gram 'si' as SUFFIX:\n",
      "  • ni → nisi\n",
      "  • pep → pepsi\n",
      "  • man → mansi\n",
      "  • tut → tutsi\n",
      "  • i → isi\n",
      "  • far → farsi\n",
      "  • par → parsi\n",
      "  • p → psi\n",
      "  • sc → scsi\n",
      "  (9 total)\n",
      "\n",
      "2‐gram 'si' as PREFIX:\n",
      "  • sidelight → delight\n",
      "  • siva → va\n",
      "  • sidle → dle\n",
      "  • sion → on\n",
      "  • sids → ds\n",
      "  • simoon → moon\n",
      "  • simon → mon\n",
      "  • siberia → beria\n",
      "  • siwan → wan\n",
      "  • sing → ng\n",
      "  (52 total)\n",
      "\n",
      "2‐gram 'ea' as SUFFIX:\n",
      "  • corn → cornea\n",
      "  • tineoid → tineoidea\n",
      "  • med → medea\n",
      "  • phoronid → phoronidea\n",
      "  • pang → pangea\n",
      "  • id → idea\n",
      "  • kor → korea\n",
      "  • napa → napaea\n",
      "  • sabin → sabinea\n",
      "  • caesar → caesarea\n",
      "  (56 total)\n",
      "\n",
      "2‐gram 'ea' as PREFIX:\n",
      "  • eas → s\n",
      "  • earn → rn\n",
      "  • easing → sing\n",
      "  • eat → t\n",
      "  • eared → red\n",
      "  • ease → se\n",
      "  • ear → r\n",
      "  • eating → ting\n",
      "  • eastern → stern\n",
      "  • eatable → table\n",
      "  (10 total)\n",
      "\n",
      "2‐gram 'to' as SUFFIX:\n",
      "  • ko → koto\n",
      "  • grot → grotto\n",
      "  • pro → proto\n",
      "  • dit → ditto\n",
      "  • get_on → get_onto\n",
      "  • dig_in → dig_into\n",
      "  • na → nato\n",
      "  • pot → potto\n",
      "  • pan → panto\n",
      "  • pas → pasto\n",
      "  (48 total)\n",
      "\n",
      "2‐gram 'to' as PREFIX:\n",
      "  • today → day\n",
      "  • tone → ne\n",
      "  • torus → rus\n",
      "  • tour → ur\n",
      "  • toad → ad\n",
      "  • too → o\n",
      "  • tonga → nga\n",
      "  • toda → da\n",
      "  • toed → ed\n",
      "  • tomb → mb\n",
      "  (56 total)\n",
      "\n",
      "2‐gram 'in' as SUFFIX:\n",
      "  • buffer → bufferin\n",
      "  • jacob → jacobin\n",
      "  • augment → augmentin\n",
      "  • tall → tallin\n",
      "  • sat → satin\n",
      "  • puff → puffin\n",
      "  • f → fin\n",
      "  • ra → rain\n",
      "  • ops → opsin\n",
      "  • digital → digitalin\n",
      "  (110 total)\n",
      "\n",
      "2‐gram 'in' as PREFIX:\n",
      "  • inhumanely → humanely\n",
      "  • infrequently → frequently\n",
      "  • ineligibility → eligibility\n",
      "  • inconsideration → consideration\n",
      "  • insinuate → sinuate\n",
      "  • instep → step\n",
      "  • instill → still\n",
      "  • infallibility → fallibility\n",
      "  • incorrectly → correctly\n",
      "  • inefficiency → efficiency\n",
      "  (693 total)\n",
      "\n",
      "2‐gram 'be' as SUFFIX:\n",
      "  • vi → vibe\n",
      "  • ro → robe\n",
      "  • ado → adobe\n",
      "  • micro → microbe\n",
      "  • danu → danube\n",
      "  • n → nbe\n",
      "  • lu → lube\n",
      "  • se → sebe\n",
      "  • cu → cube\n",
      "  • gy → gybe\n",
      "  (26 total)\n",
      "\n",
      "2‐gram 'be' as PREFIX:\n",
      "  • berate → rate\n",
      "  • bema → ma\n",
      "  • bespangle → spangle\n",
      "  • bewilder → wilder\n",
      "  • befuddle → fuddle\n",
      "  • beda → da\n",
      "  • bey → y\n",
      "  • bedimmed → dimmed\n",
      "  • bedroll → droll\n",
      "  • bestir → stir\n",
      "  (151 total)\n",
      "\n",
      "2‐gram 'th' as SUFFIX:\n",
      "  • call_for → call_forth\n",
      "  • wye → wyeth\n",
      "  • ro → roth\n",
      "  • four → fourth\n",
      "  • quadrillion → quadrillionth\n",
      "  • go → goth\n",
      "  • heal → health\n",
      "  • 36 → 36th\n",
      "  • pa → path\n",
      "  • 47 → 47th\n",
      "  (151 total)\n",
      "\n",
      "2‐gram 'th' as PREFIX:\n",
      "  • theft → eft\n",
      "  • tho → o\n",
      "  • throw → row\n",
      "  • thwart → wart\n",
      "  • thc → c\n",
      "  • thallium → allium\n",
      "  • theta → eta\n",
      "  • thrill → rill\n",
      "  • thane → ane\n",
      "  • throb → rob\n",
      "  (49 total)\n",
      "\n",
      "2‐gram 'en' as SUFFIX:\n",
      "  • rum → rumen\n",
      "  • silk → silken\n",
      "  • stiff → stiffen\n",
      "  • deep → deepen\n",
      "  • lind → linden\n",
      "  • chick → chicken\n",
      "  • hark → harken\n",
      "  • fast → fasten\n",
      "  • behold → beholden\n",
      "  • f → fen\n",
      "  (144 total)\n",
      "\n",
      "2‐gram 'en' as PREFIX:\n",
      "  • enchondroma → chondroma\n",
      "  • encode → code\n",
      "  • entangle → tangle\n",
      "  • enclothe → clothe\n",
      "  • enlisting → listing\n",
      "  • ensis → sis\n",
      "  • enkindle → kindle\n",
      "  • envision → vision\n",
      "  • entrance → trance\n",
      "  • enchant → chant\n",
      "  (142 total)\n",
      "\n",
      "2‐gram 'nd' as SUFFIX:\n",
      "  • se → send\n",
      "  • opera → operand\n",
      "  • 42 → 42nd\n",
      "  • po → pond\n",
      "  • ha → hand\n",
      "  • e → end\n",
      "  • ba → band\n",
      "  • te → tend\n",
      "  • la → land\n",
      "  • le → lend\n",
      "  (44 total)\n",
      "\n",
      "2‐gram 'ou' as SUFFIX:\n",
      "  • carib → caribou\n",
      "  • s → sou\n",
      "  • bay → bayou\n",
      "  • i → iou\n",
      "  • tat → tatou\n",
      "  • th → thou\n",
      "  (6 total)\n",
      "\n",
      "2‐gram 'ou' as PREFIX:\n",
      "  • outing → ting\n",
      "  • outwit → twit\n",
      "  • outrigger → trigger\n",
      "  • ouse → se\n",
      "  • ousting → sting\n",
      "  • out → t\n",
      "  (6 total)\n",
      "\n",
      "2‐gram 'st' as SUFFIX:\n",
      "  • 41 → 41st\n",
      "  • ni → nist\n",
      "  • inge → ingest\n",
      "  • ne → nest\n",
      "  • m → mst\n",
      "  • mid → midst\n",
      "  • maoi → maoist\n",
      "  • mahdi → mahdist\n",
      "  • li → list\n",
      "  • gi → gist\n",
      "  (71 total)\n",
      "\n",
      "2‐gram 'st' as PREFIX:\n",
      "  • stoat → oat\n",
      "  • stamp → amp\n",
      "  • strings → rings\n",
      "  • strive → rive\n",
      "  • stitching → itching\n",
      "  • stripping → ripping\n",
      "  • struck → ruck\n",
      "  • strife → rife\n",
      "  • std → d\n",
      "  • stillness → illness\n",
      "  (110 total)\n",
      "\n",
      "2‐gram 'ro' as SUFFIX:\n",
      "  • tore → torero\n",
      "  • ti → tiro\n",
      "  • c → cro\n",
      "  • cast → castro\n",
      "  • mi → miro\n",
      "  • dine → dinero\n",
      "  • bole → bolero\n",
      "  • brace → bracero\n",
      "  • p → pro\n",
      "  • mo → moro\n",
      "  (28 total)\n",
      "\n",
      "2‐gram 'ro' as PREFIX:\n",
      "  • romanic → manic\n",
      "  • roth → th\n",
      "  • robe → be\n",
      "  • rostand → stand\n",
      "  • rotc → tc\n",
      "  • rope → pe\n",
      "  • rowing → wing\n",
      "  • rounder → under\n",
      "  • route → ute\n",
      "  • rodent → dent\n",
      "  (68 total)\n",
      "\n",
      "2‐gram 'ne' as SUFFIX:\n",
      "  • dy → dyne\n",
      "  • ni → nine\n",
      "  • vali → valine\n",
      "  • pi → pine\n",
      "  • age → agene\n",
      "  • er → erne\n",
      "  • capo → capone\n",
      "  • overdo → overdone\n",
      "  • chi → chine\n",
      "  • co → cone\n",
      "  (85 total)\n",
      "\n",
      "2‐gram 'ne' as PREFIX:\n",
      "  • nepa → pa\n",
      "  • nee → e\n",
      "  • neuropathy → uropathy\n",
      "  • nepali → pali\n",
      "  • nett → tt\n",
      "  • neurology → urology\n",
      "  • nec → c\n",
      "  • next → xt\n",
      "  • nepal → pal\n",
      "  • negate → gate\n",
      "  (32 total)\n",
      "\n",
      "2‐gram 'nt' as SUFFIX:\n",
      "  • resurge → resurgent\n",
      "  • sc → scnt\n",
      "  • depone → deponent\n",
      "  • pa → pant\n",
      "  • late → latent\n",
      "  • reside → resident\n",
      "  • opera → operant\n",
      "  • solve → solvent\n",
      "  • phosphoresce → phosphorescent\n",
      "  • reminisce → reminiscent\n",
      "  (118 total)\n",
      "\n",
      "2‐gram 'nt' as PREFIX:\n",
      "  • nth → h\n",
      "  (1 total)\n",
      "\n",
      "2‐gram 'or' as SUFFIX:\n",
      "  • adjust → adjustor\n",
      "  • demean → demeanor\n",
      "  • debt → debtor\n",
      "  • hum → humor\n",
      "  • transact → transactor\n",
      "  • reflect → reflector\n",
      "  • clang → clangor\n",
      "  • assess → assessor\n",
      "  • exposit → expositor\n",
      "  • elect → elector\n",
      "  (175 total)\n",
      "\n",
      "2‐gram 'or' as PREFIX:\n",
      "  • orbison → bison\n",
      "  • orology → ology\n",
      "  • oracular → acular\n",
      "  • orate → ate\n",
      "  • orpin → pin\n",
      "  • orad → ad\n",
      "  • orbiter → biter\n",
      "  • orgy → gy\n",
      "  • ore → e\n",
      "  • orbit → bit\n",
      "  (25 total)\n",
      "\n",
      "2‐gram 'ac' as SUFFIX:\n",
      "  • sum → sumac\n",
      "  • tomb → tombac\n",
      "  • p → pac\n",
      "  • m → mac\n",
      "  • l → lac\n",
      "  • shell → shellac\n",
      "  • n → nac\n",
      "  • w → wac\n",
      "  • v → vac\n",
      "  • lin → linac\n",
      "  (11 total)\n",
      "\n",
      "2‐gram 'ac' as PREFIX:\n",
      "  • accredited → credited\n",
      "  • acerose → erose\n",
      "  • accost → cost\n",
      "  • accustom → custom\n",
      "  • acanthus → anthus\n",
      "  • accountable → countable\n",
      "  • acarid → arid\n",
      "  • acrid → rid\n",
      "  • actress → tress\n",
      "  • accumulative → cumulative\n",
      "  (57 total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram = []\n",
    "for i in most_common_bigrams:\n",
    "    bigram.append(i[0])\n",
    "    \n",
    "get_common_affix(bigram, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afbb259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3‐gram 'ide' as SUFFIX:\n",
      "  • rings → ringside\n",
      "  • r → ride\n",
      "  • a → aide\n",
      "  • res → reside\n",
      "  • ways → wayside\n",
      "  • burns → burnside\n",
      "  • fluor → fluoride\n",
      "  • ore → oreide\n",
      "  • az → azide\n",
      "  • gu → guide\n",
      "  (39 total)\n",
      "\n",
      "3‐gram 'ide' as PREFIX:\n",
      "  • ides → s\n",
      "  • idea → a\n",
      "  • ideal → al\n",
      "  • ideology → ology\n",
      "  • ideate → ate\n",
      "  • ideally → ally\n",
      "  (6 total)\n",
      "\n",
      "3‐gram 'sid' as SUFFIX:\n",
      "  • ha → hasid\n",
      "  • cap → capsid\n",
      "  • re → resid\n",
      "  (3 total)\n",
      "\n",
      "3‐gram 'sid' as PREFIX:\n",
      "  • sidle → le\n",
      "  • sidney → ney\n",
      "  • sids → s\n",
      "  • sidalcea → alcea\n",
      "  • sida → a\n",
      "  • side → e\n",
      "  • sidon → on\n",
      "  (7 total)\n",
      "\n",
      "3‐gram 'nea' as SUFFIX:\n",
      "  • gui → guinea\n",
      "  • genus_ara → genus_aranea\n",
      "  • us → usnea\n",
      "  • ti → tinea\n",
      "  • ara → aranea\n",
      "  (5 total)\n",
      "\n",
      "3‐gram 'nea' as PREFIX:\n",
      "  • neat → t\n",
      "  • neap → p\n",
      "  • neaten → ten\n",
      "  • near → r\n",
      "  • nearest → rest\n",
      "  (5 total)\n",
      "\n",
      "3‐gram 'ear' as SUFFIX:\n",
      "  • g → gear\n",
      "  • goody → goodyear\n",
      "  • wheat → wheatear\n",
      "  • lin → linear\n",
      "  • s → sear\n",
      "  • h → hear\n",
      "  • w → wear\n",
      "  • cl → clear\n",
      "  • d → dear\n",
      "  • end → endear\n",
      "  (20 total)\n",
      "\n",
      "3‐gram 'ear' as PREFIX:\n",
      "  • earshot → shot\n",
      "  • earpiece → piece\n",
      "  • earphone → phone\n",
      "  • earn → n\n",
      "  • earlobe → lobe\n",
      "  • earmuff → muff\n",
      "  • earl → l\n",
      "  • earring → ring\n",
      "  • earreach → reach\n",
      "  • earplug → plug\n",
      "  (27 total)\n",
      "\n",
      "3‐gram 'out' as SUFFIX:\n",
      "  • cook → cookout\n",
      "  • dug → dugout\n",
      "  • strike → strikeout\n",
      "  • rag → ragout\n",
      "  • work → workout\n",
      "  • check → checkout\n",
      "  • l → lout\n",
      "  • close → closeout\n",
      "  • fold → foldout\n",
      "  • g → gout\n",
      "  (56 total)\n",
      "\n",
      "3‐gram 'out' as PREFIX:\n",
      "  • outright → right\n",
      "  • outride → ride\n",
      "  • outline → line\n",
      "  • outcaste → caste\n",
      "  • outflowing → flowing\n",
      "  • outspan → span\n",
      "  • outsmart → smart\n",
      "  • outcall → call\n",
      "  • outfall → fall\n",
      "  • outbid → bid\n",
      "  (117 total)\n",
      "\n",
      "3‐gram 'ong' as SUFFIX:\n",
      "  • pr → prong\n",
      "  • parts → partsong\n",
      "  • b → bong\n",
      "  • hm → hmong\n",
      "  • folks → folksong\n",
      "  • bel → belong\n",
      "  • camp → campong\n",
      "  • th → thong\n",
      "  • d → dong\n",
      "  • mek → mekong\n",
      "  (19 total)\n",
      "\n",
      "3‐gram 'ace' as SUFFIX:\n",
      "  • l → lace\n",
      "  • r → race\n",
      "  • m → mace\n",
      "  • f → face\n",
      "  • p → pace\n",
      "  • enl → enlace\n",
      "  • sol → solace\n",
      "  • alt → altace\n",
      "  • bull → bullace\n",
      "  • pal → palace\n",
      "  (22 total)\n",
      "\n",
      "3‐gram 'ace' as PREFIX:\n",
      "  • acerose → rose\n",
      "  • acetonic → tonic\n",
      "  • acedia → dia\n",
      "  • acetic → tic\n",
      "  • acerate → rate\n",
      "  • acerb → rb\n",
      "  • acetone → tone\n",
      "  • acetabular → tabular\n",
      "  • acer → r\n",
      "  • acetate → tate\n",
      "  (12 total)\n",
      "\n",
      "3‐gram 'und' as SUFFIX:\n",
      "  • redo → redound\n",
      "  • expo → expound\n",
      "  • ma → maund\n",
      "  • abo → abound\n",
      "  • so → sound\n",
      "  • ro → round\n",
      "  • rot → rotund\n",
      "  • f → fund\n",
      "  • mo → mound\n",
      "  • ho → hound\n",
      "  (14 total)\n",
      "\n",
      "3‐gram 'und' as PREFIX:\n",
      "  • undrape → rape\n",
      "  • undo → o\n",
      "  • undraped → raped\n",
      "  • undset → set\n",
      "  • undergo → ergo\n",
      "  • undone → one\n",
      "  • undermine → ermine\n",
      "  • under → er\n",
      "  (8 total)\n",
      "\n",
      "3‐gram 'ter' as SUFFIX:\n",
      "  • mol → molter\n",
      "  • plat → platter\n",
      "  • rebut → rebutter\n",
      "  • ut → utter\n",
      "  • lat → latter\n",
      "  • put → putter\n",
      "  • tit → titter\n",
      "  • split → splitter\n",
      "  • cot → cotter\n",
      "  • bun → bunter\n",
      "  (163 total)\n",
      "\n",
      "3‐gram 'ter' as PREFIX:\n",
      "  • tercentenary → centenary\n",
      "  • termite → mite\n",
      "  • teras → as\n",
      "  • term → m\n",
      "  • terrace → race\n",
      "  • teres → es\n",
      "  • tern → n\n",
      "  • ternary → nary\n",
      "  • tera → a\n",
      "  • tertry → try\n",
      "  (17 total)\n",
      "\n",
      "3‐gram 'for' as SUFFIX:\n",
      "  • there → therefor\n",
      "  (1 total)\n",
      "\n",
      "3‐gram 'for' as PREFIX:\n",
      "  • fork → k\n",
      "  • forgiving → giving\n",
      "  • form → m\n",
      "  • forswearing → swearing\n",
      "  • forrad → rad\n",
      "  • forester → ester\n",
      "  • forgather → gather\n",
      "  • foram → am\n",
      "  • format → mat\n",
      "  • foramen → amen\n",
      "  (51 total)\n",
      "\n",
      "3‐gram 'ast' as SUFFIX:\n",
      "  • lamb → lambast\n",
      "  • be → beast\n",
      "  • bomb → bombast\n",
      "  • e → east\n",
      "  • le → least\n",
      "  • v → vast\n",
      "  • n → nast\n",
      "  • p → past\n",
      "  • cl → clast\n",
      "  • f → fast\n",
      "  (21 total)\n",
      "\n",
      "3‐gram 'ast' as PREFIX:\n",
      "  • astern → ern\n",
      "  • astraddle → raddle\n",
      "  • astaire → aire\n",
      "  • astir → ir\n",
      "  • astana → ana\n",
      "  • astor → or\n",
      "  • aster → er\n",
      "  • astute → ute\n",
      "  • astasia → asia\n",
      "  • astray → ray\n",
      "  (11 total)\n",
      "\n",
      "3‐gram 'ent' as SUFFIX:\n",
      "  • coexist → coexistent\n",
      "  • lat → latent\n",
      "  • resid → resident\n",
      "  • respond → respondent\n",
      "  • noc → nocent\n",
      "  • ev → event\n",
      "  • retard → retardent\n",
      "  • p → pent\n",
      "  • pot → potent\n",
      "  • adsorb → adsorbent\n",
      "  (77 total)\n",
      "\n",
      "3‐gram 'ent' as PREFIX:\n",
      "  • entrant → rant\n",
      "  • entangle → angle\n",
      "  • entailment → ailment\n",
      "  • entrails → rails\n",
      "  • entomb → omb\n",
      "  • entire → ire\n",
      "  • enter → er\n",
      "  • enticing → icing\n",
      "  • entwine → wine\n",
      "  • entangled → angled\n",
      "  (18 total)\n",
      "\n",
      "3‐gram 'wit' as SUFFIX:\n",
      "  • dim → dimwit\n",
      "  • pe → pewit\n",
      "  • out → outwit\n",
      "  • t → twit\n",
      "  • nit → nitwit\n",
      "  • pee → peewit\n",
      "  • god → godwit\n",
      "  (7 total)\n",
      "\n",
      "3‐gram 'wit' as PREFIX:\n",
      "  • within → hin\n",
      "  • withe → he\n",
      "  • witting → ting\n",
      "  • witness → ness\n",
      "  • witless → less\n",
      "  • wits → s\n",
      "  (6 total)\n",
      "\n",
      "3‐gram 'ith' as SUFFIX:\n",
      "  • cr → crith\n",
      "  • k → kith\n",
      "  • p → pith\n",
      "  • zen → zenith\n",
      "  • sm → smith\n",
      "  • fecal → fecalith\n",
      "  • br → brith\n",
      "  • faecal → faecalith\n",
      "  • fa → faith\n",
      "  • holler → hollerith\n",
      "  (11 total)\n",
      "\n",
      "3‐gram 'rou' as PREFIX:\n",
      "  • rouge → ge\n",
      "  • roux → x\n",
      "  • routine → tine\n",
      "  • route → te\n",
      "  • round → nd\n",
      "  • rouse → se\n",
      "  • roumania → mania\n",
      "  • roulade → lade\n",
      "  • rous → s\n",
      "  • rout → t\n",
      "  (12 total)\n",
      "\n",
      "3‐gram 'ard' as SUFFIX:\n",
      "  • bay → bayard\n",
      "  • must → mustard\n",
      "  • boll → bollard\n",
      "  • l → lard\n",
      "  • y → yard\n",
      "  • steely → steelyard\n",
      "  • sw → sward\n",
      "  • mall → mallard\n",
      "  • buzz → buzzard\n",
      "  • tab → tabard\n",
      "  (54 total)\n",
      "\n",
      "3‐gram 'ard' as PREFIX:\n",
      "  • ardea → ea\n",
      "  • ardor → or\n",
      "  • ardeb → eb\n",
      "  • ards → s\n",
      "  • arda → a\n",
      "  (5 total)\n",
      "\n",
      "3‐gram 'mid' as SUFFIX:\n",
      "  • aga → agamid\n",
      "  • cos → cosmid\n",
      "  • des → desmid\n",
      "  • ti → timid\n",
      "  (4 total)\n",
      "\n",
      "3‐gram 'mid' as PREFIX:\n",
      "  • midgrass → grass\n",
      "  • midrib → rib\n",
      "  • midway → way\n",
      "  • midweekly → weekly\n",
      "  • midweek → week\n",
      "  • midland → land\n",
      "  • midvein → vein\n",
      "  • midmost → most\n",
      "  • midiron → iron\n",
      "  • midas → as\n",
      "  (38 total)\n",
      "\n",
      "3‐gram 'nde' as SUFFIX:\n",
      "  • ma → mande\n",
      "  • giro → gironde\n",
      "  (2 total)\n",
      "\n",
      "3‐gram 'der' as SUFFIX:\n",
      "  • ci → cider\n",
      "  • deco → decoder\n",
      "  • german → germander\n",
      "  • rejoin → rejoinder\n",
      "  • lea → leader\n",
      "  • tin → tinder\n",
      "  • win → winder\n",
      "  • min → minder\n",
      "  • sen → sender\n",
      "  • sun → sunder\n",
      "  (70 total)\n",
      "\n",
      "3‐gram 'der' as PREFIX:\n",
      "  • derv → v\n",
      "  • derain → ain\n",
      "  • derby → by\n",
      "  • derate → ate\n",
      "  • derailment → ailment\n",
      "  • derail → ail\n",
      "  • derringer → ringer\n",
      "  • derrick → rick\n",
      "  • derma → ma\n",
      "  (9 total)\n",
      "\n",
      "3‐gram 'ore' as SUFFIX:\n",
      "  • eyes → eyesore\n",
      "  • y → yore\n",
      "  • s → sore\n",
      "  • lah → lahore\n",
      "  • p → pore\n",
      "  • ash → ashore\n",
      "  • sc → score\n",
      "  • tag → tagore\n",
      "  • ad → adore\n",
      "  • mo → moore\n",
      "  (27 total)\n",
      "\n",
      "3‐gram 'ore' as PREFIX:\n",
      "  • oreo → o\n",
      "  • oread → ad\n",
      "  (2 total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram = []\n",
    "for i in most_common_trigrams:\n",
    "    trigram.append(i[0])\n",
    "    \n",
    "# 2. Test a few common trigrams\n",
    "get_common_affix(trigram, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4be87aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4‐gram 'side' as SUFFIX:\n",
      "  • up → upside\n",
      "  • ring → ringside\n",
      "  • re → reside\n",
      "  • mountain → mountainside\n",
      "  • way → wayside\n",
      "  • over → overside\n",
      "  • river → riverside\n",
      "  • burn → burnside\n",
      "  • dock → dockside\n",
      "  • lake → lakeside\n",
      "  (41 total)\n",
      "\n",
      "4‐gram 'side' as PREFIX:\n",
      "  • sidelight → light\n",
      "  • sidereal → real\n",
      "  • sidearm → arm\n",
      "  • sideburn → burn\n",
      "  • sidestroke → stroke\n",
      "  • sidesaddle → saddle\n",
      "  • sideslip → slip\n",
      "  • sideline → line\n",
      "  • sideward → ward\n",
      "  • siderite → rite\n",
      "  (28 total)\n",
      "\n",
      "4‐gram 'with' as SUFFIX:\n",
      "  • here → herewith\n",
      "  • there → therewith\n",
      "  • forth → forthwith\n",
      "  (3 total)\n",
      "\n",
      "4‐gram 'with' as PREFIX:\n",
      "  • withdrawn → drawn\n",
      "  • within → in\n",
      "  • withal → al\n",
      "  • withdraw → draw\n",
      "  • withhold → hold\n",
      "  • withholder → holder\n",
      "  • withstand → stand\n",
      "  • withe → e\n",
      "  • withdrawing_room → drawing_room\n",
      "  • withy → y\n",
      "  (14 total)\n",
      "\n",
      "4‐gram 'near' as SUFFIX:\n",
      "  • li → linear\n",
      "  (1 total)\n",
      "\n",
      "4‐gram 'near' as PREFIX:\n",
      "  • nearsighted → sighted\n",
      "  • nearer → er\n",
      "  • nearsightedness → sightedness\n",
      "  • nearside → side\n",
      "  • nearby → by\n",
      "  • nearness → ness\n",
      "  • nearest → est\n",
      "  (7 total)\n",
      "\n",
      "4‐gram 'unde' as PREFIX:\n",
      "  • underage → rage\n",
      "  • undeterminable → terminable\n",
      "  • undefinable → finable\n",
      "  • underevaluation → revaluation\n",
      "  • undeserving → serving\n",
      "  • undesigned → signed\n",
      "  • undecomposed → composed\n",
      "  • under → r\n",
      "  (8 total)\n",
      "\n",
      "4‐gram 'nder' as SUFFIX:\n",
      "  • re → render\n",
      "  • ti → tinder\n",
      "  • wi → winder\n",
      "  • mi → minder\n",
      "  • se → sender\n",
      "  • la → lander\n",
      "  • fe → fender\n",
      "  • pa → pander\n",
      "  • ge → gender\n",
      "  • cola → colander\n",
      "  (32 total)\n",
      "\n",
      "4‐gram 'amon' as SUFFIX:\n",
      "  • d → damon\n",
      "  • card → cardamon\n",
      "  (2 total)\n",
      "\n",
      "4‐gram 'mong' as SUFFIX:\n",
      "  • h → hmong\n",
      "  (1 total)\n",
      "\n",
      "4‐gram 'mong' as PREFIX:\n",
      "  • mongo → o\n",
      "  • monger → er\n",
      "  (2 total)\n",
      "\n",
      "4‐gram 'alon' as SUFFIX:\n",
      "  • h → halon\n",
      "  • s → salon\n",
      "  • t → talon\n",
      "  (3 total)\n",
      "\n",
      "4‐gram 'alon' as PREFIX:\n",
      "  • alonso → so\n",
      "  • alone → e\n",
      "  • along → g\n",
      "  (3 total)\n",
      "\n",
      "4‐gram 'long' as SUFFIX:\n",
      "  • live → livelong\n",
      "  • day → daylong\n",
      "  • ob → oblong\n",
      "  • pro → prolong\n",
      "  • age → agelong\n",
      "  • be → belong\n",
      "  • night → nightlong\n",
      "  • week → weeklong\n",
      "  • year → yearlong\n",
      "  • head → headlong\n",
      "  (16 total)\n",
      "\n",
      "4‐gram 'long' as PREFIX:\n",
      "  • longlegs → legs\n",
      "  • longstanding → standing\n",
      "  • longness → ness\n",
      "  • longhand → hand\n",
      "  • longfellow → fellow\n",
      "  • longwise → wise\n",
      "  • longbeard → beard\n",
      "  • longan → an\n",
      "  • longwool → wool\n",
      "  • longshot → shot\n",
      "  (22 total)\n",
      "\n",
      "4‐gram 'betw' does NOT appear as a productive affix.\n",
      "\n",
      "4‐gram 'cent' as SUFFIX:\n",
      "  • no → nocent\n",
      "  • do → docent\n",
      "  • de → decent\n",
      "  • ac → accent\n",
      "  • s → scent\n",
      "  • as → ascent\n",
      "  • re → recent\n",
      "  • des → descent\n",
      "  • pubes → pubescent\n",
      "  • lu → lucent\n",
      "  (10 total)\n",
      "\n",
      "4‐gram 'cent' as PREFIX:\n",
      "  • centrally → rally\n",
      "  • centimo → imo\n",
      "  • cental → al\n",
      "  • centas → as\n",
      "  • centavo → avo\n",
      "  • centare → are\n",
      "  • center → er\n",
      "  • centrum → rum\n",
      "  • centre → re\n",
      "  • centrex → rex\n",
      "  (10 total)\n",
      "\n",
      "4‐gram 'hout' as SUFFIX:\n",
      "  • ma → mahout\n",
      "  • s → shout\n",
      "  (2 total)\n",
      "\n",
      "4‐gram 'twee' as PREFIX:\n",
      "  • tweet → t\n",
      "  • tweed → d\n",
      "  • tweedle → dle\n",
      "  • tweedy → dy\n",
      "  (4 total)\n",
      "\n",
      "4‐gram 'ween' as SUFFIX:\n",
      "  • bet → between\n",
      "  (1 total)\n",
      "\n",
      "4‐gram 'ween' as PREFIX:\n",
      "  • weenie → ie\n",
      "  • weeny → y\n",
      "  (2 total)\n",
      "\n",
      "4‐gram 'thro' as PREFIX:\n",
      "  • throw → w\n",
      "  • throb → b\n",
      "  • throne → ne\n",
      "  • throng → ng\n",
      "  • throe → e\n",
      "  • throat → at\n",
      "  • throes → es\n",
      "  (7 total)\n",
      "\n",
      "4‐gram 'hrou' does NOT appear as a productive affix.\n",
      "\n",
      "4‐gram 'roug' as PREFIX:\n",
      "  • rouge → e\n",
      "  • rouged → ed\n",
      "  • rough → h\n",
      "  • roughen → hen\n",
      "  (4 total)\n",
      "\n",
      "4‐gram 'ough' as SUFFIX:\n",
      "  • th → though\n",
      "  • furl → furlough\n",
      "  • r → rough\n",
      "  • thor → thorough\n",
      "  • t → tough\n",
      "  • s → sough\n",
      "  • l → lough\n",
      "  • sl → slough\n",
      "  • d → dough\n",
      "  • b → bough\n",
      "  (12 total)\n",
      "\n",
      "4‐gram 'ongs' as SUFFIX:\n",
      "  • t → tongs\n",
      "  (1 total)\n",
      "\n",
      "4‐gram 'towa' as PREFIX:\n",
      "  • towage → ge\n",
      "  (1 total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fourgram = []\n",
    "for i in most_common_fourgrams:\n",
    "    fourgram.append(i[0])\n",
    "\n",
    "# 3. Test a few common fourgrams\n",
    "get_common_affix(fourgram, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e6765",
   "metadata": {},
   "source": [
    "## Checking atomic morph with wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c0e6b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: suffix? True, prefix? True\n",
      "  examples suffix → ([('pa', 'paid'), ('b', 'bid'), ('ac', 'acid'), ('s', 'sid'), ('rash', 'rashid'), ('v', 'vid'), ('maj', 'majid'), ('sol', 'solid'), ('d', 'did'), ('wal', 'walid'), ('r', 'rid'), ('sa', 'said'), ('usa', 'usaid'), ('l', 'lid'), ('ar', 'arid'), ('ham', 'hamid'), ('had', 'hadid'), ('liv', 'livid'), ('metro', 'metroid'), ('qua', 'quaid'), ('ov', 'ovid'), ('k', 'kid'), ('re', 'reid'), ('ra', 'raid'), ('lip', 'lipid'), ('a', 'aid'), ('rab', 'rabid'), ('shah', 'shahid'), ('w', 'wid'), ('p', 'pid'), ('ma', 'maid'), ('flu', 'fluid'), ('pla', 'plaid'), ('m', 'mid'), ('sl', 'slid'), ('cov', 'covid'), ('la', 'laid'), ('av', 'avid'), ('e', 'eid'), ('qu', 'quid'), ('val', 'valid'), ('devo', 'devoid'), ('luc', 'lucid'), ('sk', 'skid'), ('medica', 'medicaid'), ('tim', 'timid'), ('bra', 'braid'), ('h', 'hid'), ('viv', 'vivid'), ('gr', 'grid'), ('rf', 'rfid'), ('dav', 'david'), ('hum', 'humid'), ('en', 'enid'), ('rap', 'rapid'), ('sta', 'staid'), ('far', 'farid'), ('cup', 'cupid'), ('vo', 'void'), ('dru', 'druid'), ('rig', 'rigid'), ('am', 'amid'), ('ib', 'ibid'), ('c', 'cid'), ('leon', 'leonid')],) \n",
      " 65 times\n",
      "  examples prefix → [('idly', 'ly'), ('ides', 'es'), ('idf', 'f'), ('idle', 'le'), ('idea', 'ea')] \n",
      " 19 times\n",
      "\n",
      "de: suffix? True, prefix? True\n",
      "  examples suffix → ([('hy', 'hyde'), ('ce', 'cede'), ('abi', 'abide'), ('ri', 'ride'), ('ry', 'ryde'), ('nu', 'nude'), ('dio', 'diode'), ('ba', 'bade'), ('tra', 'trade'), ('gar', 'garde'), ('gran', 'grande'), ('eva', 'evade'), ('abo', 'abode'), ('gra', 'grade'), ('ai', 'aide'), ('hor', 'horde'), ('sue', 'suede'), ('sha', 'shade'), ('hi', 'hide'), ('electro', 'electrode'), ('be', 'bede'), ('fa', 'fade'), ('lau', 'laude'), ('mo', 'mode'), ('k', 'kde'), ('sla', 'slade'), ('pri', 'pride'), ('no', 'node'), ('mon', 'monde'), ('lo', 'lode'), ('sta', 'stade'), ('ru', 'rude'), ('du', 'dude'), ('ju', 'jude'), ('vi', 'vide'), ('lor', 'lorde'), ('ma', 'made'), ('para', 'parade'), ('bri', 'bride'), ('rho', 'rhode'), ('con', 'conde'), ('cru', 'crude'), ('ja', 'jade'), ('gui', 'guide'), ('bo', 'bode'), ('wil', 'wilde'), ('da', 'dade'), ('serena', 'serenade'), ('de', 'dede'), ('wa', 'wade'), ('i', 'ide'), ('co', 'code'), ('ol', 'olde'), ('marina', 'marinade'), ('bi', 'bide'), ('ano', 'anode'), ('ver', 'verde'), ('lin', 'linde'), ('a', 'ade'), ('chara', 'charade'), ('si', 'side'), ('mea', 'meade'), ('asi', 'aside'), ('ca', 'cade'), ('ti', 'tide'), ('wi', 'wide'), ('rea', 'reade'), ('gla', 'glade'), ('mau', 'maude'), ('goo', 'goode'), ('sa', 'sade'), ('allen', 'allende'), ('deco', 'decode'), ('swe', 'swede'), ('bla', 'blade'), ('ro', 'rode'), ('spa', 'spade'), ('fi', 'fide'), ('o', 'ode')],) \n",
      " 79 times\n",
      "  examples prefix → [('deg', 'g'), ('deus', 'us'), ('deck', 'ck'), ('dead', 'ad'), ('deal', 'al')] \n",
      " 292 times\n",
      "\n",
      "ar: suffix? True, prefix? True\n",
      "  examples suffix → ([('son', 'sonar'), ('th', 'thar'), ('reb', 'rebar'), ('ge', 'gear'), ('d', 'dar'), ('fe', 'fear'), ('s', 'sar'), ('sam', 'samar'), ('she', 'shear'), ('line', 'linear'), ('bo', 'boar'), ('hag', 'hagar'), ('farr', 'farrar'), ('sol', 'solar'), ('tart', 'tartar'), ('k', 'kar'), ('mill', 'millar'), ('band', 'bandar'), ('l', 'lar'), ('um', 'umar'), ('sme', 'smear'), ('r', 'rar'), ('se', 'sear'), ('sag', 'sagar'), ('pix', 'pixar'), ('alt', 'altar'), ('doll', 'dollar'), ('coll', 'collar'), ('lid', 'lidar'), ('din', 'dinar'), ('ces', 'cesar'), ('sp', 'spar'), ('re', 'rear'), ('osc', 'oscar'), ('g', 'gar'), ('m', 'mar'), ('li', 'liar'), ('he', 'hear'), ('dew', 'dewar'), ('pol', 'polar'), ('c', 'car'), ('uncle', 'unclear'), ('shank', 'shankar'), ('f', 'far'), ('nag', 'nagar'), ('so', 'soar'), ('we', 'wear'), ('cle', 'clear'), ('ein', 'einar'), ('ag', 'agar'), ('bash', 'bashar'), ('plant', 'plantar'), ('mort', 'mortar'), ('y', 'yar'), ('de', 'dear'), ('dem', 'demar'), ('le', 'lear'), ('t', 'tar'), ('n', 'nar'), ('iv', 'ivar'), ('spe', 'spear'), ('w', 'war'), ('ro', 'roar'), ('ne', 'near'), ('af', 'afar'), ('cell', 'cellar'), ('lam', 'lamar'), ('aj', 'ajar'), ('cz', 'czar'), ('j', 'jar'), ('plan', 'planar'), ('am', 'amar'), ('pil', 'pilar'), ('vic', 'vicar'), ('bri', 'briar'), ('st', 'star'), ('om', 'omar'), ('p', 'par'), ('gunn', 'gunnar'), ('ans', 'ansar'), ('cig', 'cigar'), ('bigg', 'biggar'), ('te', 'tear'), ('consul', 'consular'), ('mol', 'molar'), ('ch', 'char'), ('rad', 'radar'), ('tam', 'tamar'), ('a', 'aar'), ('dak', 'dakar'), ('baz', 'bazar'), ('tat', 'tatar'), ('ye', 'year'), ('be', 'bear'), ('pill', 'pillar'), ('ts', 'tsar'), ('hang', 'hangar'), ('bab', 'babar'), ('pe', 'pear'), ('e', 'ear'), ('fri', 'friar'), ('swe', 'swear'), ('h', 'har'), ('v', 'var'), ('sc', 'scar'), ('o', 'oar'), ('sark', 'sarkar'), ('b', 'bar'), ('lun', 'lunar')],) \n",
      " 109 times\n",
      "  examples prefix → [('arbor', 'bor'), ('arrange', 'range'), ('arcade', 'cade'), ('aron', 'on'), ('arc', 'c')] \n",
      " 106 times\n",
      "\n",
      "er: suffix? True, prefix? True\n",
      "  examples suffix → ([('lean', 'leaner'), ('down', 'downer'), ('harsh', 'harsher'), ('bull', 'buller'), ('om', 'omer'), ('platt', 'platter'), ('supp', 'supper'), ('tam', 'tamer'), ('sprint', 'sprinter'), ('less', 'lesser'), ('zealand', 'zealander'), ('show', 'shower'), ('math', 'mather'), ('hill', 'hiller'), ('shiv', 'shiver'), ('coop', 'cooper'), ('rain', 'rainer'), ('common', 'commoner'), ('molest', 'molester'), ('fish', 'fisher'), ('jet', 'jeter'), ('click', 'clicker'), ('cater', 'caterer'), ('convert', 'converter'), ('respond', 'responder'), ('link', 'linker'), ('putt', 'putter'), ('foy', 'foyer'), ('found', 'founder'), ('work', 'worker'), ('sav', 'saver'), ('jewell', 'jeweller'), ('cid', 'cider'), ('pap', 'paper'), ('hat', 'hater'), ('bust', 'buster'), ('southern', 'southerner'), ('poop', 'pooper'), ('crush', 'crusher'), ('fest', 'fester'), ('palm', 'palmer'), ('eth', 'ether'), ('tas', 'taser'), ('barb', 'barber'), ('cod', 'coder'), ('hamburg', 'hamburger'), ('dumb', 'dumber'), ('creep', 'creeper'), ('webb', 'webber'), ('piet', 'pieter'), ('island', 'islander'), ('infield', 'infielder'), ('trawl', 'trawler'), ('bit', 'biter'), ('deep', 'deeper'), ('stroll', 'stroller'), ('coast', 'coaster'), ('geez', 'geezer'), ('s', 'ser'), ('help', 'helper'), ('clos', 'closer'), ('finish', 'finisher'), ('seat', 'seater'), ('sang', 'sanger'), ('weld', 'welder'), ('dim', 'dimer'), ('drink', 'drinker'), ('deck', 'decker'), ('sniff', 'sniffer'), ('min', 'miner'), ('cant', 'canter'), ('ste', 'steer'), ('execution', 'executioner'), ('oth', 'other'), ('join', 'joiner'), ('ch', 'cher'), ('pet', 'peter'), ('view', 'viewer'), ('clear', 'clearer'), ('herd', 'herder'), ('golf', 'golfer'), ('talk', 'talker'), ('gam', 'gamer'), ('papi', 'papier'), ('lead', 'leader'), ('amb', 'amber'), ('k', 'ker'), ('mang', 'manger'), ('gow', 'gower'), ('brew', 'brewer'), ('hack', 'hacker'), ('forrest', 'forrester'), ('hov', 'hover'), ('adjust', 'adjuster'), ('soft', 'softer'), ('moth', 'mother'), ('boost', 'booster'), ('butt', 'butter'), ('inn', 'inner'), ('numb', 'number'), ('bright', 'brighter'), ('open', 'opener'), ('trott', 'trotter'), ('install', 'installer'), ('fuck', 'fucker'), ('mean', 'meaner'), ('dream', 'dreamer'), ('export', 'exporter'), ('soon', 'sooner'), ('with', 'wither'), ('bark', 'barker'), ('mos', 'moser'), ('cricket', 'cricketer'), ('fly', 'flyer'), ('travel', 'traveler'), ('rein', 'reiner'), ('wank', 'wanker'), ('mah', 'maher'), ('javi', 'javier'), ('must', 'muster'), ('tig', 'tiger'), ('twist', 'twister'), ('tru', 'truer'), ('point', 'pointer'), ('punt', 'punter'), ('mull', 'muller'), ('narrow', 'narrower'), ('attack', 'attacker'), ('tim', 'timer'), ('xavi', 'xavier'), ('pick', 'picker'), ('wind', 'winder'), ('reef', 'reefer'), ('hunt', 'hunter'), ('outfield', 'outfielder'), ('near', 'nearer'), ('grind', 'grinder'), ('pay', 'payer'), ('nic', 'nicer'), ('cock', 'cocker'), ('ent', 'enter'), ('teach', 'teacher'), ('inform', 'informer'), ('lug', 'luger'), ('g', 'ger'), ('refresh', 'refresher'), ('foot', 'footer'), ('row', 'rower'), ('rac', 'racer'), ('sob', 'sober'), ('sink', 'sinker'), ('d', 'der'), ('sweet', 'sweeter'), ('proud', 'prouder'), ('send', 'sender'), ('still', 'stiller'), ('fold', 'folder'), ('holi', 'holier'), ('field', 'fielder'), ('bigg', 'bigger'), ('rid', 'rider'), ('watch', 'watcher'), ('borrow', 'borrower'), ('t', 'ter'), ('tink', 'tinker'), ('keel', 'keeler'), ('small', 'smaller'), ('gunn', 'gunner'), ('land', 'lander'), ('slid', 'slider'), ('add', 'adder'), ('flow', 'flower'), ('pull', 'puller'), ('ord', 'order'), ('fix', 'fixer'), ('wall', 'waller'), ('crawl', 'crawler'), ('troop', 'trooper'), ('bloom', 'bloomer'), ('gre', 'greer'), ('kerb', 'kerber'), ('scoot', 'scooter'), ('football', 'footballer'), ('labour', 'labourer'), ('de', 'deer'), ('forest', 'forester'), ('rout', 'router'), ('grand', 'grander'), ('lust', 'luster'), ('adapt', 'adapter'), ('pitch', 'pitcher'), ('def', 'defer'), ('lend', 'lender'), ('sing', 'singer'), ('bold', 'bolder'), ('holland', 'hollander'), ('fend', 'fender'), ('cool', 'cooler'), ('los', 'loser'), ('cook', 'cooker'), ('cast', 'caster'), ('rent', 'renter'), ('fry', 'fryer'), ('harvest', 'harvester'), ('bonn', 'bonner'), ('dock', 'docker'), ('raid', 'raider'), ('household', 'householder'), ('reform', 'reformer'), ('pac', 'pacer'), ('highlight', 'highlighter'), ('flick', 'flicker'), ('shear', 'shearer'), ('pretend', 'pretender'), ('walt', 'walter'), ('snip', 'sniper'), ('shallow', 'shallower'), ('ris', 'riser'), ('sting', 'stinger'), ('wild', 'wilder'), ('engine', 'engineer'), ('int', 'inter'), ('eat', 'eater'), ('prison', 'prisoner'), ('bowl', 'bowler'), ('div', 'diver'), ('drift', 'drifter'), ('feed', 'feeder'), ('bomb', 'bomber'), ('raft', 'rafter'), ('block', 'blocker'), ('lau', 'lauer'), ('chart', 'charter'), ('shin', 'shiner'), ('cat', 'cater'), ('j', 'jer'), ('adl', 'adler'), ('ald', 'alder'), ('witch', 'witcher'), ('wien', 'wiener'), ('bad', 'bader'), ('farm', 'farmer'), ('w', 'wer'), ('warn', 'warner'), ('boil', 'boiler'), ('box', 'boxer'), ('employ', 'employer'), ('falcon', 'falconer'), ('sign', 'signer'), ('keep', 'keeper'), ('remind', 'reminder'), ('contain', 'container'), ('extend', 'extender'), ('ranch', 'rancher'), ('review', 'reviewer'), ('clean', 'cleaner'), ('mong', 'monger'), ('sweat', 'sweater'), ('conceal', 'concealer'), ('my', 'myer'), ('float', 'floater'), ('hook', 'hooker'), ('dov', 'dover'), ('sick', 'sicker'), ('a', 'aer'), ('round', 'rounder'), ('highland', 'highlander'), ('com', 'comer'), ('green', 'greener'), ('support', 'supporter'), ('sau', 'sauer'), ('destroy', 'destroyer'), ('tenn', 'tenner'), ('young', 'younger'), ('tight', 'tighter'), ('whisk', 'whisker'), ('hub', 'huber'), ('cork', 'corker'), ('light', 'lighter'), ('great', 'greater'), ('be', 'beer'), ('mat', 'mater'), ('thrust', 'thruster'), ('ba', 'baer'), ('new', 'newer'), ('od', 'oder'), ('own', 'owner'), ('poach', 'poacher'), ('writ', 'writer'), ('condition', 'conditioner'), ('crock', 'crocker'), ('bleach', 'bleacher'), ('thick', 'thicker'), ('dorm', 'dormer'), ('form', 'former'), ('interpret', 'interpreter'), ('mist', 'mister'), ('didi', 'didier'), ('ham', 'hamer'), ('y', 'yer'), ('arch', 'archer'), ('h', 'her'), ('garb', 'garber'), ('invert', 'inverter'), ('heal', 'healer'), ('pleas', 'pleaser'), ('est', 'ester'), ('spray', 'sprayer'), ('jail', 'jailer'), ('tuck', 'tucker'), ('commission', 'commissioner'), ('bay', 'bayer'), ('tank', 'tanker'), ('rar', 'rarer'), ('lin', 'liner'), ('hark', 'harker'), ('high', 'higher'), ('meek', 'meeker'), ('labor', 'laborer'), ('ott', 'otter'), ('puff', 'puffer'), ('western', 'westerner'), ('bau', 'bauer'), ('sh', 'sher'), ('retail', 'retailer'), ('grad', 'grader'), ('rudd', 'rudder'), ('ball', 'baller'), ('mill', 'miller'), ('pe', 'peer'), ('shock', 'shocker'), ('ev', 'ever'), ('ung', 'unger'), ('find', 'finder'), ('track', 'tracker'), ('keen', 'keener'), ('lag', 'lager'), ('blatt', 'blatter'), ('desert', 'deserter'), ('pow', 'power'), ('ub', 'uber'), ('strain', 'strainer'), ('fill', 'filler'), ('straight', 'straighter'), ('post', 'poster'), ('usurp', 'usurper'), ('pension', 'pensioner'), ('hard', 'harder'), ('broad', 'broader'), ('roost', 'rooster'), ('vip', 'viper'), ('hab', 'haber'), ('skew', 'skewer'), ('build', 'builder'), ('sneak', 'sneaker'), ('ton', 'toner'), ('laud', 'lauder'), ('beat', 'beater'), ('kickstart', 'kickstarter'), ('vouch', 'voucher'), ('care', 'career'), ('ay', 'ayer'), ('bear', 'bearer'), ('redeem', 'redeemer'), ('cent', 'center'), ('fresh', 'fresher'), ('pag', 'pager'), ('walk', 'walker'), ('tough', 'tougher'), ('tweet', 'tweeter'), ('draw', 'drawer'), ('hoy', 'hoyer'), ('report', 'reporter'), ('night', 'nighter'), ('chest', 'chester'), ('wid', 'wider'), ('blast', 'blaster'), ('stretch', 'stretcher'), ('kiss', 'kisser'), ('hijack', 'hijacker'), ('merc', 'mercer'), ('conf', 'confer'), ('rik', 'riker'), ('loud', 'louder'), ('break', 'breaker'), ('ladd', 'ladder'), ('finch', 'fincher'), ('port', 'porter'), ('spe', 'speer'), ('climb', 'climber'), ('merci', 'mercier'), ('wag', 'wager'), ('blitz', 'blitzer'), ('go', 'goer'), ('beck', 'becker'), ('berg', 'berger'), ('quiet', 'quieter'), ('surf', 'surfer'), ('defend', 'defender'), ('am', 'amer'), ('ov', 'over'), ('weird', 'weirder'), ('mov', 'mover'), ('publish', 'publisher'), ('cream', 'creamer'), ('fasten', 'fastener'), ('listen', 'listener'), ('string', 'stringer'), ('breed', 'breeder'), ('beak', 'beaker'), ('hold', 'holder'), ('interview', 'interviewer'), ('heartbreak', 'heartbreaker'), ('dy', 'dyer'), ('warm', 'warmer'), ('low', 'lower'), ('start', 'starter'), ('trapp', 'trapper'), ('slow', 'slower'), ('me', 'meer'), ('behold', 'beholder'), ('speak', 'speaker'), ('mark', 'marker'), ('hang', 'hanger'), ('sew', 'sewer'), ('crowd', 'crowder'), ('reap', 'reaper'), ('strang', 'stranger'), ('lift', 'lifter'), ('sharp', 'sharper'), ('strict', 'stricter'), ('hung', 'hunger'), ('extinguish', 'extinguisher'), ('same', 'sameer'), ('steep', 'steeper'), ('fenn', 'fenner'), ('market', 'marketer'), ('murder', 'murderer'), ('diff', 'differ'), ('mei', 'meier'), ('play', 'player'), ('firm', 'firmer'), ('pound', 'pounder'), ('elm', 'elmer'), ('spoon', 'spooner'), ('smelt', 'smelter'), ('rock', 'rocker'), ('paint', 'painter'), ('tow', 'tower'), ('load', 'loader'), ('stiff', 'stiffer'), ('tun', 'tuner'), ('dup', 'duper'), ('nev', 'never'), ('rough', 'rougher'), ('matt', 'matter'), ('calm', 'calmer'), ('truck', 'trucker'), ('mis', 'miser'), ('quart', 'quarter'), ('kick', 'kicker'), ('cram', 'cramer'), ('mix', 'mixer'), ('halt', 'halter'), ('command', 'commander'), ('repeat', 'repeater'), ('bo', 'boer'), ('york', 'yorker'), ('contend', 'contender'), ('us', 'user'), ('stalk', 'stalker'), ('sab', 'saber'), ('scrap', 'scraper'), ('din', 'diner'), ('thrill', 'thriller'), ('test', 'tester'), ('jewel', 'jeweler'), ('east', 'easter'), ('b', 'ber'), ('pars', 'parser'), ('prim', 'primer'), ('fib', 'fiber'), ('ash', 'asher'), ('se', 'seer'), ('bend', 'bender'), ('count', 'counter'), ('jest', 'jester'), ('heath', 'heather'), ('train', 'trainer'), ('smooth', 'smoother'), ('wat', 'water'), ('kidd', 'kidder'), ('batt', 'batter'), ('spoil', 'spoiler'), ('flank', 'flanker'), ('digg', 'digger'), ('pest', 'pester'), ('wing', 'winger'), ('cow', 'cower'), ('aft', 'after'), ('inf', 'infer'), ('messi', 'messier'), ('lay', 'layer'), ('fab', 'faber'), ('lang', 'langer'), ('butch', 'butcher'), ('wait', 'waiter'), ('tend', 'tender'), ('widow', 'widower'), ('saf', 'safer'), ('haus', 'hauser'), ('design', 'designer'), ('orbit', 'orbiter'), ('aug', 'auger'), ('berlin', 'berliner'), ('tak', 'taker'), ('v', 'ver'), ('loos', 'looser'), ('ac', 'acer'), ('rush', 'rusher'), ('slack', 'slacker'), ('bon', 'boner'), ('tick', 'ticker'), ('pray', 'prayer'), ('horn', 'horner'), ('fre', 'freer'), ('fin', 'finer'), ('backpack', 'backpacker'), ('boom', 'boomer'), ('solid', 'solider'), ('kohl', 'kohler'), ('black', 'blacker'), ('mail', 'mailer'), ('hamm', 'hammer'), ('rapp', 'rapper'), ('gross', 'grosser'), ('cap', 'caper'), ('litt', 'litter'), ('alt', 'alter'), ('rang', 'ranger'), ('suck', 'sucker'), ('wear', 'wearer'), ('jenn', 'jenner'), ('full', 'fuller'), ('mak', 'maker'), ('sweep', 'sweeper'), ('pi', 'pier'), ('short', 'shorter'), ('splint', 'splinter'), ('las', 'laser'), ('comfort', 'comforter'), ('chas', 'chaser'), ('school', 'schooler'), ('trail', 'trailer'), ('sleep', 'sleeper'), ('hall', 'haller'), ('well', 'weller'), ('print', 'printer'), ('rug', 'ruger'), ('freight', 'freighter'), ('fad', 'fader'), ('dress', 'dresser'), ('jump', 'jumper'), ('tap', 'taper'), ('neu', 'neuer'), ('wander', 'wanderer'), ('bows', 'bowser'), ('fell', 'feller'), ('marin', 'mariner'), ('sinn', 'sinner'), ('she', 'sheer'), ('turn', 'turner'), ('and', 'ander'), ('rich', 'richer'), ('staff', 'staffer'), ('hatch', 'hatcher'), ('bey', 'beyer'), ('poor', 'poorer'), ('retain', 'retainer'), ('cart', 'carter'), ('met', 'meter'), ('ell', 'eller'), ('lon', 'loner'), ('beam', 'beamer'), ('seal', 'sealer'), ('sold', 'solder'), ('think', 'thinker'), ('perform', 'performer'), ('suffer', 'sufferer'), ('teas', 'teaser'), ('offend', 'offender'), ('chang', 'changer'), ('camp', 'camper'), ('scream', 'screamer'), ('strong', 'stronger'), ('pass', 'passer'), ('thay', 'thayer'), ('fowl', 'fowler'), ('krug', 'kruger'), ('both', 'bother'), ('stick', 'sticker'), ('wheel', 'wheeler'), ('ski', 'skier'), ('le', 'leer'), ('quick', 'quicker'), ('cheat', 'cheater'), ('roll', 'roller'), ('wis', 'wiser'), ('pos', 'poser'), ('transport', 'transporter'), ('sweeten', 'sweetener'), ('prop', 'proper'), ('earn', 'earner'), ('follow', 'follower'), ('back', 'backer'), ('cold', 'colder'), ('whit', 'whiter'), ('slash', 'slasher'), ('th', 'ther'), ('slay', 'slayer'), ('spring', 'springer'), ('press', 'presser'), ('pip', 'piper'), ('bak', 'baker'), ('entertain', 'entertainer'), ('spread', 'spreader'), ('pal', 'paler'), ('trad', 'trader'), ('absorb', 'absorber'), ('adopt', 'adopter'), ('kissing', 'kissinger'), ('spend', 'spender'), ('may', 'mayer'), ('que', 'queer'), ('photograph', 'photographer'), ('diet', 'dieter'), ('swing', 'swinger'), ('sell', 'seller'), ('nad', 'nader'), ('list', 'lister'), ('dry', 'dryer'), ('blow', 'blower'), ('task', 'tasker'), ('kind', 'kinder'), ('lav', 'laver'), ('tri', 'trier'), ('terri', 'terrier'), ('out', 'outer'), ('gaff', 'gaffer'), ('broth', 'brother'), ('shad', 'shader'), ('car', 'carer'), ('throw', 'thrower'), ('sup', 'super'), ('dri', 'drier'), ('trumpet', 'trumpeter'), ('lock', 'locker'), ('crack', 'cracker'), ('det', 'deter'), ('lib', 'liber'), ('import', 'importer'), ('beech', 'beecher'), ('transform', 'transformer'), ('lit', 'liter'), ('book', 'booker'), ('fast', 'faster'), ('web', 'weber'), ('few', 'fewer'), ('blend', 'blender'), ('thrash', 'thrasher'), ('grub', 'gruber'), ('wick', 'wicker'), ('read', 'reader'), ('launch', 'launcher'), ('broadcast', 'broadcaster'), ('present', 'presenter'), ('bank', 'banker'), ('und', 'under'), ('leak', 'leaker'), ('liv', 'liver'), ('off', 'offer'), ('corn', 'corner'), ('discover', 'discoverer'), ('fam', 'famer'), ('comment', 'commenter'), ('leg', 'leger'), ('ang', 'anger'), ('burg', 'burger'), ('gather', 'gatherer'), ('damp', 'damper'), ('grow', 'grower'), ('hawk', 'hawker'), ('seek', 'seeker'), ('frankfurt', 'frankfurter'), ('wash', 'washer'), ('bart', 'barter'), ('dwell', 'dweller'), ('petition', 'petitioner'), ('wand', 'wander'), ('smart', 'smarter'), ('tat', 'tater'), ('pack', 'packer'), ('ref', 'refer'), ('mow', 'mower'), ('n', 'ner'), ('conn', 'conner'), ('heat', 'heater'), ('midfield', 'midfielder'), ('mild', 'milder'), ('hell', 'heller'), ('custom', 'customer'), ('ti', 'tier'), ('cleans', 'cleanser'), ('should', 'shoulder'), ('end', 'ender'), ('lest', 'lester'), ('ling', 'linger'), ('brows', 'browser'), ('mai', 'maier'), ('whisper', 'whisperer'), ('call', 'caller'), ('kemp', 'kemper'), ('burn', 'burner'), ('wreck', 'wrecker'), ('wip', 'wiper'), ('recruit', 'recruiter'), ('p', 'per'), ('shift', 'shifter'), ('garden', 'gardener'), ('mutt', 'mutter'), ('record', 'recorder'), ('weak', 'weaker'), ('buy', 'buyer'), ('tell', 'teller'), ('sand', 'sander'), ('head', 'header'), ('ring', 'ringer'), ('charm', 'charmer'), ('protest', 'protester'), ('bunk', 'bunker'), ('dispatch', 'dispatcher'), ('bump', 'bumper'), ('fight', 'fighter'), ('deal', 'dealer'), ('f', 'fer'), ('mess', 'messer'), ('resell', 'reseller'), ('research', 'researcher'), ('mann', 'manner'), ('tub', 'tuber'), ('steam', 'steamer'), ('firefight', 'firefighter'), ('tall', 'taller'), ('kill', 'killer'), ('m', 'mer'), ('breath', 'breather'), ('hoard', 'hoarder'), ('abn', 'abner'), ('dens', 'denser'), ('till', 'tiller'), ('park', 'parker'), ('cov', 'cover'), ('buzz', 'buzzer'), ('lat', 'later'), ('shoot', 'shooter'), ('foreign', 'foreigner'), ('ast', 'aster'), ('nutt', 'nutter'), ('push', 'pusher'), ('hand', 'hander'), ('board', 'boarder'), ('dark', 'darker'), ('plant', 'planter'), ('fair', 'fairer'), ('learn', 'learner'), ('boy', 'boyer'), ('dust', 'duster'), ('cheap', 'cheaper'), ('dang', 'danger'), ('old', 'older'), ('buff', 'buffer'), ('wav', 'waver'), ('iv', 'iver'), ('lev', 'lever'), ('stream', 'streamer'), ('salt', 'salter'), ('bang', 'banger'), ('hind', 'hinder'), ('long', 'longer'), ('temp', 'temper'), ('thatch', 'thatcher'), ('hom', 'homer'), ('ve', 'veer'), ('bow', 'bower'), ('hoop', 'hooper'), ('kitchen', 'kitchener'), ('plumb', 'plumber'), ('stein', 'steiner'), ('rath', 'rather'), ('platform', 'platformer'), ('kell', 'keller'), ('toast', 'toaster'), ('cut', 'cuter'), ('campaign', 'campaigner'), ('thi', 'thier'), ('brain', 'brainer'), ('che', 'cheer'), ('preach', 'preacher'), ('eras', 'eraser'), ('oust', 'ouster'), ('christoph', 'christopher'), ('develop', 'developer'), ('punish', 'punisher'), ('harp', 'harper'), ('ruck', 'rucker'), ('pint', 'pinter'), ('winn', 'winner'), ('pond', 'ponder'), ('do', 'doer'), ('rog', 'roger'), ('check', 'checker'), ('bind', 'binder'), ('catch', 'catcher'), ('mast', 'master'), ('robb', 'robber')],) \n",
      " 825 times\n",
      "  examples prefix → [('ere', 'e'), ('err', 'r'), ('ernest', 'nest'), ('eras', 'as'), ('erm', 'm')] \n",
      " 29 times\n",
      "\n",
      "on: suffix? True, prefix? True\n",
      "  examples suffix → ([('gibb', 'gibbon'), ('m', 'mon'), ('js', 'json'), ('add', 'addon'), ('carb', 'carbon'), ('p', 'pon'), ('tr', 'tron'), ('po', 'poon'), ('ar', 'aron'), ('johns', 'johnson'), ('land', 'landon'), ('sanders', 'sanderson'), ('al', 'alon'), ('men', 'menon'), ('tend', 'tendon'), ('bent', 'benton'), ('piers', 'pierson'), ('steps', 'stepson'), ('ors', 'orson'), ('rec', 'recon'), ('walt', 'walton'), ('dutt', 'dutton'), ('apr', 'apron'), ('cond', 'condon'), ('k', 'kon'), ('xe', 'xeon'), ('ir', 'iron'), ('coup', 'coupon'), ('illuminati', 'illumination'), ('mo', 'moon'), ('hens', 'henson'), ('ode', 'odeon'), ('ther', 'theron'), ('clint', 'clinton'), ('calder', 'calderon'), ('mac', 'macon'), ('mari', 'marion'), ('ars', 'arson'), ('felt', 'felton'), ('eg', 'egon'), ('si', 'sion'), ('ellis', 'ellison'), ('comm', 'common'), ('eds', 'edson'), ('av', 'avon'), ('grands', 'grandson'), ('e', 'eon'), ('col', 'colon'), ('berger', 'bergeron'), ('aeg', 'aegon'), ('gods', 'godson'), ('cray', 'crayon'), ('tet', 'teton'), ('rip', 'ripon'), ('trent', 'trenton'), ('taunt', 'taunton'), ('n', 'non'), ('hilt', 'hilton'), ('ye', 'yeon'), ('up', 'upon'), ('s', 'son'), ('man', 'manon'), ('bac', 'bacon'), ('ic', 'icon'), ('dam', 'damon'), ('bos', 'boson'), ('drago', 'dragoon'), ('fel', 'felon'), ('oni', 'onion'), ('jens', 'jenson'), ('yang', 'yangon'), ('overt', 'overton'), ('mais', 'maison'), ('brett', 'bretton'), ('newt', 'newton'), ('gall', 'gallon'), ('wag', 'wagon'), ('mass', 'masson'), ('dem', 'demon'), ('am', 'amon'), ('yo', 'yoon'), ('i', 'ion'), ('jacobs', 'jacobson'), ('tim', 'timon'), ('graft', 'grafton'), ('rent', 'renton'), ('y', 'yon'), ('sams', 'samson'), ('woods', 'woodson'), ('kw', 'kwon'), ('pers', 'person'), ('mans', 'manson'), ('addis', 'addison'), ('marl', 'marlon'), ('robs', 'robson'), ('bart', 'barton'), ('j', 'jon'), ('richards', 'richardson'), ('bor', 'boron'), ('melt', 'melton'), ('less', 'lesson'), ('rad', 'radon'), ('brand', 'brandon'), ('dill', 'dillon'), ('ex', 'exon'), ('drag', 'dragon'), ('di', 'dion'), ('ast', 'aston'), ('hint', 'hinton'), ('kent', 'kenton'), ('surge', 'surgeon'), ('roberts', 'robertson'), ('dent', 'denton'), ('an', 'anon'), ('jays', 'jayson'), ('quint', 'quinton'), ('stevens', 'stevenson'), ('buff', 'buffon'), ('act', 'acton'), ('harris', 'harrison'), ('luz', 'luzon'), ('fall', 'fallon'), ('cars', 'carson'), ('el', 'elon'), ('ae', 'aeon'), ('h', 'hon'), ('fergus', 'ferguson'), ('colt', 'colton'), ('unis', 'unison'), ('dicks', 'dickson'), ('sci', 'scion'), ('bo', 'boon'), ('butt', 'button'), ('hendricks', 'hendrickson'), ('dev', 'devon'), ('masters', 'masterson'), ('mas', 'mason'), ('sim', 'simon'), ('lars', 'larson'), ('cm', 'cmon'), ('uni', 'union'), ('group', 'groupon'), ('ho', 'hoon'), ('pat', 'paton'), ('clarks', 'clarkson'), ('ec', 'econ'), ('vern', 'vernon'), ('west', 'weston'), ('holt', 'holton'), ('no', 'noon'), ('ga', 'gaon'), ('harm', 'harmon'), ('list', 'liston'), ('plato', 'platoon'), ('w', 'won'), ('morris', 'morrison'), ('c', 'con'), ('hans', 'hanson'), ('hutchins', 'hutchinson'), ('prot', 'proton'), ('nix', 'nixon'), ('brit', 'briton'), ('g', 'gon'), ('bat', 'baton'), ('burt', 'burton'), ('go', 'goon'), ('britt', 'britton'), ('there', 'thereon'), ('set', 'seton'), ('seas', 'season'), ('loud', 'loudon'), ('jacks', 'jackson'), ('want', 'wanton'), ('ori', 'orion'), ('jas', 'jason'), ('ant', 'anton'), ('domini', 'dominion'), ('fut', 'futon'), ('jo', 'joon'), ('br', 'bron'), ('mel', 'melon'), ('cord', 'cordon'), ('davis', 'davison'), ('milli', 'million'), ('singlet', 'singleton'), ('wilt', 'wilton'), ('nichols', 'nicholson'), ('eps', 'epson'), ('adams', 'adamson'), ('atkins', 'atkinson'), ('peters', 'peterson'), ('cart', 'carton'), ('ne', 'neon'), ('james', 'jameson'), ('her', 'heron'), ('alt', 'alton'), ('anders', 'anderson'), ('je', 'jeon'), ('mah', 'mahon'), ('robins', 'robinson'), ('hur', 'huron'), ('jeffers', 'jefferson'), ('bis', 'bison'), ('bolt', 'bolton'), ('wilkins', 'wilkinson'), ('sax', 'saxon'), ('heat', 'heaton'), ('shim', 'shimon'), ('bar', 'baron'), ('grays', 'grayson'), ('bright', 'brighton'), ('pauls', 'paulson'), ('ball', 'ballon'), ('pars', 'parson'), ('car', 'caron'), ('can', 'canon'), ('weld', 'weldon'), ('edmonds', 'edmondson'), ('east', 'easton'), ('et', 'eton'), ('b', 'bon'), ('v', 'von'), ('so', 'soon'), ('r', 'ron'), ('gab', 'gabon'), ('davids', 'davidson'), ('lo', 'loon'), ('do', 'doon'), ('ani', 'anion'), ('hutt', 'hutton'), ('swans', 'swanson'), ('co', 'coon'), ('ray', 'rayon'), ('ly', 'lyon'), ('sal', 'salon'), ('denis', 'denison'), ('part', 'parton'), ('th', 'thon'), ('laws', 'lawson'), ('lem', 'lemon'), ('ans', 'anson'), ('t', 'ton'), ('mutt', 'mutton'), ('rest', 'reston'), ('milt', 'milton'), ('mini', 'minion'), ('brought', 'broughton'), ('to', 'toon'), ('mort', 'morton'), ('aar', 'aaron'), ('seat', 'seaton'), ('lint', 'linton'), ('sol', 'solon'), ('mor', 'moron'), ('coco', 'cocoon'), ('dix', 'dixon'), ('lago', 'lagoon'), ('l', 'lon'), ('beat', 'beaton'), ('the', 'theon'), ('nik', 'nikon'), ('wheat', 'wheaton'), ('tal', 'talon'), ('pears', 'pearson'), ('le', 'leon'), ('ti', 'tion'), ('cant', 'canton'), ('ram', 'ramon'), ('yuk', 'yukon'), ('stephens', 'stephenson'), ('li', 'lion'), ('d', 'don'), ('eat', 'eaton'), ('ax', 'axon'), ('williams', 'williamson'), ('bret', 'breton'), ('dennis', 'dennison'), ('barr', 'barron'), ('zi', 'zion'), ('arg', 'argon'), ('ox', 'oxon'), ('rat', 'raton')],) \n",
      " 282 times\n",
      "  examples prefix → [('onscreen', 'screen'), ('onward', 'ward'), ('oni', 'i'), ('onto', 'to'), ('onus', 'us')] \n",
      " 27 times\n",
      "\n",
      "si: suffix? True, prefix? True\n",
      "  examples suffix → ([('tut', 'tutsi'), ('i', 'isi'), ('mes', 'messi'), ('o', 'osi'), ('d', 'dsi'), ('far', 'farsi'), ('p', 'psi'), ('qua', 'quasi'), ('pep', 'pepsi'), ('ros', 'rossi'), ('si', 'sisi'), ('m', 'msi'), ('sta', 'stasi'), ('de', 'desi'), ('na', 'nasi'), ('c', 'csi'), ('h', 'hsi'), ('sc', 'scsi'), ('s', 'ssi'), ('a', 'asi'), ('mor', 'morsi'), ('an', 'ansi'), ('r', 'rsi')],) \n",
      " 23 times\n",
      "  examples prefix → [('sil', 'l'), ('silas', 'las'), ('siesta', 'esta'), ('sid', 'd'), ('sited', 'ted')] \n",
      " 80 times\n",
      "\n",
      "ea: suffix? True, prefix? True\n",
      "  examples suffix → ([('corn', 'cornea'), ('f', 'fea'), ('n', 'nea'), ('i', 'iea'), ('t', 'tea'), ('med', 'medea'), ('c', 'cea'), ('corr', 'correa'), ('id', 'idea'), ('w', 'wea'), ('h', 'hea'), ('kor', 'korea'), ('jud', 'judea'), ('s', 'sea'), ('ur', 'urea'), ('fl', 'flea'), ('th', 'thea'), ('e', 'eea'), ('r', 'rea'), ('l', 'lea'), ('pl', 'plea'), ('m', 'mea'), ('b', 'bea'), ('hos', 'hosea'), ('ar', 'area'), ('swans', 'swansea'), ('p', 'pea'), ('sh', 'shea'), ('batters', 'battersea'), ('ia', 'iaea'), ('crim', 'crimea'), ('d', 'dea'), ('rh', 'rhea'), ('br', 'brea'), ('y', 'yea'), ('g', 'gea'), ('ik', 'ikea')],) \n",
      " 37 times\n",
      "  examples prefix → [('ealing', 'ling'), ('early', 'rly'), ('eased', 'sed'), ('eas', 's'), ('easy', 'sy')] \n",
      " 30 times\n",
      "\n",
      "to: suffix? True, prefix? True\n",
      "  examples suffix → ([('hither', 'hitherto'), ('sa', 'sato'), ('tan', 'tanto'), ('chris', 'christo'), ('be', 'beto'), ('sai', 'saito'), ('to', 'toto'), ('yama', 'yamato'), ('on', 'onto'), ('e', 'eto'), ('pro', 'proto'), ('dit', 'ditto'), ('a', 'ato'), ('toma', 'tomato'), ('vi', 'vito'), ('go', 'goto'), ('gus', 'gusto'), ('ti', 'tito'), ('so', 'soto'), ('beni', 'benito'), ('nie', 'nieto'), ('un', 'unto'), ('na', 'nato'), ('ben', 'bento'), ('rena', 'renato'), ('g', 'gto'), ('up', 'upto'), ('p', 'pto'), ('ton', 'tonto'), ('mo', 'moto'), ('mako', 'makoto'), ('san', 'santo'), ('ka', 'kato'), ('kan', 'kanto'), ('ama', 'amato'), ('fac', 'facto'), ('shin', 'shinto'), ('lot', 'lotto'), ('pho', 'photo'), ('ca', 'cato'), ('c', 'cto'), ('mot', 'motto'), ('i', 'ito'), ('le', 'leto'), ('pes', 'pesto'), ('pres', 'presto'), ('pin', 'pinto'), ('pla', 'plato'), ('al', 'alto'), ('cris', 'cristo'), ('por', 'porto'), ('modes', 'modesto'), ('s', 'sto'), ('ke', 'keto'), ('au', 'auto'), ('w', 'wto'), ('kyo', 'kyoto'), ('ve', 'veto'), ('in', 'into'), ('ot', 'otto'), ('tin', 'tinto'), ('can', 'canto'), ('qui', 'quito'), ('devi', 'devito'), ('there', 'thereto')],) \n",
      " 65 times\n",
      "  examples prefix → [('told', 'ld'), ('toma', 'ma'), ('tomorrow', 'morrow'), ('today', 'day'), ('toning', 'ning')] \n",
      " 124 times\n",
      "\n",
      "in: suffix? True, prefix? True\n",
      "  examples suffix → ([('tint', 'tintin'), ('roll', 'rollin'), ('sla', 'slain'), ('start', 'startin'), ('bev', 'bevin'), ('bullet', 'bulletin'), ('fall', 'fallin'), ('ja', 'jain'), ('h', 'hin'), ('cum', 'cumin'), ('mak', 'makin'), ('sat', 'satin'), ('freak', 'freakin'), ('puff', 'puffin'), ('f', 'fin'), ('ra', 'rain'), ('frick', 'frickin'), ('marl', 'marlin'), ('cry', 'cryin'), ('album', 'albumin'), ('qu', 'quin'), ('tra', 'train'), ('aga', 'again'), ('col', 'colin'), ('gra', 'grain'), ('tur', 'turin'), ('watch', 'watchin'), ('mar', 'marin'), ('roma', 'romain'), ('park', 'parkin'), ('sk', 'skin'), ('ga', 'gain'), ('ka', 'kain'), ('ron', 'ronin'), ('tripp', 'trippin'), ('log', 'login'), ('la', 'lain'), ('villa', 'villain'), ('pa', 'pain'), ('feel', 'feelin'), ('jump', 'jumpin'), ('with', 'within'), ('ia', 'iain'), ('pal', 'palin'), ('dunk', 'dunkin'), ('y', 'yin'), ('hold', 'holdin'), ('od', 'odin'), ('blow', 'blowin'), ('salad', 'saladin'), ('v', 'vin'), ('liv', 'livin'), ('gr', 'grin'), ('d', 'din'), ('aust', 'austin'), ('putt', 'puttin'), ('mess', 'messin'), ('west', 'westin'), ('rank', 'rankin'), ('here', 'herein'), ('sav', 'savin'), ('sar', 'sarin'), ('sing', 'singin'), ('tonk', 'tonkin'), ('t', 'tin'), ('rab', 'rabin'), ('adrenal', 'adrenalin'), ('ball', 'ballin'), ('god', 'godin'), ('cook', 'cookin'), ('see', 'seein'), ('hav', 'havin'), ('there', 'therein'), ('lew', 'lewin'), ('ben', 'benin'), ('ak', 'akin'), ('arm', 'armin'), ('say', 'sayin'), ('griff', 'griffin'), ('walk', 'walkin'), ('keep', 'keepin'), ('w', 'win'), ('eat', 'eatin'), ('ala', 'alain'), ('jo', 'join'), ('l', 'lin'), ('r', 'rin'), ('rob', 'robin'), ('ol', 'olin'), ('dolph', 'dolphin'), ('where', 'wherein'), ('bra', 'brain'), ('carl', 'carlin'), ('chill', 'chillin'), ('fight', 'fightin'), ('ma', 'main'), ('ste', 'stein'), ('sta', 'stain'), ('marv', 'marvin'), ('constant', 'constantin'), ('eo', 'eoin'), ('p', 'pin'), ('kick', 'kickin'), ('go', 'goin'), ('ask', 'askin'), ('twa', 'twain'), ('coll', 'collin'), ('k', 'kin'), ('usa', 'usain'), ('hero', 'heroin'), ('sp', 'spin'), ('tell', 'tellin'), ('check', 'checkin'), ('lev', 'levin'), ('kill', 'killin'), ('pla', 'plain'), ('rock', 'rockin'), ('re', 'rein'), ('ca', 'cain'), ('len', 'lenin'), ('irv', 'irvin'), ('terra', 'terrain'), ('thor', 'thorin'), ('j', 'jin'), ('sh', 'shin'), ('call', 'callin'), ('com', 'comin'), ('tw', 'twin'), ('er', 'erin'), ('morn', 'mornin'), ('rusk', 'ruskin'), ('pull', 'pullin'), ('mal', 'malin'), ('mor', 'morin'), ('za', 'zain'), ('se', 'sein'), ('b', 'bin'), ('g', 'gin'), ('dust', 'dustin'), ('put', 'putin'), ('m', 'min'), ('lat', 'latin'), ('ha', 'hain'), ('think', 'thinkin'), ('n', 'nin'), ('play', 'playin'), ('orr', 'orrin'), ('cha', 'chain'), ('lora', 'lorain'), ('try', 'tryin'), ('linked', 'linkedin'), ('kev', 'kevin'), ('va', 'vain'), ('chop', 'chopin'), ('spa', 'spain'), ('fe', 'fein'), ('be', 'bein'), ('gro', 'groin'), ('bask', 'baskin'), ('s', 'sin'), ('res', 'resin'), ('drink', 'drinkin'), ('work', 'workin'), ('me', 'mein'), ('lark', 'larkin'), ('look', 'lookin'), ('hang', 'hangin'), ('he', 'hein'), ('curt', 'curtin'), ('ve', 'vein'), ('talk', 'talkin'), ('marg', 'margin'), ('beg', 'begin'), ('break', 'breakin'), ('em', 'emin'), ('michel', 'michelin'), ('ly', 'lyin'), ('stay', 'stayin'), ('august', 'augustin'), ('atta', 'attain'), ('ed', 'edin'), ('cab', 'cabin'), ('rid', 'ridin'), ('shoot', 'shootin'), ('link', 'linkin'), ('a', 'ain'), ('co', 'coin'), ('bas', 'basin'), ('dar', 'darin'), ('orig', 'origin'), ('dev', 'devin'), ('tak', 'takin'), ('mart', 'martin'), ('th', 'thin'), ('e', 'ein'), ('muff', 'muffin'), ('bitch', 'bitchin'), ('chap', 'chapin'), ('anton', 'antonin'), ('hard', 'hardin'), ('wait', 'waitin'), ('plug', 'plugin'), ('lo', 'loin'), ('crisp', 'crispin'), ('anak', 'anakin'), ('ba', 'bain'), ('rub', 'rubin'), ('act', 'actin'), ('ru', 'ruin'), ('do', 'doin'), ('just', 'justin'), ('q', 'qin'), ('x', 'xin'), ('c', 'cin'), ('br', 'brin'), ('rod', 'rodin'), ('fuck', 'fuckin'), ('am', 'amin'), ('ch', 'chin'), ('kar', 'karin'), ('adm', 'admin'), ('mov', 'movin')],) \n",
      " 222 times\n",
      "  examples prefix → [('infrequently', 'frequently'), ('injustice', 'justice'), ('inflows', 'flows'), ('instill', 'still'), ('inequity', 'equity')] \n",
      " 324 times\n",
      "\n",
      "be: suffix? True, prefix? True\n",
      "  examples suffix → ([('m', 'mbe'), ('vi', 'vibe'), ('pro', 'probe'), ('ro', 'robe'), ('tri', 'tribe'), ('ado', 'adobe'), ('micro', 'microbe'), ('bri', 'bribe'), ('be', 'bebe'), ('a', 'abe'), ('tu', 'tube'), ('ga', 'gabe'), ('ru', 'rube'), ('lo', 'lobe'), ('t', 'tbe'), ('ba', 'babe'), ('c', 'cbe'), ('lu', 'lube'), ('cu', 'cube'), ('bee', 'beebe'), ('wanna', 'wannabe'), ('uri', 'uribe'), ('glo', 'globe'), ('ko', 'kobe'), ('to', 'tobe'), ('may', 'maybe'), ('o', 'obe')],) \n",
      " 27 times\n",
      "  examples prefix → [('beef', 'ef'), ('beal', 'al'), ('beit', 'it'), ('bevin', 'vin'), ('best', 'st')] \n",
      " 143 times\n",
      "\n",
      "th: suffix? True, prefix? True\n",
      "  examples suffix → ([('eleven', 'eleventh'), ('wye', 'wyeth'), ('boo', 'booth'), ('eighteen', 'eighteenth'), ('kei', 'keith'), ('sixteen', 'sixteenth'), ('my', 'myth'), ('mou', 'mouth'), ('edi', 'edith'), ('bir', 'birth'), ('wid', 'width'), ('ro', 'roth'), ('o', 'oth'), ('four', 'fourth'), ('7', '7th'), ('8', '8th'), ('go', 'goth'), ('heal', 'health'), ('pa', 'path'), ('n', 'nth'), ('nea', 'neath'), ('dar', 'darth'), ('wi', 'with'), ('loa', 'loath'), ('nineteen', 'nineteenth'), ('bar', 'barth'), ('fir', 'firth'), ('bro', 'broth'), ('dea', 'death'), ('wir', 'wirth'), ('shea', 'sheath'), ('fro', 'froth'), ('seventeen', 'seventeenth'), ('brea', 'breath'), ('bo', 'both'), ('4', '4th'), ('lei', 'leith'), ('steal', 'stealth'), ('ca', 'cath'), ('gar', 'garth'), ('me', 'meth'), ('ha', 'hath'), ('lili', 'lilith'), ('au', 'auth'), ('bread', 'breadth'), ('oa', 'oath'), ('a', 'ath'), ('seven', 'seventh'), ('na', 'nath'), ('hundred', 'hundredth'), ('thirteen', 'thirteenth'), ('tru', 'truth'), ('six', 'sixth'), ('si', 'sith'), ('gare', 'gareth'), ('bly', 'blyth'), ('you', 'youth'), ('ra', 'rath'), ('sou', 'south'), ('6', '6th'), ('ka', 'kath'), ('mea', 'meath'), ('fifteen', 'fifteenth'), ('mo', 'moth'), ('hadi', 'hadith'), ('warm', 'warmth'), ('fourteen', 'fourteenth'), ('ber', 'berth'), ('nor', 'north'), ('s', 'sth'), ('outgrow', 'outgrowth'), ('fai', 'faith'), ('se', 'seth'), ('mon', 'month'), ('5', '5th'), ('ba', 'bath'), ('come', 'cometh'), ('dear', 'dearth'), ('ma', 'math'), ('ru', 'ruth'), ('wor', 'worth'), ('clo', 'cloth'), ('fil', 'filth'), ('tee', 'teeth'), ('hear', 'hearth'), ('hea', 'heath'), ('w', 'wth'), ('syn', 'synth'), ('million', 'millionth'), ('grow', 'growth'), ('nin', 'ninth'), ('for', 'forth'), ('do', 'doth'), ('dep', 'depth'), ('fri', 'frith'), ('ear', 'earth'), ('sai', 'saith'), ('per', 'perth'), ('slo', 'sloth'), ('to', 'toth'), ('e', 'eth'), ('judi', 'judith'), ('mir', 'mirth'), ('ten', 'tenth'), ('be', 'beth'), ('i', 'ith'), ('too', 'tooth'), ('give', 'giveth'), ('9', '9th')],) \n",
      " 109 times\n",
      "  examples prefix → [('three', 'ree'), ('theft', 'eft'), ('thrice', 'rice'), ('tho', 'o'), ('things', 'ings')] \n",
      " 94 times\n",
      "\n",
      "en: suffix? True, prefix? True\n",
      "  examples suffix → ([('gard', 'garden'), ('hal', 'halen'), ('kitt', 'kitten'), ('rav', 'raven'), ('silk', 'silken'), ('tak', 'taken'), ('deep', 'deepen'), ('ov', 'oven'), ('lik', 'liken'), ('niels', 'nielsen'), ('te', 'teen'), ('yu', 'yuen'), ('cull', 'cullen'), ('lind', 'linden'), ('om', 'omen'), ('c', 'cen'), ('sv', 'sven'), ('ste', 'steen'), ('chick', 'chicken'), ('all', 'allen'), ('hsi', 'hsien'), ('hel', 'helen'), ('fuck', 'fucken'), ('frank', 'franken'), ('orig', 'origen'), ('lin', 'linen'), ('wid', 'widen'), ('th', 'then'), ('ox', 'oxen'), ('fast', 'fasten'), ('aud', 'auden'), ('behold', 'beholden'), ('cov', 'coven'), ('stat', 'staten'), ('m', 'men'), ('cord', 'corden'), ('wald', 'walden'), ('f', 'fen'), ('wool', 'woolen'), ('ev', 'even'), ('weak', 'weaken'), ('ell', 'ellen'), ('sunk', 'sunken'), ('ca', 'caen'), ('brad', 'braden'), ('robb', 'robben'), ('aust', 'austen'), ('ew', 'ewen'), ('christ', 'christen'), ('hast', 'hasten'), ('thick', 'thicken'), ('y', 'yen'), ('or', 'oren'), ('she', 'sheen'), ('fresh', 'freshen'), ('wi', 'wien'), ('r', 'ren'), ('rog', 'rogen'), ('ros', 'rosen'), ('h', 'hen'), ('barr', 'barren'), ('d', 'den'), ('s', 'sen'), ('ess', 'essen'), ('ad', 'aden'), ('liv', 'liven'), ('loos', 'loosen'), ('rub', 'ruben'), ('jens', 'jensen'), ('sharp', 'sharpen'), ('drunk', 'drunken'), ('gall', 'gallen'), ('height', 'heighten'), ('g', 'gen'), ('lum', 'lumen'), ('wr', 'wren'), ('yell', 'yellen'), ('jal', 'jalen'), ('ar', 'aren'), ('vivi', 'vivien'), ('list', 'listen'), ('threat', 'threaten'), ('steph', 'stephen'), ('glut', 'gluten'), ('bad', 'baden'), ('less', 'lessen'), ('co', 'coen'), ('be', 'been'), ('britt', 'britten'), ('ram', 'ramen'), ('zh', 'zhen'), ('j', 'jen'), ('wood', 'wooden'), ('w', 'wen'), ('tok', 'token'), ('oft', 'often'), ('ti', 'tien'), ('juli', 'julien'), ('de', 'deen'), ('straight', 'straighten'), ('bur', 'buren'), ('kam', 'kamen'), ('gosh', 'goshen'), ('batt', 'batten'), ('e', 'een'), ('sweet', 'sweeten'), ('bi', 'bien'), ('mull', 'mullen'), ('hans', 'hansen'), ('asp', 'aspen'), ('pauls', 'paulsen'), ('fall', 'fallen'), ('quick', 'quicken'), ('op', 'open'), ('hold', 'holden'), ('dore', 'doreen'), ('had', 'haden'), ('tough', 'toughen'), ('gl', 'glen'), ('dark', 'darken'), ('b', 'ben'), ('er', 'eren'), ('li', 'lien'), ('hav', 'haven'), ('bod', 'boden'), ('heath', 'heathen'), ('bright', 'brighten'), ('ald', 'alden'), ('sor', 'soren'), ('sir', 'siren'), ('witt', 'witten'), ('p', 'pen'), ('gre', 'green'), ('sh', 'shen'), ('earth', 'earthen'), ('wok', 'woken'), ('z', 'zen'), ('gold', 'golden'), ('lad', 'laden'), ('light', 'lighten'), ('short', 'shorten'), ('hard', 'harden'), ('berg', 'bergen'), ('aid', 'aiden'), ('eb', 'eben'), ('seam', 'seamen'), ('gal', 'galen'), ('t', 'ten'), ('mort', 'morten'), ('k', 'ken'), ('kar', 'karen'), ('ke', 'keen'), ('br', 'bren'), ('ow', 'owen'), ('deutsch', 'deutschen'), ('cow', 'cowen'), ('ris', 'risen'), ('poll', 'pollen'), ('mart', 'marten'), ('old', 'olden'), ('vix', 'vixen'), ('length', 'lengthen'), ('damp', 'dampen'), ('se', 'seen'), ('lars', 'larsen'), ('v', 'ven'), ('soft', 'soften'), ('mads', 'madsen'), ('anders', 'andersen'), ('ed', 'eden'), ('hag', 'hagen'), ('que', 'queen'), ('fright', 'frighten'), ('sem', 'semen'), ('tight', 'tighten'), ('ward', 'warden'), ('peters', 'petersen'), ('lor', 'loren'), ('wh', 'when'), ('ali', 'alien'), ('maid', 'maiden'), ('chi', 'chien'), ('ard', 'arden'), ('rip', 'ripen'), ('gw', 'gwen'), ('beat', 'beaten'), ('jacobs', 'jacobsen'), ('ch', 'chen'), ('gott', 'gotten'), ('am', 'amen'), ('strength', 'strengthen'), ('aris', 'arisen'), ('ibs', 'ibsen'), ('prov', 'proven'), ('eat', 'eaten'), ('l', 'len'), ('shrunk', 'shrunken'), ('bid', 'biden'), ('bow', 'bowen'), ('broad', 'broaden')],) \n",
      " 200 times\n",
      "  examples prefix → [('enchanting', 'chanting'), ('encircled', 'circled'), ('encode', 'code'), ('entrusted', 'trusted'), ('enix', 'ix')] \n",
      " 114 times\n",
      "\n",
      "nd: suffix? True, prefix? True\n",
      "  examples suffix → ([('dura', 'durand'), ('se', 'send'), ('sta', 'stand'), ('ame', 'amend'), ('fo', 'fond'), ('fie', 'fiend'), ('spe', 'spend'), ('d', 'dnd'), ('po', 'pond'), ('fu', 'fund'), ('liga', 'ligand'), ('ha', 'hand'), ('ki', 'kind'), ('mou', 'mound'), ('ra', 'rand'), ('ble', 'blend'), ('bola', 'boland'), ('gra', 'grand'), ('e', 'end'), ('a', 'and'), ('ba', 'band'), ('hou', 'hound'), ('fe', 'fend'), ('te', 'tend'), ('tre', 'trend'), ('conte', 'contend'), ('me', 'mend'), ('la', 'land'), ('arma', 'armand'), ('le', 'lend'), ('holla', 'holland'), ('divide', 'dividend'), ('bridge', 'bridgend'), ('bra', 'brand'), ('be', 'bend'), ('comma', 'command'), ('i', 'ind'), ('bla', 'bland'), ('u', 'und'), ('si', 'sind'), ('hi', 'hind'), ('isla', 'island'), ('bi', 'bind'), ('abou', 'abound'), ('revere', 'reverend'), ('li', 'lind'), ('week', 'weeknd'), ('bu', 'bund'), ('sou', 'sound'), ('co', 'cond'), ('wi', 'wind'), ('na', 'nand'), ('bou', 'bound'), ('wa', 'wand'), ('sa', 'sand'), ('remi', 'remind'), ('cha', 'chand'), ('comme', 'commend'), ('fou', 'found'), ('2', '2nd'), ('lu', 'lund'), ('ber', 'bernd'), ('s', 'snd'), ('bo', 'bond'), ('mi', 'mind'), ('ana', 'anand'), ('fi', 'find'), ('stipe', 'stipend'), ('ri', 'rind'), ('gla', 'gland')],) \n",
      " 70 times\n",
      "  examples prefix → [('nda', 'a'), ('ndc', 'c'), ('ndtv', 'tv'), ('ndp', 'p')] \n",
      " 4 times\n",
      "\n",
      "ou: suffix? True, prefix? True\n",
      "  examples suffix → ([('n', 'nou'), ('angel', 'angelou'), ('ab', 'abou'), ('ch', 'chou'), ('bay', 'bayou'), ('b', 'bou'), ('l', 'lou'), ('s', 'sou'), ('y', 'you'), ('sh', 'shou'), ('c', 'cou'), ('d', 'dou'), ('t', 'tou'), ('v', 'vou'), ('zh', 'zhou'), ('h', 'hou'), ('f', 'fou'), ('m', 'mou'), ('th', 'thou')],) \n",
      " 19 times\n",
      "  examples prefix → [('oui', 'i'), ('ours', 'rs'), ('ouch', 'ch'), ('ousting', 'sting'), ('ould', 'ld')] \n",
      " 12 times\n",
      "\n",
      "st: suffix? True, prefix? True\n",
      "  examples suffix → ([('strange', 'strangest'), ('te', 'test'), ('na', 'nast'), ('be', 'best'), ('simple', 'simplest'), ('puri', 'purist'), ('ze', 'zest'), ('ju', 'just'), ('cute', 'cutest'), ('p', 'pst'), ('pa', 'past'), ('among', 'amongst'), ('d', 'dst'), ('ho', 'host'), ('ha', 'hast'), ('h', 'hst'), ('repo', 'repost'), ('ni', 'nist'), ('wai', 'waist'), ('que', 'quest'), ('tru', 'trust'), ('ae', 'aest'), ('con', 'const'), ('olde', 'oldest'), ('ru', 'rust'), ('true', 'truest'), ('inge', 'ingest'), ('conte', 'contest'), ('cy', 'cyst'), ('little', 'littlest'), ('hur', 'hurst'), ('faire', 'fairest'), ('ince', 'incest'), ('bea', 'beast'), ('ne', 'nest'), ('g', 'gst'), ('c', 'cst'), ('m', 'mst'), ('pe', 'pest'), ('mid', 'midst'), ('cru', 'crust'), ('s', 'sst'), ('au', 'aust'), ('li', 'list'), ('ve', 'vest'), ('di', 'dist'), ('o', 'ost'), ('wide', 'widest'), ('lo', 'lost'), ('contra', 'contrast'), ('do', 'dost'), ('gi', 'gist'), ('mi', 'mist'), ('hone', 'honest'), ('dive', 'divest'), ('moi', 'moist'), ('provo', 'provost'), ('co', 'cost'), ('hei', 'heist'), ('boo', 'boost'), ('ea', 'east'), ('u', 'ust'), ('lu', 'lust'), ('sharpe', 'sharpest'), ('fa', 'fast'), ('l', 'lst'), ('safe', 'safest'), ('roa', 'roast'), ('la', 'last'), ('again', 'against'), ('fierce', 'fiercest'), ('amid', 'amidst'), ('brave', 'bravest'), ('ca', 'cast'), ('fea', 'feast'), ('du', 'dust'), ('ang', 'angst'), ('1', '1st'), ('sure', 'surest'), ('ps', 'psst'), ('jihadi', 'jihadist'), ('try', 'tryst'), ('in', 'inst'), ('bu', 'bust'), ('ma', 'mast'), ('wor', 'worst'), ('re', 'rest'), ('wise', 'wisest'), ('mari', 'marist'), ('nice', 'nicest'), ('le', 'lest'), ('large', 'largest'), ('lowe', 'lowest'), ('b', 'bst'), ('gu', 'gust'), ('hor', 'horst'), ('coa', 'coast'), ('mu', 'must'), ('pro', 'prost'), ('hi', 'hist'), ('thicke', 'thickest'), ('cre', 'crest'), ('ou', 'oust'), ('we', 'west'), ('che', 'chest'), ('bur', 'burst'), ('fine', 'finest'), ('yea', 'yeast'), ('late', 'latest'), ('fe', 'fest'), ('rare', 'rarest'), ('ba', 'bast'), ('boa', 'boast'), ('bla', 'blast'), ('lea', 'least'), ('i', 'ist'), ('tempe', 'tempest'), ('desi', 'desist'), ('a', 'ast'), ('pure', 'purest'), ('va', 'vast'), ('close', 'closest'), ('sincere', 'sincerest'), ('e', 'est'), ('wilde', 'wildest'), ('fore', 'forest'), ('as', 'asst'), ('po', 'post'), ('fro', 'frost'), ('mole', 'molest'), ('toa', 'toast'), ('hear', 'hearst'), ('mo', 'most'), ('mode', 'modest'), ('fir', 'first'), ('thru', 'thrust'), ('dur', 'durst'), ('hoi', 'hoist'), ('roo', 'roost'), ('grande', 'grandest'), ('brea', 'breast'), ('je', 'jest'), ('cri', 'crist'), ('fi', 'fist'), ('yo', 'yost')],) \n",
      " 145 times\n",
      "  examples prefix → [('strangers', 'rangers'), ('stamp', 'amp'), ('stand', 'and'), ('strings', 'rings'), ('stubs', 'ubs')] \n",
      " 182 times\n",
      "\n",
      "ro: suffix? True, prefix? True\n",
      "  examples suffix → ([('ag', 'agro'), ('ichi', 'ichiro'), ('mun', 'munro'), ('ta', 'taro'), ('hi', 'hiro'), ('spi', 'spiro'), ('csi', 'csiro'), ('fer', 'ferro'), ('gi', 'giro'), ('ae', 'aero'), ('pie', 'piero'), ('guerre', 'guerrero'), ('elect', 'electro'), ('ret', 'retro'), ('c', 'cro'), ('aust', 'austro'), ('pet', 'petro'), ('sombre', 'sombrero'), ('bo', 'boro'), ('af', 'afro'), ('cast', 'castro'), ('mac', 'macro'), ('tru', 'truro'), ('mi', 'miro'), ('pe', 'pero'), ('a', 'aro'), ('gop', 'gopro'), ('out', 'outro'), ('piet', 'pietro'), ('mic', 'micro'), ('mau', 'mauro'), ('fa', 'faro'), ('rome', 'romero'), ('ni', 'niro'), ('ve', 'vero'), ('shi', 'shiro'), ('ze', 'zero'), ('ute', 'utero'), ('to', 'toro'), ('cent', 'centro'), ('g', 'gro'), ('eu', 'euro'), ('o', 'oro'), ('ped', 'pedro'), ('pot', 'potro'), ('alva', 'alvaro'), ('neg', 'negro'), ('met', 'metro'), ('sand', 'sandro'), ('int', 'intro'), ('f', 'fro'), ('ast', 'astro'), ('nit', 'nitro'), ('ne', 'nero'), ('th', 'thro'), ('he', 'hero'), ('gy', 'gyro'), ('p', 'pro'), ('ca', 'caro'), ('b', 'bro'), ('neu', 'neuro'), ('cai', 'cairo'), ('py', 'pyro'), ('vit', 'vitro'), ('mo', 'moro'), ('monte', 'montero')],) \n",
      " 66 times\n",
      "  examples prefix → [('rovers', 'vers'), ('roof', 'of'), ('roth', 'th'), ('roald', 'ald'), ('rock', 'ck')] \n",
      " 144 times\n",
      "\n",
      "ne: suffix? True, prefix? True\n",
      "  examples suffix → ([('dia', 'diane'), ('kai', 'kaine'), ('cra', 'crane'), ('malo', 'malone'), ('forego', 'foregone'), ('argon', 'argonne'), ('ni', 'nine'), ('ire', 'irene'), ('pla', 'plane'), ('marian', 'marianne'), ('bor', 'borne'), ('pi', 'pine'), ('sho', 'shone'), ('to', 'tone'), ('thro', 'throne'), ('tow', 'towne'), ('thor', 'thorne'), ('keto', 'ketone'), ('ho', 'hone'), ('ina', 'inane'), ('medici', 'medicine'), ('maxi', 'maxine'), ('laver', 'laverne'), ('hor', 'horne'), ('pai', 'paine'), ('capo', 'capone'), ('ber', 'berne'), ('sto', 'stone'), ('bo', 'bone'), ('ne', 'nene'), ('overdo', 'overdone'), ('ac', 'acne'), ('an', 'anne'), ('tu', 'tune'), ('lean', 'leanne'), ('vivien', 'vivienne'), ('rai', 'raine'), ('alo', 'alone'), ('pho', 'phone'), ('outdo', 'outdone'), ('ravi', 'ravine'), ('noo', 'noone'), ('kristi', 'kristine'), ('jay', 'jayne'), ('co', 'cone'), ('joan', 'joanne'), ('levi', 'levine'), ('way', 'wayne'), ('war', 'warne'), ('boo', 'boone'), ('mar', 'marne'), ('sha', 'shane'), ('pro', 'prone'), ('shi', 'shine'), ('uri', 'urine'), ('dun', 'dunne'), ('no', 'none'), ('lay', 'layne'), ('marti', 'martine'), ('cli', 'cline'), ('susan', 'susanne'), ('falco', 'falcone'), ('ka', 'kane'), ('mi', 'mine'), ('ca', 'cane'), ('dion', 'dionne'), ('do', 'done'), ('ba', 'bane'), ('sa', 'sane'), ('la', 'lane'), ('brow', 'browne'), ('ja', 'jane'), ('za', 'zane'), ('sco', 'scone'), ('a', 'ane'), ('i', 'ine'), ('u', 'une'), ('vi', 'vine'), ('redo', 'redone'), ('devi', 'devine'), ('fi', 'fine'), ('pauli', 'pauline'), ('bon', 'bonne'), ('li', 'line'), ('hay', 'hayne'), ('pu', 'pune'), ('e', 'ene'), ('go', 'gone'), ('lai', 'laine'), ('re', 'rene'), ('condo', 'condone'), ('so', 'sone'), ('wi', 'wine'), ('clo', 'clone'), ('wa', 'wane'), ('thi', 'thine'), ('leo', 'leone'), ('cro', 'crone'), ('delphi', 'delphine'), ('christi', 'christine'), ('bri', 'brine'), ('da', 'dane'), ('jean', 'jeanne'), ('lor', 'lorne'), ('ami', 'amine'), ('tha', 'thane'), ('ci', 'cine'), ('coy', 'coyne'), ('ver', 'verne'), ('dua', 'duane'), ('car', 'carne'), ('spi', 'spine'), ('shay', 'shayne'), ('arse', 'arsene'), ('ma', 'mane'), ('mil', 'milne'), ('may', 'mayne'), ('julian', 'julianne'), ('ru', 'rune'), ('cai', 'caine'), ('o', 'one'), ('kee', 'keene'), ('be', 'bene'), ('rho', 'rhone'), ('mari', 'marine'), ('ar', 'arne'), ('ge', 'gene'), ('hei', 'heine'), ('undo', 'undone'), ('ale', 'alene'), ('ty', 'tyne'), ('ju', 'june'), ('sei', 'seine'), ('aria', 'ariane'), ('du', 'dune'), ('ali', 'aline'), ('ti', 'tine'), ('shri', 'shrine'), ('pa', 'pane'), ('pay', 'payne'), ('adrien', 'adrienne'), ('di', 'dine'), ('alkali', 'alkaline'), ('undergo', 'undergone'), ('dea', 'deane'), ('lyn', 'lynne'), ('seri', 'serine'), ('don', 'donne'), ('ton', 'tonne'), ('dian', 'dianne'), ('si', 'sine'), ('ato', 'atone'), ('huma', 'humane'), ('ei', 'eine'), ('zo', 'zone'), ('zi', 'zine'), ('mai', 'maine'), ('va', 'vane'), ('lo', 'lone')],) \n",
      " 159 times\n",
      "  examples prefix → [('nep', 'p'), ('nem', 'm'), ('news', 'ws'), ('newest', 'west'), ('negated', 'gated')] \n",
      " 77 times\n",
      "\n",
      "nt: suffix? True, prefix? True\n",
      "  examples suffix → ([('could', 'couldnt'), ('bu', 'bunt'), ('shu', 'shunt'), ('has', 'hasnt'), ('were', 'werent'), ('pa', 'pant'), ('adhere', 'adherent'), ('compete', 'competent'), ('di', 'dint'), ('late', 'latent'), ('adama', 'adamant'), ('reside', 'resident'), ('mi', 'mint'), ('e', 'ent'), ('age', 'agent'), ('tau', 'taunt'), ('cli', 'clint'), ('converge', 'convergent'), ('tyra', 'tyrant'), ('re', 'rent'), ('ste', 'stent'), ('was', 'wasnt'), ('conte', 'content'), ('solve', 'solvent'), ('fai', 'faint'), ('do', 'dont'), ('lear', 'learnt'), ('reminisce', 'reminiscent'), ('hi', 'hint'), ('is', 'isnt'), ('have', 'havent'), ('would', 'wouldnt'), ('gia', 'giant'), ('bra', 'brant'), ('eve', 'event'), ('ra', 'rant'), ('se', 'sent'), ('prude', 'prudent'), ('pe', 'pent'), ('precede', 'precedent'), ('ka', 'kant'), ('vince', 'vincent'), ('dura', 'durant'), ('sla', 'slant'), ('wo', 'wont'), ('torre', 'torrent'), ('sa', 'sant'), ('stu', 'stunt'), ('sca', 'scant'), ('stride', 'strident'), ('mo', 'mont'), ('cha', 'chant'), ('rode', 'rodent'), ('regime', 'regiment'), ('blu', 'blunt'), ('cu', 'cunt'), ('flue', 'fluent'), ('i', 'int'), ('t', 'tnt'), ('ava', 'avant'), ('insta', 'instant'), ('pate', 'patent'), ('me', 'ment'), ('w', 'wnt'), ('hydra', 'hydrant'), ('au', 'aunt'), ('preside', 'president'), ('fro', 'front'), ('qua', 'quant'), ('be', 'bent'), ('pu', 'punt'), ('confide', 'confident'), ('we', 'went'), ('bur', 'burnt'), ('vaca', 'vacant'), ('ke', 'kent'), ('diverge', 'divergent'), ('fonda', 'fondant'), ('ce', 'cent'), ('pi', 'pint'), ('did', 'didnt'), ('ca', 'cant'), ('decade', 'decadent'), ('pri', 'print'), ('should', 'shouldnt'), ('tre', 'trent'), ('pai', 'paint'), ('te', 'tent'), ('fo', 'font'), ('gru', 'grunt'), ('luce', 'lucent'), ('emerge', 'emergent'), ('tale', 'talent'), ('gra', 'grant'), ('spe', 'spent'), ('le', 'lent'), ('urge', 'urgent'), ('pare', 'parent'), ('lame', 'lament'), ('does', 'doesnt'), ('o', 'ont'), ('sai', 'saint'), ('wa', 'want'), ('ai', 'aint'), ('hu', 'hunt'), ('c', 'cnt'), ('li', 'lint'), ('indulge', 'indulgent'), ('ga', 'gant'), ('cove', 'covent'), ('provide', 'provident'), ('po', 'pont'), ('cou', 'count'), ('a', 'ant'), ('are', 'arent'), ('u', 'unt'), ('poi', 'point'), ('de', 'dent'), ('bru', 'brunt'), ('qui', 'quint'), ('ge', 'gent'), ('co', 'cont'), ('sti', 'stint'), ('pla', 'plant'), ('ti', 'tint'), ('comme', 'comment'), ('tai', 'taint'), ('mou', 'mount'), ('ve', 'vent'), ('mea', 'meant')],) \n",
      " 130 times\n",
      "  examples prefix → [('nth', 'h'), ('ntsb', 'sb'), ('nta', 'a'), ('ntsc', 'sc'), ('nts', 's')] \n",
      " 5 times\n",
      "\n",
      "or: suffix? True, prefix? True\n",
      "  examples suffix → ([('arb', 'arbor'), ('demean', 'demeanor'), ('k', 'kor'), ('f', 'for'), ('pry', 'pryor'), ('n', 'nor'), ('debt', 'debtor'), ('audit', 'auditor'), ('train', 'trainor'), ('connect', 'connector'), ('hum', 'humor'), ('l', 'lor'), ('reflect', 'reflector'), ('assess', 'assessor'), ('j', 'jor'), ('convey', 'conveyor'), ('elect', 'elector'), ('no', 'noor'), ('edit', 'editor'), ('sav', 'savor'), ('sand', 'sandor'), ('invent', 'inventor'), ('ig', 'igor'), ('sign', 'signor'), ('b', 'bor'), ('success', 'successor'), ('council', 'councilor'), ('do', 'door'), ('compress', 'compressor'), ('effect', 'effector'), ('arm', 'armor'), ('govern', 'governor'), ('mot', 'motor'), ('inject', 'injector'), ('may', 'mayor'), ('fav', 'favor'), ('lab', 'labor'), ('bang', 'bangor'), ('col', 'color'), ('greg', 'gregor'), ('indo', 'indoor'), ('construct', 'constructor'), ('tim', 'timor'), ('m', 'mor'), ('tab', 'tabor'), ('tut', 'tutor'), ('suit', 'suitor'), ('intercept', 'interceptor'), ('th', 'thor'), ('man', 'manor'), ('credit', 'creditor'), ('conn', 'connor'), ('counsel', 'counselor'), ('c', 'cor'), ('auth', 'author'), ('ten', 'tenor'), ('stat', 'stator'), ('iv', 'ivor'), ('p', 'por'), ('invest', 'investor'), ('di', 'dior'), ('prospect', 'prospector'), ('gat', 'gator'), ('lib', 'libor'), ('po', 'poor'), ('err', 'error'), ('fl', 'flor'), ('select', 'selector'), ('d', 'dor'), ('vo', 'voor'), ('con', 'conor'), ('sculpt', 'sculptor'), ('predict', 'predictor'), ('defect', 'defector'), ('dec', 'decor'), ('past', 'pastor'), ('contract', 'contractor'), ('flo', 'floor'), ('sect', 'sector'), ('tum', 'tumor'), ('pri', 'prior'), ('don', 'donor'), ('oppress', 'oppressor'), ('h', 'hor'), ('vis', 'visor'), ('profess', 'professor'), ('nest', 'nestor'), ('resist', 'resistor'), ('trait', 'traitor'), ('joh', 'johor'), ('extract', 'extractor'), ('conquer', 'conqueror'), ('lux', 'luxor'), ('winds', 'windsor'), ('od', 'odor'), ('accept', 'acceptor'), ('act', 'actor'), ('visit', 'visitor'), ('conduct', 'conductor'), ('solicit', 'solicitor'), ('ment', 'mentor'), ('tens', 'tensor'), ('inhibit', 'inhibitor'), ('hod', 'hodor'), ('s', 'sor'), ('adapt', 'adaptor'), ('rum', 'rumor'), ('v', 'vor'), ('cant', 'cantor'), ('collect', 'collector'), ('survey', 'surveyor'), ('direct', 'director'), ('val', 'valor'), ('tract', 'tractor'), ('outdo', 'outdoor'), ('sail', 'sailor'), ('capt', 'captor'), ('tail', 'tailor'), ('suppress', 'suppressor'), ('possess', 'possessor'), ('confess', 'confessor'), ('mo', 'moor'), ('t', 'tor'), ('sens', 'sensor'), ('project', 'projector'), ('clam', 'clamor'), ('am', 'amor'), ('min', 'minor'), ('g', 'gor'), ('hon', 'honor'), ('rig', 'rigor'), ('exhibit', 'exhibitor'), ('fed', 'fedor'), ('process', 'processor'), ('protect', 'protector'), ('maj', 'major'), ('ast', 'astor'), ('cond', 'condor'), ('cast', 'castor'), ('instruct', 'instructor'), ('fact', 'factor'), ('rot', 'rotor'), ('react', 'reactor'), ('inspect', 'inspector'), ('gab', 'gabor'), ('sen', 'senor'), ('detect', 'detector'), ('w', 'wor')],) \n",
      " 148 times\n",
      "  examples prefix → [('orc', 'c'), ('orson', 'son'), ('orlando', 'lando'), ('oregon', 'egon'), ('orange', 'ange')] \n",
      " 47 times\n",
      "\n",
      "ac: suffix? True, prefix? True\n",
      "  examples suffix → ([('j', 'jac'), ('n', 'nac'), ('r', 'rac'), ('cardi', 'cardiac'), ('z', 'zac'), ('br', 'brac'), ('w', 'wac'), ('lil', 'lilac'), ('iss', 'issac'), ('b', 'bac'), ('v', 'vac'), ('mani', 'maniac'), ('e', 'eac'), ('s', 'sac'), ('p', 'pac'), ('c', 'cac'), ('isa', 'isaac'), ('m', 'mac'), ('dir', 'dirac'), ('anz', 'anzac'), ('t', 'tac'), ('a', 'aac'), ('l', 'lac'), ('f', 'fac'), ('d', 'dac'), ('shell', 'shellac'), ('im', 'imac'), ('i', 'iac'), ('hv', 'hvac')],) \n",
      " 29 times\n",
      "  examples prefix → [('accredited', 'credited'), ('ache', 'he'), ('ach', 'h'), ('acid', 'id'), ('acl', 'l')] \n",
      " 61 times\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# Example: using wordfreq to test “xy” as a suffix or prefix\n",
    "# -----------------------------------------------\n",
    "\n",
    "from wordfreq import top_n_list\n",
    "\n",
    "def find_suffix_pairs_wordfreq(ngram, top_n=50000):\n",
    "    ngram = ngram.lower()\n",
    "    words = top_n_list(\"en\", n=top_n)\n",
    "    wordset = set(w.lower() for w in words)\n",
    "    pairs = []\n",
    "    for w in wordset:\n",
    "        if w.endswith(ngram) and len(w) > len(ngram):\n",
    "            base = w[:-len(ngram)]\n",
    "            if base in wordset:\n",
    "                pairs.append((base, w))\n",
    "    # return both the matching pairs and the total count\n",
    "    return pairs, \n",
    "\n",
    "def find_prefix_pairs_wordfreq(ngram, top_n=50000):\n",
    "    ngram = ngram.lower()\n",
    "    words = top_n_list(\"en\", n=top_n)\n",
    "    wordset = set(w.lower() for w in words)\n",
    "    pairs = []\n",
    "    count_w = 0\n",
    "    for w in wordset:\n",
    "        if w.startswith(ngram) and len(w) > len(ngram):\n",
    "            base = w[len(ngram):]\n",
    "            if base in wordset:\n",
    "                pairs.append((w, base))\n",
    "    return pairs\n",
    "\n",
    "def is_valid_suffix_wordfreq(ngram, top_n=50000):\n",
    "    return bool(find_suffix_pairs_wordfreq(ngram, top_n=top_n))\n",
    "\n",
    "def is_valid_prefix_wordfreq(ngram, top_n=50000):\n",
    "    return bool(find_prefix_pairs_wordfreq(ngram, top_n=top_n))\n",
    "\n",
    "def affix_validity_wordfreq(ngram, top_n=50000):\n",
    "    \"\"\"\n",
    "    Returns a dict with booleans for suffix and prefix productivity.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"suffix\": is_valid_suffix_wordfreq(ngram, top_n),\n",
    "        \"prefix\": is_valid_prefix_wordfreq(ngram, top_n)\n",
    "    }\n",
    "\n",
    "# 3. Test a few common bigrams:\n",
    "for bg in bigram:\n",
    "    val = affix_validity_wordfreq(bg, top_n=50000)\n",
    "    print(f\"{bg}: suffix? {val['suffix']}, prefix? {val['prefix']}\")\n",
    "    if val['suffix']:\n",
    "        print(f\"  examples suffix → {find_suffix_pairs_wordfreq(bg)[:1]} \\n {len(find_suffix_pairs_wordfreq(bg)[0])} times\")\n",
    "    if val['prefix']:\n",
    "        print(f\"  examples prefix → {find_prefix_pairs_wordfreq(bg)[:5]} \\n {len(find_prefix_pairs_wordfreq(bg))} times\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea132c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1753822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4aabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
