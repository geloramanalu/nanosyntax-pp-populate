{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eef0c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/glora/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from nltk.grammar import CFG, Nonterminal, Production\n",
    "from nltk.parse import EarleyChartParser\n",
    "# nltk.download('averaged_perceptron_tagger')  \n",
    "nltk.download('averaged_perceptron_tagger_eng')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8934ae",
   "metadata": {},
   "source": [
    "# Derivative Decomposition of Complex Prepositional Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ab47b",
   "metadata": {},
   "source": [
    "## Step 1: initialize master lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1c446a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_pp_lexicon = {}\n",
    "# Populate from atomic_p.json: Iterate through every entry in atomic_p.json. For each preposition (e.g., \"behind\"), add it as a key to master_lexicon and its full feature object as the value.\n",
    "with open('pp_lexicon/atomic_p.json', 'r') as f:\n",
    "    atomic_p = json.load(f)\n",
    "    for preposition, features in atomic_p.items():\n",
    "        master_pp_lexicon[preposition] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "522f4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate from p_lexicon.json: Iterate through every entry in p_lexicon.json.\n",
    "# for each key, value pair if the key already exists in master_lexicon, overwrite the value with the new value from p_lexicon.json.\n",
    "with open('pp_lexicon/p_lexicon.json', 'r') as f:\n",
    "    p_lexicon = json.load(f)\n",
    "    for preposition, features in p_lexicon.items():\n",
    "        if preposition in master_pp_lexicon:\n",
    "            master_pp_lexicon[preposition] = features\n",
    "        else:\n",
    "            master_pp_lexicon[preposition] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "644b165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_pp_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc253361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['behind', 'above', 'below', 'beyond', 'in front of', 'inside', 'outside', 'left', 'right', 'against', 'among', 'beside', 'between', 'near', 'next to', 'upon', 'across', 'along', 'around', 'over', 'past', 'through', 'under', 'up', 'down', 'on', 'off', 'in', 'out', 'away', 'top', 'astride', 'corner', 'by', 'edge', 'after', 'but', 'end', 'for', 'base', 'higher', 'high', 'bottom', 'via', 'back', 'at', 'astern', 'following', 'center', 'prior', 'front', 'before', 'opposite', 'from', 'beneath', 'with', 'rear', 'apart', 'next', 'side', 'of', 'far', 'amid', 'skin', 'flank', 'part', 'to', 'board', 'surface', 'a', 'amidst', 'middle', 'rim', 'face', 'close', 'core', 'foot', 'subsequent', 'heart'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_pp_lexicon.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d3c32",
   "metadata": {},
   "source": [
    "## Step 2: add complex preposition list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d29bfd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp_wordnet = pd.read_csv('dictionaries/pp_wordnet_dict_wiki_pop_fix.csv', sep=',')\n",
    "pp_wordnet_wiki = list(df_pp_wordnet['preposition'])\n",
    "# # drop nan in pp_wordnet_wiki\n",
    "pp_wordnet_wiki = [x for x in pp_wordnet_wiki if x is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe699622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_pp_list = []\n",
    "# check pp_wordnet_wiki against master_pp_lexicon keys\n",
    "for preposition in pp_wordnet_wiki:\n",
    "    if preposition not in master_pp_lexicon:\n",
    "        complex_pp_list.append(preposition)\n",
    "\n",
    "# remove nan type() float in complex_pp_list\n",
    "complex_pp_list = [x for x in complex_pp_list if type(x) is str]\n",
    "complex_pp_list = list(set(complex_pp_list))  # remove duplicates\n",
    "complex_pp_list.sort()\n",
    "len(complex_pp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b6624fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# add empty p_lexicon.json entry to complex_pp_list\n",
    "counter = 0\n",
    "for key, entry in p_lexicon.items():\n",
    "    if entry[\"isAtomicMorph\"] == \"\" and entry[\"class\"] == \"\" and entry[\"path_p_morphology\"] == \"\" and entry[\"measure_allowed\"] == \"\" and entry[\"spellOutHEAD\"] == [\"\"]:\n",
    "        complex_pp_list.append(key)\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "56161d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('pp_lexicon/complex_pp_repop.json', 'w') as f:\n",
    "    json.dump(complex_pp_list, f, indent=4)\n",
    "    \n",
    "len(complex_pp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "972565ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['until',\n",
       " 'up to',\n",
       " 'upside',\n",
       " 'versus',\n",
       " 'with a view to',\n",
       " 'with regard to',\n",
       " 'with respect to',\n",
       " 'within',\n",
       " 'without',\n",
       " 'worth']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'the' in complex_pp_list:\n",
    "    complex_pp_list.remove('the')\n",
    "complex_pp_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c2ad8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_result = {} # dictionary to store deomposition results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7b3cb0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "underside\n",
      "cross\n"
     ]
    }
   ],
   "source": [
    "with open('pp_lexicon/axial_words.json', 'r') as f:\n",
    "    axial_words = json.load(f)\n",
    "\n",
    "for ax in axial_words:\n",
    "    if ax not in master_pp_lexicon.keys():\n",
    "        print(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293509d",
   "metadata": {},
   "source": [
    "### get empty list lexicon in p_lexicon.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d81a781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# get empty or \"\" entries from p_lexicon.json\n",
    "empty_entries = []\n",
    "for key, entry in p_lexicon.items():\n",
    "    if entry[\"isAtomicMorph\"] == \"\" and entry[\"class\"] == \"\" and entry[\"path_p_morphology\"] == \"\" and entry[\"measure_allowed\"] == \"\" and entry[\"spellOutHEAD\"] == [\"\"]:\n",
    "        empty_entries.append(key)\n",
    "    \n",
    "print(len(empty_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e26e3c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy p_lexicon.json to dictionary\n",
    "filled_p_lexicon = {}\n",
    "\n",
    "for key, entry in p_lexicon.items():\n",
    "    if entry[\"isAtomicMorph\"] == \"\" and entry[\"class\"] == \"\" and entry[\"path_p_morphology\"] == \"\" and entry[\"measure_allowed\"] == \"\" and entry[\"spellOutHEAD\"] == [\"\"]:\n",
    "        continue\n",
    "    else:\n",
    "        filled_p_lexicon[key] = entry\n",
    "        \n",
    "len(filled_p_lexicon.keys())\n",
    "\n",
    "# with open('pp_lexicon/p_lexicon.json', 'w') as f:\n",
    "#     json.dump(filled_p_lexicon, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ce435",
   "metadata": {},
   "source": [
    "## Step 3: Decomposition Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "471dafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstract_domain_classes import PPFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "52c169fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aboard': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[SURFACE]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'about': {'isAtomicMorph': False,\n",
       "  'class': ['NOT_SPATIAL'],\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': ['none'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['bout']},\n",
       " 'absent': {'isAtomicMorph': False,\n",
       "  'class': ['NOT_SPATIAL'],\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': ['none'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['bsent']},\n",
       " 'according to': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', '*p', {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['ccording']},\n",
       " 'adjacent': {'isAtomicMorph': False,\n",
       "  'class': ['NOT_SPATIAL'],\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': ['none'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['djacent']},\n",
       " 'adjacent to': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', '*p', {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['djacent']},\n",
       " 'afore': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'BOUNDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   {'Path': 'for'}],\n",
       "  'path_p_morphology': ['GOAL', 'LOC'],\n",
       "  'measure_allowed': True},\n",
       " 'ahead': {'isAtomicMorph': False,\n",
       "  'class': ['NOT_SPATIAL'],\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': ['none'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['head']},\n",
       " 'ahead of': {'isAtomicMorph': False,\n",
       "  'class': ['NOT_SPATIAL', 'NOT_SPATIAL'],\n",
       "  'spellOutHEAD': [{'K': 'of'}],\n",
       "  'path_p_morphology': ['none'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['head']},\n",
       " 'alongside': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'along'},\n",
       "   {'K': 'side'},\n",
       "   {'AxPart': '[EDGE]'},\n",
       "   {'AxPart': '[SIDE]'},\n",
       "   '*Deg',\n",
       "   '*Proj'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': True},\n",
       " 'amongst': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'BOUNDED'],\n",
       "  'spellOutHEAD': [{'*Deg': '[PROXIMAL]'},\n",
       "   {'K': 'among'},\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'among'},\n",
       "   {'p': 'astride'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'apart from': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[OUT]'},\n",
       "   {'Deg': '[DISTAL]'},\n",
       "   '*Proj',\n",
       "   {'p': 'apart'},\n",
       "   {'Path': 'from'}],\n",
       "  'path_p_morphology': ['LOC', 'SOURCE'],\n",
       "  'measure_allowed': True},\n",
       " 'as': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'as far as': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'BOUNDED', 'BOUNDED'],\n",
       "  'spellOutHEAD': [{'K': 'far'},\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   {'Deg': '[DISTAL]'},\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   {'p': 'far'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'as of': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': [{'K': 'of'},\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'as opposed to': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['opposed']},\n",
       " 'as per': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['per']},\n",
       " 'as regards': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['regards']},\n",
       " 'as soon as': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'BOUNDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['soon']},\n",
       " 'as well as': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'BOUNDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['well']},\n",
       " 'aside': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'side'}, {'AxPart': '[SIDE]'}, '*Deg', '*Proj'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': True},\n",
       " 'aside from': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'side'},\n",
       "   {'AxPart': '[SIDE]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'from'}],\n",
       "  'path_p_morphology': ['LOC', 'SOURCE'],\n",
       "  'measure_allowed': True},\n",
       " 'astern of': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'astern'},\n",
       "   {'K': 'of'},\n",
       "   {'AxPart': '[BACK_NAUTICAL]'},\n",
       "   '*Deg',\n",
       "   '*Proj'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': True},\n",
       " 'at least': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', {'p': 'at'}, '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['least']},\n",
       " 'at most': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', {'p': 'at'}, '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['most']},\n",
       " 'at the back of': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'back'},\n",
       "   {'K': 'of'},\n",
       "   {'AxPart': '[BACK]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'at'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['the']},\n",
       " 'at the behest of': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': [{'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'at'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['the', 'behest']},\n",
       " 'at the rear of': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'rear'},\n",
       "   {'K': 'of'},\n",
       "   {'AxPart': '[BACK]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'at'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['the']},\n",
       " 'atop': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'BOUNDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[TOP]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'at'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False},\n",
       " 'back to': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'back'},\n",
       "   {'AxPart': '[BACK]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'because of': {'isAtomicMorph': False,\n",
       "  'class': ['NOT_SPATIAL'],\n",
       "  'spellOutHEAD': [{'K': 'of'}],\n",
       "  'path_p_morphology': ['none'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['because']},\n",
       " 'besides': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'BOUNDED'],\n",
       "  'spellOutHEAD': [{'*Deg': '[PROXIMAL]'},\n",
       "   {'K': 'beside'},\n",
       "   {'AxPart': '[SIDE]'},\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'betwixt': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['betwixt']},\n",
       " 'by means of': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': [{'K': 'of'},\n",
       "   '*AxPart',\n",
       "   {'Deg': '[PROXIMAL]'},\n",
       "   '*Proj',\n",
       "   {'p': 'by'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'ROUTE'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['means']},\n",
       " 'by virtue of': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': [{'K': 'of'},\n",
       "   '*AxPart',\n",
       "   {'Deg': '[PROXIMAL]'},\n",
       "   '*Proj',\n",
       "   {'p': 'by'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'ROUTE'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['virtue']},\n",
       " 'circa': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['circa']},\n",
       " 'close to': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'close'},\n",
       "   '*AxPart',\n",
       "   {'Deg': '[PROXIMAL]'},\n",
       "   '*Proj',\n",
       "   {'p': 'close'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'concerning': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['concerning']},\n",
       " 'cross': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'across'}, {'AxPart': '[EDGE]'}, '*Deg', '*Proj'],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'despite': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['despite']},\n",
       " 'due to': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', '*p', {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['due']},\n",
       " 'during': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['during']},\n",
       " 'except': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['except']},\n",
       " 'except for': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', '*p', {'Path': 'for'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['except']},\n",
       " 'far from': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'far'},\n",
       "   '*AxPart',\n",
       "   {'Deg': '[DISTAL]'},\n",
       "   '*Proj',\n",
       "   {'p': 'far'},\n",
       "   {'Path': 'from'}],\n",
       "  'path_p_morphology': ['LOC', 'SOURCE'],\n",
       "  'measure_allowed': True},\n",
       " 'for the sake of': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'for'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['the', 'sake']},\n",
       " 'from behind': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'behind'},\n",
       "   {'AxPart': '[BACK]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'from'}],\n",
       "  'path_p_morphology': ['SOURCE', 'LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'from under': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'under'},\n",
       "   {'AxPart': '[DOWN]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'from'}],\n",
       "  'path_p_morphology': ['SOURCE', 'LOC'],\n",
       "  'measure_allowed': True},\n",
       " 'in a higher place': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'higher'},\n",
       "   {'AxPart': '[UP]'},\n",
       "   {'Deg': ['[GRADIENT]', '[POSITIVE]']},\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['place']},\n",
       " 'in accordance with': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE', 'BOUNDED'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'with'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   {'p': 'with'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['ccordance']},\n",
       " 'in addition to': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE', 'EXTENDED'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   '*K',\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['ddition']},\n",
       " 'in case of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['case']},\n",
       " 'in lieu of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['lieu']},\n",
       " 'in place of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['place']},\n",
       " 'in point of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['point']},\n",
       " 'in spite of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['spite']},\n",
       " 'including': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   '*K',\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['cluding']},\n",
       " 'inside of': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'inside'},\n",
       "   {'K': 'of'},\n",
       "   {'AxPart': '[IN]'},\n",
       "   '*Deg',\n",
       "   '*Proj'],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'instead of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['stead']},\n",
       " 'into': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE', 'EXTENDED'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   '*K',\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'in'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'left of': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'left'},\n",
       "   {'K': 'of'},\n",
       "   {'AxPart': '[LEFT]'},\n",
       "   '*Deg',\n",
       "   '*Proj'],\n",
       "  'path_p_morphology': [''],\n",
       "  'measure_allowed': True},\n",
       " 'less': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['less']},\n",
       " 'like': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['like']},\n",
       " 'minus': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['minus']},\n",
       " 'near to': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'near'},\n",
       "   '*AxPart',\n",
       "   {'Deg': '[PROXIMAL]'},\n",
       "   '*Proj',\n",
       "   {'p': 'near'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'nearer': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'BOUNDED'],\n",
       "  'spellOutHEAD': [{'K': 'near'},\n",
       "   {'AxPart': '[EDGE]'},\n",
       "   {'Deg': '[PROXIMAL]'},\n",
       "   '*Proj',\n",
       "   {'p': 'near'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'nearest': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': [{'K': 'near'},\n",
       "   '*AxPart',\n",
       "   {'Deg': '[PROXIMAL]'},\n",
       "   '*Proj',\n",
       "   {'p': 'near'}],\n",
       "  'path_p_morphology': ['none'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['est']},\n",
       " 'nigh': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['nigh']},\n",
       " 'notwithstanding': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['notwithstanding']},\n",
       " 'on account of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'on'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['ccount']},\n",
       " 'on behalf of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'on'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['behalf']},\n",
       " 'on top of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE', 'BOUNDED'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   {'AxPart': '[TOP]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'on'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'onto': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE', 'EXTENDED'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   '*K',\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'on'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'opposite of': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': [{'K': 'opposite'},\n",
       "   {'K': 'of'},\n",
       "   {'AxPart': '[FRONT]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'opposite'}],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'opposite to': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'opposite'},\n",
       "   {'AxPart': '[FRONT]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'opposite'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'out from': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE', 'EXTENDED'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   '*K',\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'out'},\n",
       "   {'Path': 'from'}],\n",
       "  'path_p_morphology': ['LOC', 'SOURCE'],\n",
       "  'measure_allowed': True},\n",
       " 'out of': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'of'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'out'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'outside of': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'outside'},\n",
       "   {'K': 'of'},\n",
       "   {'AxPart': '[OUT]'},\n",
       "   '*Deg',\n",
       "   '*Proj'],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'owing to': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'following'},\n",
       "   {'AxPart': '[BACK_SEQUENTIAL_DYNAMIC]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'per': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['per']},\n",
       " 'plus': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['plus']},\n",
       " 'prior to': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'prior'},\n",
       "   {'AxPart': '[fRONT]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'pursuant to': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', '*p', {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['pursuant']},\n",
       " 'rather than': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['rather', 'than']},\n",
       " 'regardless of': {'isAtomicMorph': False,\n",
       "  'class': ['NOT_SPATIAL'],\n",
       "  'spellOutHEAD': [{'K': 'of'}],\n",
       "  'path_p_morphology': ['none'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['regardless']},\n",
       " 'right of': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'right'},\n",
       "   {'K': 'of'},\n",
       "   {'AxPart': '[RIGHT]'},\n",
       "   '*Deg',\n",
       "   '*Proj'],\n",
       "  'path_p_morphology': [''],\n",
       "  'measure_allowed': True},\n",
       " 'save': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['save']},\n",
       " 'since': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['since']},\n",
       " 'subsequent to': {'isAtomicMorph': False,\n",
       "  'class': ['PROJECTIVE', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'subsequent'},\n",
       "   {'AxPart': '[BACK]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'such as': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'astride'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['such']},\n",
       " 'thanks to': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', '*p', {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['thanks']},\n",
       " 'throughout': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'through'},\n",
       "   {'AxPart': '[IN]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'out'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['ROUTE', 'LOC'],\n",
       "  'measure_allowed': True},\n",
       " 'to a higher place': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'higher'},\n",
       "   {'AxPart': '[UP]'},\n",
       "   {'Deg': ['[GRADIENT]', '[POSITIVE]']},\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL', 'LOC'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['place']},\n",
       " 'to behind': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'behind'},\n",
       "   {'AxPart': '[BACK]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL', 'LOC', 'SOURCE'],\n",
       "  'measure_allowed': True},\n",
       " 'to under': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'under'},\n",
       "   {'AxPart': '[DOWN]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   '*p',\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL', 'LOC'],\n",
       "  'measure_allowed': True},\n",
       " 'toward': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', '*p', {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['ward']},\n",
       " 'towards': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED'],\n",
       "  'spellOutHEAD': ['*K', '*AxPart', '*Deg', '*Proj', '*p', {'Path': 'to'}],\n",
       "  'path_p_morphology': ['GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['wards']},\n",
       " 'tween': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED'],\n",
       "  'spellOutHEAD': [{'K': 'between'},\n",
       "   {'AxPart': '[BIFURCATION]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'between'}],\n",
       "  'path_p_morphology': ['none'],\n",
       "  'measure_allowed': False},\n",
       " 'underneath': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'under'},\n",
       "   {'K': 'beneath'},\n",
       "   {'AxPart': '[DOWN]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'beneath'}],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': True},\n",
       " 'underside': {'isAtomicMorph': False,\n",
       "  'class': ['EXTENDED', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'under'},\n",
       "   {'K': 'side'},\n",
       "   {'AxPart': '[DOWN]'},\n",
       "   {'AxPart': '[SIDE]'},\n",
       "   '*Deg',\n",
       "   '*Proj'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': True},\n",
       " 'until': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['until']},\n",
       " 'up to': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE', 'EXTENDED'],\n",
       "  'spellOutHEAD': ['*K',\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'up'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'upside': {'isAtomicMorph': False,\n",
       "  'class': ['PARTICLE', 'PROJECTIVE'],\n",
       "  'spellOutHEAD': [{'K': 'side'},\n",
       "   {'AxPart': '[SIDE]'},\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'up'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True},\n",
       " 'versus': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['versus']},\n",
       " 'with a view to': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'with'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'with'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['view']},\n",
       " 'with regard to': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'with'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'with'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['regard']},\n",
       " 'with respect to': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'EXTENDED'],\n",
       "  'spellOutHEAD': [{'K': 'with'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'with'},\n",
       "   {'Path': 'to'}],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': True,\n",
       "  'unlexicalized': ['respect']},\n",
       " 'within': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'with'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'with'},\n",
       "   {'p': 'in'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC', 'GOAL'],\n",
       "  'measure_allowed': False},\n",
       " 'without': {'isAtomicMorph': False,\n",
       "  'class': ['BOUNDED', 'PARTICLE'],\n",
       "  'spellOutHEAD': ['*Det',\n",
       "   {'K': 'with'},\n",
       "   '*AxPart',\n",
       "   '*Deg',\n",
       "   '*Proj',\n",
       "   {'p': 'with'},\n",
       "   {'p': 'out'},\n",
       "   '*Path'],\n",
       "  'path_p_morphology': ['LOC'],\n",
       "  'measure_allowed': False},\n",
       " 'worth': {'isAtomicMorph': False,\n",
       "  'class': None,\n",
       "  'spellOutHEAD': [],\n",
       "  'path_p_morphology': None,\n",
       "  'measure_allowed': False,\n",
       "  'unlexicalized': ['worth']}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH={'to','from','into','onto','through','across','toward','past'}\n",
    "PLACE={'in','on','at','under','beside','near','between','among'}\n",
    "factory = PPFactory('pp_lexicon/atomic_p.json', 'pp_lexicon/p_lexicon.json', 'pp_lexicon/complex_pp_repop.json', PATH, PLACE)\n",
    "factory.create_classes()\n",
    "# Export the augmented lexicon\n",
    "decomposed_result = factory.export_complex_pp()\n",
    "decomposed_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cb43c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unlexicalized entries: 65\n",
      "['about', 'absent', 'according to', 'adjacent', 'adjacent to', 'ahead', 'ahead of', 'as opposed to', 'as per', 'as regards', 'as soon as', 'as well as', 'at least', 'at most', 'at the back of', 'at the behest of', 'at the rear of', 'because of', 'betwixt', 'by means of', 'by virtue of', 'circa', 'concerning', 'despite', 'due to', 'during', 'except', 'except for', 'for the sake of', 'in a higher place', 'in accordance with', 'in addition to', 'in case of', 'in lieu of', 'in place of', 'in point of', 'in spite of', 'including', 'instead of', 'less', 'like', 'minus', 'nearest', 'nigh', 'notwithstanding', 'on account of', 'on behalf of', 'per', 'plus', 'pursuant to', 'rather than', 'regardless of', 'save', 'since', 'such as', 'thanks to', 'to a higher place', 'toward', 'towards', 'until', 'versus', 'with a view to', 'with regard to', 'with respect to', 'worth']\n"
     ]
    }
   ],
   "source": [
    "unlexicalized_count = 0\n",
    "for entry in decomposed_result.values():\n",
    "    unlex = entry.get('unlexicalized')  \n",
    "    if unlex:                           \n",
    "        unlexicalized_count += 1\n",
    "\n",
    "print(f\"Number of unlexicalized entries: {unlexicalized_count}\")\n",
    "\n",
    "keys_with_unlex = [\n",
    "    k\n",
    "    for k, entry in decomposed_result.items()\n",
    "    if entry.get(\"unlexicalized\")\n",
    "]\n",
    "\n",
    "print(keys_with_unlex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a681ed",
   "metadata": {},
   "source": [
    "## Step 4: Acquire Spatial Sentences Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a3974",
   "metadata": {},
   "source": [
    "### Refclef dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e226d398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_ids_list</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>split</th>\n",
       "      <th>category_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>raw</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19135_1</td>\n",
       "      <td>0</td>\n",
       "      <td>19135</td>\n",
       "      <td>train</td>\n",
       "      <td>60</td>\n",
       "      <td>sky</td>\n",
       "      <td>sky</td>\n",
       "      <td>0</td>\n",
       "      <td>sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19135_2</td>\n",
       "      <td>1</td>\n",
       "      <td>19135</td>\n",
       "      <td>train</td>\n",
       "      <td>235</td>\n",
       "      <td>statue</td>\n",
       "      <td>statue</td>\n",
       "      <td>1</td>\n",
       "      <td>statue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23412_4</td>\n",
       "      <td>2</td>\n",
       "      <td>23412</td>\n",
       "      <td>train</td>\n",
       "      <td>258</td>\n",
       "      <td>anywhere,except,the,people</td>\n",
       "      <td>anywhere except the people</td>\n",
       "      <td>2</td>\n",
       "      <td>anywhere except the people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23412_1</td>\n",
       "      <td>3</td>\n",
       "      <td>23412</td>\n",
       "      <td>train</td>\n",
       "      <td>160</td>\n",
       "      <td>person,in,front</td>\n",
       "      <td>person in front</td>\n",
       "      <td>3</td>\n",
       "      <td>person in front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23412_2</td>\n",
       "      <td>4</td>\n",
       "      <td>23412</td>\n",
       "      <td>train</td>\n",
       "      <td>120</td>\n",
       "      <td>person,all,the,way,in,back</td>\n",
       "      <td>person all the way in back</td>\n",
       "      <td>4</td>\n",
       "      <td>person all the way in back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130359</th>\n",
       "      <td>130358,130359</td>\n",
       "      <td>7380_2</td>\n",
       "      <td>99291</td>\n",
       "      <td>7380</td>\n",
       "      <td>train</td>\n",
       "      <td>96</td>\n",
       "      <td>two,birds,on,left</td>\n",
       "      <td>two birds on left</td>\n",
       "      <td>130359</td>\n",
       "      <td>two birds on left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130360</th>\n",
       "      <td>130360</td>\n",
       "      <td>7380_5</td>\n",
       "      <td>99292</td>\n",
       "      <td>7380</td>\n",
       "      <td>train</td>\n",
       "      <td>182</td>\n",
       "      <td>palm,tree,to,the,right</td>\n",
       "      <td>palm tree to the right</td>\n",
       "      <td>130360</td>\n",
       "      <td>palm tree to the right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130361</th>\n",
       "      <td>130361</td>\n",
       "      <td>7380_4</td>\n",
       "      <td>99293</td>\n",
       "      <td>7380</td>\n",
       "      <td>train</td>\n",
       "      <td>182</td>\n",
       "      <td>tree,on,left,side</td>\n",
       "      <td>tree on left side</td>\n",
       "      <td>130361</td>\n",
       "      <td>tree on left side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130362</th>\n",
       "      <td>130362</td>\n",
       "      <td>38047_4</td>\n",
       "      <td>99294</td>\n",
       "      <td>38047</td>\n",
       "      <td>train</td>\n",
       "      <td>34</td>\n",
       "      <td>bush,bottom,left</td>\n",
       "      <td>bush bottom left</td>\n",
       "      <td>130362</td>\n",
       "      <td>bush bottom left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130363</th>\n",
       "      <td>130363</td>\n",
       "      <td>7380_6</td>\n",
       "      <td>99295</td>\n",
       "      <td>7380</td>\n",
       "      <td>train</td>\n",
       "      <td>224</td>\n",
       "      <td>sky</td>\n",
       "      <td>sky</td>\n",
       "      <td>130363</td>\n",
       "      <td>sky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130364 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sent_ids_list   ann_id  ref_id  image_id  split  category_id                      tokens                         raw  sent_id                        sent\n",
       "0                   0  19135_1       0     19135  train           60                         sky                         sky        0                         sky\n",
       "1                   1  19135_2       1     19135  train          235                      statue                      statue        1                      statue\n",
       "2                   2  23412_4       2     23412  train          258  anywhere,except,the,people  anywhere except the people        2  anywhere except the people\n",
       "3                   3  23412_1       3     23412  train          160             person,in,front             person in front        3             person in front\n",
       "4                   4  23412_2       4     23412  train          120  person,all,the,way,in,back  person all the way in back        4  person all the way in back\n",
       "...               ...      ...     ...       ...    ...          ...                         ...                         ...      ...                         ...\n",
       "130359  130358,130359   7380_2   99291      7380  train           96           two,birds,on,left           two birds on left   130359           two birds on left\n",
       "130360         130360   7380_5   99292      7380  train          182      palm,tree,to,the,right      palm tree to the right   130360      palm tree to the right\n",
       "130361         130361   7380_4   99293      7380  train          182           tree,on,left,side           tree on left side   130361           tree on left side\n",
       "130362         130362  38047_4   99294     38047  train           34            bush,bottom,left            bush bottom left   130362            bush bottom left\n",
       "130363         130363   7380_6   99295      7380  train          224                         sky                         sky   130363                         sky\n",
       "\n",
       "[130364 rows x 10 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_refer = pd.read_csv('dataset/refer/referitdataset/refclef_unc_flattened.csv')\n",
    "df_refer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "07c58387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                sky\n",
       "1                             statue\n",
       "2         anywhere except the people\n",
       "3                    person in front\n",
       "4         person all the way in back\n",
       "                     ...            \n",
       "130359             two birds on left\n",
       "130360        palm tree to the right\n",
       "130361             tree on left side\n",
       "130362              bush bottom left\n",
       "130363                           sky\n",
       "Name: sent, Length: 130364, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_refer['sent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e7ebc",
   "metadata": {},
   "source": [
    "#### Inspect most frequent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "53047f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bottom,right,corner', 476), ('bottom,left,corner', 446), ('bottom,right', 413), ('bottom,left', 399), ('the,sky', 386), ('top,left,corner', 347), ('top,right,corner', 338), ('top,right', 291), ('top,left', 271), ('blue,sky', 255), ('bike', 233), ('any,person', 217), ('tree,on,left', 162), ('tree,on,right', 155), ('top,sky', 147), ('tree,left', 138), ('anywhere', 127), ('left,building', 127), ('tree,right', 119), ('sky,top,left', 118)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# ensure Brown corpus and the universal tagset are available\n",
    "nltk.download('brown', quiet=True)\n",
    "nltk.download('universal_tagset', quiet=True)\n",
    "\n",
    "# build a set of lower‐cased nouns from the Brown corpus\n",
    "noun_set = {w.lower() for w, t in brown.tagged_words(tagset='universal') if t == 'NOUN'}\n",
    "\n",
    "# explode your tokens, drop missing, lowercase them\n",
    "tokens = df_refer['tokens'].str.split().explode().dropna().str.lower()\n",
    "\n",
    "# keep only those tokens that are NOT in the Brown corpus noun set\n",
    "filtered_tokens = tokens[~tokens.isin(noun_set)]\n",
    "\n",
    "from collections import Counter\n",
    "most_common_tokens = Counter(filtered_tokens).most_common(20)\n",
    "print((most_common_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "341ddd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bottom,right,corner', 476),\n",
       " ('bottom,left,corner', 446),\n",
       " ('bottom,right', 413),\n",
       " ('bottom,left', 399),\n",
       " ('the,sky', 386),\n",
       " ('top,left,corner', 347),\n",
       " ('top,right,corner', 338),\n",
       " ('top,right', 291),\n",
       " ('top,left', 271),\n",
       " ('blue,sky', 255),\n",
       " ('bike', 233),\n",
       " ('any,person', 217),\n",
       " ('tree,on,left', 162),\n",
       " ('tree,on,right', 155),\n",
       " ('top,sky', 147),\n",
       " ('tree,left', 138),\n",
       " ('anywhere', 127),\n",
       " ('left,building', 127),\n",
       " ('tree,right', 119),\n",
       " ('sky,top,left', 118)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb99456",
   "metadata": {},
   "source": [
    "### Random Sampling for RefClef dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1652d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences longer than 2 tokens: 34533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_ids_list</th>\n",
       "      <th>ann_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>split</th>\n",
       "      <th>category_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>raw</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111206</th>\n",
       "      <td>111206</td>\n",
       "      <td>37864_6</td>\n",
       "      <td>84758</td>\n",
       "      <td>37864</td>\n",
       "      <td>train</td>\n",
       "      <td>160</td>\n",
       "      <td>person,behind,banner,on,the,right,near,guy,holding,banner,on,right</td>\n",
       "      <td>person behind banner on the right near guy holding banner on right</td>\n",
       "      <td>111206</td>\n",
       "      <td>person behind banner on the right near guy holding banner on right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12482</th>\n",
       "      <td>12482,12483</td>\n",
       "      <td>12335_2</td>\n",
       "      <td>9234</td>\n",
       "      <td>12335</td>\n",
       "      <td>train</td>\n",
       "      <td>191</td>\n",
       "      <td>plant,to,the,left,of,the,head</td>\n",
       "      <td>Plant to the left of the head</td>\n",
       "      <td>12482</td>\n",
       "      <td>plant to the left of the head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104404</th>\n",
       "      <td>104401,104402,104403,104404,104405</td>\n",
       "      <td>7020_5</td>\n",
       "      <td>79423</td>\n",
       "      <td>7020</td>\n",
       "      <td>train</td>\n",
       "      <td>88</td>\n",
       "      <td>5th,man,from,bottom,,,green,cap,face,only</td>\n",
       "      <td>5th man from bottom, green cap face only</td>\n",
       "      <td>104404</td>\n",
       "      <td>5th man from bottom , green cap face only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308</th>\n",
       "      <td>9308,9309</td>\n",
       "      <td>35840_3</td>\n",
       "      <td>7010</td>\n",
       "      <td>35840</td>\n",
       "      <td>train</td>\n",
       "      <td>31</td>\n",
       "      <td>tallest,building,in,the,background</td>\n",
       "      <td>tallest building in the background</td>\n",
       "      <td>9308</td>\n",
       "      <td>tallest building in the background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27705</th>\n",
       "      <td>27705</td>\n",
       "      <td>24239_4</td>\n",
       "      <td>20297</td>\n",
       "      <td>24239</td>\n",
       "      <td>train</td>\n",
       "      <td>120</td>\n",
       "      <td>the,shape,their,bodies,are,forming</td>\n",
       "      <td>the shape their bodies are forming</td>\n",
       "      <td>27705</td>\n",
       "      <td>the shape their bodies are forming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19324</th>\n",
       "      <td>19324</td>\n",
       "      <td>18518_4</td>\n",
       "      <td>14177</td>\n",
       "      <td>18518</td>\n",
       "      <td>train</td>\n",
       "      <td>119</td>\n",
       "      <td>old,machine,left,-,big,wheel</td>\n",
       "      <td>old machine left - big wheel</td>\n",
       "      <td>19324</td>\n",
       "      <td>old machine left - big wheel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103721</th>\n",
       "      <td>103721</td>\n",
       "      <td>7003_6</td>\n",
       "      <td>78843</td>\n",
       "      <td>7003</td>\n",
       "      <td>train</td>\n",
       "      <td>204</td>\n",
       "      <td>dark,gray,rocks,above,lower,green,and,white,stuff</td>\n",
       "      <td>dark gray rocks above lower green and white stuff</td>\n",
       "      <td>103721</td>\n",
       "      <td>dark gray rocks above lower green and white stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92840</th>\n",
       "      <td>92840</td>\n",
       "      <td>18280_4</td>\n",
       "      <td>70122</td>\n",
       "      <td>18280</td>\n",
       "      <td>train</td>\n",
       "      <td>110</td>\n",
       "      <td>left,side,behind,girl,in,black</td>\n",
       "      <td>left side behind girl in black</td>\n",
       "      <td>92840</td>\n",
       "      <td>left side behind girl in black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69787</th>\n",
       "      <td>69786,69787</td>\n",
       "      <td>1411_5</td>\n",
       "      <td>52419</td>\n",
       "      <td>1411</td>\n",
       "      <td>train</td>\n",
       "      <td>271</td>\n",
       "      <td>green,glowing,corner,window,second,floor</td>\n",
       "      <td>green glowing corner window second floor</td>\n",
       "      <td>69787</td>\n",
       "      <td>green glowing corner window second floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25839</th>\n",
       "      <td>25839</td>\n",
       "      <td>15877_5</td>\n",
       "      <td>19046</td>\n",
       "      <td>15877</td>\n",
       "      <td>train</td>\n",
       "      <td>43</td>\n",
       "      <td>green,awesome,thing,on,left</td>\n",
       "      <td>green awesome thing on left</td>\n",
       "      <td>25839</td>\n",
       "      <td>green awesome thing on left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sent_ids_list   ann_id  ref_id  image_id  split  category_id                                                              tokens                                                                 raw  sent_id                                                                sent\n",
       "111206                              111206  37864_6   84758     37864  train          160  person,behind,banner,on,the,right,near,guy,holding,banner,on,right  person behind banner on the right near guy holding banner on right   111206  person behind banner on the right near guy holding banner on right\n",
       "12482                          12482,12483  12335_2    9234     12335  train          191                                       plant,to,the,left,of,the,head                                       Plant to the left of the head    12482                                       plant to the left of the head\n",
       "104404  104401,104402,104403,104404,104405   7020_5   79423      7020  train           88                           5th,man,from,bottom,,,green,cap,face,only                            5th man from bottom, green cap face only   104404                           5th man from bottom , green cap face only\n",
       "9308                             9308,9309  35840_3    7010     35840  train           31                                  tallest,building,in,the,background                                  tallest building in the background     9308                                  tallest building in the background\n",
       "27705                                27705  24239_4   20297     24239  train          120                                  the,shape,their,bodies,are,forming                                  the shape their bodies are forming    27705                                  the shape their bodies are forming\n",
       "...                                    ...      ...     ...       ...    ...          ...                                                                 ...                                                                 ...      ...                                                                 ...\n",
       "19324                                19324  18518_4   14177     18518  train          119                                        old,machine,left,-,big,wheel                                        old machine left - big wheel    19324                                        old machine left - big wheel\n",
       "103721                              103721   7003_6   78843      7003  train          204                   dark,gray,rocks,above,lower,green,and,white,stuff                   dark gray rocks above lower green and white stuff   103721                   dark gray rocks above lower green and white stuff\n",
       "92840                                92840  18280_4   70122     18280  train          110                                      left,side,behind,girl,in,black                                      left side behind girl in black    92840                                      left side behind girl in black\n",
       "69787                          69786,69787   1411_5   52419      1411  train          271                            green,glowing,corner,window,second,floor                            green glowing corner window second floor    69787                            green glowing corner window second floor\n",
       "25839                                25839  15877_5   19046     15877  train           43                                         green,awesome,thing,on,left                                         green awesome thing on left    25839                                         green awesome thing on left\n",
       "\n",
       "[873 rows x 10 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter df_refer to only sentences longer than 2 tokens\n",
    "mask = df_refer['sent'].str.split().str.len() > 4\n",
    "df_refer_filtered = df_refer.loc[mask]\n",
    "print(f\"Sentences longer than 2 tokens: {len(df_refer_filtered)}\")\n",
    "\n",
    "# now sample from the filtered dataframe\n",
    "# replace n and random_state with your desired values\n",
    "sampled_df_refer = df_refer_filtered.sample(n=873, random_state=42)\n",
    "sampled_df_refer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "41268be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person behind banner on the right near guy holding banner on right',\n",
       " 'plant to the left of the head',\n",
       " '5th man from bottom , green cap face only',\n",
       " 'tallest building in the background',\n",
       " 'the shape their bodies are forming',\n",
       " 'top left dark part of sky',\n",
       " 'green beer can middle , left of tall brown bottle',\n",
       " 'the candle at very bottom right',\n",
       " 'the tree at the left',\n",
       " 'front left girl in blue']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refer_sent = sampled_df_refer['sent'].tolist()\n",
    "refer_sent[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ab4fc",
   "metadata": {},
   "source": [
    "### Acquiring REAL_Corpus Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4feefab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>photoid</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>annotation</th>\n",
       "      <th>status</th>\n",
       "      <th>phrase length</th>\n",
       "      <th>validator_userid</th>\n",
       "      <th>validator_age</th>\n",
       "      <th>validator_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img23</td>\n",
       "      <td>495</td>\n",
       "      <td>157</td>\n",
       "      <td>Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows</td>\n",
       "      <td>correct</td>\n",
       "      <td>123</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows</td>\n",
       "      <td>cantfind</td>\n",
       "      <td>123</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img23</td>\n",
       "      <td>383</td>\n",
       "      <td>164</td>\n",
       "      <td>Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows</td>\n",
       "      <td>correct</td>\n",
       "      <td>123</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Traditional early Victorian terrace on 3 floors + dormer. Third in from the left of the end terrace.  Royal Blue Door, Black, spiked iron railings.</td>\n",
       "      <td>ambiguous</td>\n",
       "      <td>147</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img31</td>\n",
       "      <td>210</td>\n",
       "      <td>421</td>\n",
       "      <td>Traditional early Victorian terrace on 3 floors + dormer. Third in from the left of the end terrace.  Royal Blue Door, Black, spiked iron railings.</td>\n",
       "      <td>correct</td>\n",
       "      <td>147</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  age gender photoid    x    y                                                                                                                                           annotation     status  phrase length  validator_userid  validator_age validator_gender\n",
       "0       2    4   male   img23  495  157                          Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows    correct            123                26              6             male\n",
       "1       2    4   male   img23    0    0                          Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows   cantfind            123                41              5           female\n",
       "2       2    4   male   img23  383  164                          Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows    correct            123                42              4           female\n",
       "3       2    4   male   img31    0    0  Traditional early Victorian terrace on 3 floors + dormer. Third in from the left of the end terrace.  Royal Blue Door, Black, spiked iron railings.  ambiguous            147                 7              2           female\n",
       "4       2    4   male   img31  210  421  Traditional early Victorian terrace on 3 floors + dormer. Third in from the left of the end terrace.  Royal Blue Door, Black, spiked iron railings.    correct            147                 8              3           female"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real = pd.read_csv('dataset/REAL_Corpus/REAL_Corpus_ReferringExpressionsData_withValidationDetails.csv', delimiter=';')\n",
    "df_real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a67381f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>photoid</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>annotation</th>\n",
       "      <th>status</th>\n",
       "      <th>phrase length</th>\n",
       "      <th>validator_userid</th>\n",
       "      <th>validator_age</th>\n",
       "      <th>validator_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img23</td>\n",
       "      <td>495</td>\n",
       "      <td>157</td>\n",
       "      <td>Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows</td>\n",
       "      <td>correct</td>\n",
       "      <td>123</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img23</td>\n",
       "      <td>383</td>\n",
       "      <td>164</td>\n",
       "      <td>Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows</td>\n",
       "      <td>correct</td>\n",
       "      <td>123</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img31</td>\n",
       "      <td>210</td>\n",
       "      <td>421</td>\n",
       "      <td>Traditional early Victorian terrace on 3 floors + dormer. Third in from the left of the end terrace.  Royal Blue Door, Black, spiked iron railings.</td>\n",
       "      <td>correct</td>\n",
       "      <td>147</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img31</td>\n",
       "      <td>82</td>\n",
       "      <td>371</td>\n",
       "      <td>Traditional early Victorian terrace on 3 floors + dormer. Third in from the left of the end terrace.  Royal Blue Door, Black, spiked iron railings.</td>\n",
       "      <td>correct</td>\n",
       "      <td>147</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>img21</td>\n",
       "      <td>222</td>\n",
       "      <td>305</td>\n",
       "      <td>Large, modern glass fronted building, butted up against traditional victorian terrace, slightly set back from road, and with facing bowed frontage.</td>\n",
       "      <td>correct</td>\n",
       "      <td>147</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  age gender photoid    x    y                                                                                                                                           annotation   status  phrase length  validator_userid  validator_age validator_gender\n",
       "0       2    4   male   img23  495  157                          Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows  correct            123                26              6             male\n",
       "2       2    4   male   img23  383  164                          Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows  correct            123                42              4           female\n",
       "4       2    4   male   img31  210  421  Traditional early Victorian terrace on 3 floors + dormer. Third in from the left of the end terrace.  Royal Blue Door, Black, spiked iron railings.  correct            147                 8              3           female\n",
       "5       2    4   male   img31   82  371  Traditional early Victorian terrace on 3 floors + dormer. Third in from the left of the end terrace.  Royal Blue Door, Black, spiked iron railings.  correct            147                 9              2             male\n",
       "6       2    4   male   img21  222  305  Large, modern glass fronted building, butted up against traditional victorian terrace, slightly set back from road, and with facing bowed frontage.  correct            147                 6              2             male"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real[df_real['status'] == 'correct'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ec90b9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userid                                                                                                                                        2\n",
       "age                                                                                                                                           4\n",
       "gender                                                                                                                                     male\n",
       "photoid                                                                                                                                   img23\n",
       "x                                                                                                                                           495\n",
       "y                                                                                                                                           157\n",
       "annotation          Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows\n",
       "status                                                                                                                                  correct\n",
       "phrase length                                                                                                                               123\n",
       "validator_userid                                                                                                                             26\n",
       "validator_age                                                                                                                                 6\n",
       "validator_gender                                                                                                                           male\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the first row for each unique annotation,\n",
    "# but carry along every other column\n",
    "df_real_unique = df_real.drop_duplicates(subset=['annotation'], keep='first') \\\n",
    "                        .reset_index(drop=True)\n",
    "df_real_unique.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0c0394a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             Pub called 'Deacon Brodie's Tavern. Black and white traditional building with sign hanging outside and 3 big arched windows\n",
       "1     Traditional early Victorian terrace on 3 floors + dormer. Third in from the left of the end terrace.  Royal Blue Door, Black, spiked iron railings.\n",
       "2     Large, modern glass fronted building, butted up against traditional victorian terrace, slightly set back from road, and with facing bowed frontage.\n",
       "3                           Two story traditional stone building, on the left of the street as faced, just before the bed.  Two large white double doors.\n",
       "4                  Church in the middle of a small square/island - no spire but with large stained glass window in gable end, slightly obscured by trees.\n",
       "5                                                                      Building with columns behind the one in front, also in similar architecture style.\n",
       "6                                                                   End centre of the street, straight ahead, big building with a columns and a dome roof\n",
       "7                                                             Grey building block with statues above the entrance, Amarone restaurant on the bottom floor\n",
       "8                                                                                        Big historical building with huge columns and statue at the top.\n",
       "9                                 Middle vertical section of the house above the brown door of the housing block with Eigin Cashmere on the ground floor.\n",
       "10                                                                                                                              Small shed with lead roof\n",
       "11                                                                                                            Red and gold coffee shop next to the bridge\n",
       "12                                                                              Small stone capped monument/fountain with a plaque built on the pavement.\n",
       "13                                                                                                Enormous Gothic tower in the park that is stained black\n",
       "14                                                                                                        Coffee shop to the left of the converted church\n",
       "15                                                        The windows above the restaurant with the black street furniture next to the RBS on the corner.\n",
       "16                                                                         The Austrian looking white house with the dark wooden beams at the water side.\n",
       "17                                                                The castle- like tower on the corner next to the Tartan Weaving Mill on the Royal Mile.\n",
       "18                                                        The green- ish statue standing in front on the square in front of the church on the Royal Mile.\n",
       "19                                                          The square building on the right hand side with the three tall pillars next to the Pizza Hut.\n",
       "Name: annotation, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_real_unique['annotation'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a814e99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878, 12)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real_unique.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d2e7c",
   "metadata": {},
   "source": [
    "There's multiple data containing multiple sentences. We should split those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aa65fb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1245, 12)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the annotation column into lists, explode to one row per sentence\n",
    "df_real_split = (\n",
    "    df_real_unique\n",
    "      .assign(annotation=df_real_unique['annotation'].str.split(r'\\.'))\n",
    "      .explode('annotation')\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# strip whitespace and drop any empty strings\n",
    "df_real_split['annotation'] = df_real_split['annotation'].str.strip()\n",
    "df_real_split = df_real_split[df_real_split['annotation'] != '']\n",
    "\n",
    "df_real_split.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2cc69",
   "metadata": {},
   "source": [
    "Should I sample refclef with 1245 sentences as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b74c3c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1690                                                                                                                   Large cream columned building\n",
       "1691                                                                                                                                    Small Church\n",
       "1692                                                                                                                  Festival Theatre made of glass\n",
       "1693                                        A museum that looks like an ancient Greek temple with columns to two sides, except still in a good state\n",
       "1694                                                                                                     There are some classic statues on top of it\n",
       "1696                                                                            It's a restaurant and possibly pub called Deacon Brodie's Tavern, no\n",
       "1697                                                                                                                           435 in the Royal Mile\n",
       "1698                                                                                                     It has some classic arches over the windows\n",
       "1700                                                                                               A typical Edinburgh-style house with three levels\n",
       "1701                                                                                                            It has badly insulated large windows\n",
       "1702                                                                                       The windows in the 1st floor are subdivided into 12 parts\n",
       "1704                                                                                  It's a white house next to the river with four small balconies\n",
       "1705                                                                                There is a lot of (Swiss style) black-painted wood on the facade\n",
       "1706                                                                                                                             It has tiny windows\n",
       "1708                                                              Is it an optical illusion, or are the slats on the underside of the gables curved?\n",
       "1709    There is a woman walking on the pavement with a blue-gray shirt wearing weird orange pants, or is she standing behind an orange wheelie bin?\n",
       "1710                                                                                                       The cream painted shop next to the church\n",
       "1711                                                                                                     It is just opposite the pedestrian crossing\n",
       "1713                                                      the statue at the end of the road, just in front of the building with the dome shaped roof\n",
       "1714                                                                                                 The small, dark entrance just below the Saltire\n",
       "Name: annotation, dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real_split['annotation'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c774c58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.to_csv of       userid  age  gender photoid    x    y                                                                                                                                    annotation     status  phrase length  validator_userid  validator_age validator_gender\n",
       "0          2    4    male   img23  495  157                                                                                                            Pub called 'Deacon Brodie's Tavern    correct            123                26              6             male\n",
       "1          2    4    male   img23  495  157                                                       Black and white traditional building with sign hanging outside and 3 big arched windows    correct            123                26              6             male\n",
       "2          2    4    male   img31    0    0                                                                                      Traditional early Victorian terrace on 3 floors + dormer  ambiguous            147                 7              2           female\n",
       "3          2    4    male   img31    0    0                                                                                                     Third in from the left of the end terrace  ambiguous            147                 7              2           female\n",
       "4          2    4    male   img31    0    0                                                                                                  Royal Blue Door, Black, spiked iron railings  ambiguous            147                 7              2           female\n",
       "...      ...  ...     ...     ...  ...  ...                                                                                                                                           ...        ...            ...               ...            ...              ...\n",
       "1709     234    4  female   img15  611  379  There is a woman walking on the pavement with a blue-gray shirt wearing weird orange pants, or is she standing behind an orange wheelie bin?  incorrect            140               238              2             male\n",
       "1710     234    4  female   img10  240  330                                                                                                     The cream painted shop next to the church  incorrect             87               240              2             male\n",
       "1711     234    4  female   img10  240  330                                                                                                   It is just opposite the pedestrian crossing  incorrect             87               240              2             male\n",
       "1713     234    4  female   img14  273  427                                                    the statue at the end of the road, just in front of the building with the dome shaped roof    correct             90               241              2           female\n",
       "1714     234    4  female   img24  800  415                                                                                               The small, dark entrance just below the Saltire  incorrect             47               239              2             male\n",
       "\n",
       "[1245 rows x 12 columns]>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real_split.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "832af27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     nltk.data.find('taggers/averaged_perceptron_tagger_eng')\n",
    "#     print(\"‘averaged_perceptron_tagger_eng’ is installed \")\n",
    "# except LookupError:\n",
    "#     print(\"‘averaged_perceptron_tagger’ is NOT installed  (LookupError raised)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "94fe00c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger works!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.pos_tag(\"This is a test\".split())\n",
    "    print(\"Tagger works!\")\n",
    "except LookupError as e:\n",
    "    print(\"LookupError:\", e)\n",
    "    print(\"So the tagger isn’t installed yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "03078f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.pos_tag() uses the Penn Treebank Tag Set.\n",
    "unique_sents = df_real_split['annotation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "395e9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NNP Black)\n",
      "  (CC and)\n",
      "  (JJ white)\n",
      "  (JJ traditional)\n",
      "  (NN building)\n",
      "  (IN with)\n",
      "  (NN sign)\n",
      "  (VBG hanging)\n",
      "  (JJ outside)\n",
      "  (CC and)\n",
      "  (CD 3)\n",
      "  (JJ big)\n",
      "  (VBD arched)\n",
      "  (NNS windows))\n"
     ]
    }
   ],
   "source": [
    "# generate cfg rule dump constituent tree as grammar:\n",
    "\n",
    "S = Nonterminal('S')\n",
    "prod_set = set()\n",
    "\n",
    "for sent in unique_sents:\n",
    "    tokens = sent.split()\n",
    "\n",
    "    tagged = nltk.pos_tag(tokens)  \n",
    "    # build the S → POS1 POS2 … production\n",
    "    rhs_pos = [Nonterminal(pos) for (_tok, pos) in tagged]\n",
    "    prod_set.add(Production(S, rhs_pos))\n",
    "\n",
    "    # build each POS → \"word\" production\n",
    "    for word, pos in tagged:\n",
    "        prod_set.add(Production(Nonterminal(pos), [word]))\n",
    "\n",
    "\n",
    "grammar = CFG(S, list(prod_set))\n",
    "# print(grammar)\n",
    "parser = EarleyChartParser(grammar)\n",
    "\n",
    "# start_sym = trees[0].label()           # usually 'S'\n",
    "\n",
    "# prods = list({ p for p in all_prods })  # set-dedupe, original producing 2000 cfg rules\n",
    "# grammar = CFG(Nonterminal(start_sym), prods)\n",
    "\n",
    "\n",
    "# test on the first sentence\n",
    "test_sent = unique_sents_unpunct[1].split()\n",
    "for tree in parser.parse(test_sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2b53a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = Nonterminal('S')\n",
    "# prods = []\n",
    "\n",
    "# for sent in unique_sents:\n",
    "#     tagged = nltk.pos_tag(sent.split())\n",
    "#     prev_nt = S\n",
    "\n",
    "#     # for each token except the last, build NT_i → POS_i NT_{i+1}\n",
    "#     for i, (w, pos) in enumerate(tagged[:-1]):\n",
    "#         curr_nt = Nonterminal(f\"X{i}\")\n",
    "#         prods.append(Production(prev_nt, [Nonterminal(pos), curr_nt]))\n",
    "#         prods.append(Production(Nonterminal(pos), [w]))\n",
    "#         prev_nt = curr_nt\n",
    "\n",
    "#     # final link: X_{n-1} → POS_n\n",
    "#     last_word, last_pos = tagged[-1]\n",
    "#     prods.append(Production(prev_nt, [Nonterminal(last_pos)]))\n",
    "#     prods.append(Production(Nonterminal(last_pos), [last_word]))\n",
    "\n",
    "# grammar = CFG(S, prods)\n",
    "# parser = EarleyChartParser(grammar)\n",
    "\n",
    "# print(grammar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0615b9d",
   "metadata": {},
   "source": [
    "### spaCy+benepar PCFG Neural Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71df1d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d9974a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "42ff2db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/glora/projects/populate-ns-lex/venv/lib/python3.9/site-packages/benepar/parse_chart.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<benepar.integrations.spacy_plugin.BeneparComponent at 0x1445a2df0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install spacy benepar torch\n",
    "import spacy, benepar\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# download (or wrap in try/except to skip if already present)\n",
    "# benepar.download(\"benepar_en3\")\n",
    "nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dd9c4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_tags = {\",\", \":\", \"``\", \"''\", \".\", \"(\", \")\", \"--\", \"``\", \"+\"}\n",
    "\n",
    "unique_sents_unpunct = [\n",
    "    sent for sent in unique_sents if not any(tag in sent for tag in punct_tags) # reduced 50% rules\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "de46f959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/glora/projects/populate-ns-lex/venv/lib/python3.9/site-packages/torch/distributions/distribution.py:55: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NP -> NP VP,\n",
       " NP -> NN,\n",
       " NN -> 'Pub',\n",
       " VP -> VBN S,\n",
       " VBN -> 'called',\n",
       " S -> `` NP,\n",
       " `` -> \"'\",\n",
       " NP -> NP NNP,\n",
       " NP -> NNP NNP POS,\n",
       " NNP -> 'Deacon',\n",
       " NNP -> 'Brodie',\n",
       " POS -> \"'s\",\n",
       " NNP -> 'Tavern',\n",
       " NP -> NP PP,\n",
       " NP -> ADJP JJ NN,\n",
       " ADJP -> JJ CC JJ,\n",
       " JJ -> 'Black',\n",
       " CC -> 'and',\n",
       " JJ -> 'white',\n",
       " JJ -> 'traditional',\n",
       " NN -> 'building',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP CC NP,\n",
       " NP -> NP VP,\n",
       " NP -> NN,\n",
       " NN -> 'sign',\n",
       " VP -> VBG ADVP,\n",
       " VBG -> 'hanging',\n",
       " ADVP -> RB,\n",
       " RB -> 'outside',\n",
       " CC -> 'and',\n",
       " NP -> CD JJ JJ NNS,\n",
       " CD -> '3',\n",
       " JJ -> 'big',\n",
       " JJ -> 'arched',\n",
       " NNS -> 'windows',\n",
       " FRAG -> ADJP PP,\n",
       " ADJP -> JJ RB,\n",
       " JJ -> 'Third',\n",
       " RB -> 'in',\n",
       " PP -> IN NP,\n",
       " IN -> 'from',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'left',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> DT NN NN,\n",
       " DT -> 'the',\n",
       " NN -> 'end',\n",
       " NN -> 'terrace',\n",
       " NP -> CD JJ JJ JJ NNS,\n",
       " CD -> 'Two',\n",
       " JJ -> 'large',\n",
       " JJ -> 'white',\n",
       " JJ -> 'double',\n",
       " NNS -> 'doors',\n",
       " NP -> NP PP,\n",
       " NP -> JJ JJ NN,\n",
       " JJ -> 'Big',\n",
       " JJ -> 'historical',\n",
       " NN -> 'building',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP PP,\n",
       " NP -> JJ NNS CC NN,\n",
       " JJ -> 'huge',\n",
       " NNS -> 'columns',\n",
       " CC -> 'and',\n",
       " NN -> 'statue',\n",
       " PP -> IN NP,\n",
       " IN -> 'at',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'top',\n",
       " NP -> NP PP PP,\n",
       " NP -> JJ JJ NN,\n",
       " JJ -> 'Middle',\n",
       " JJ -> 'vertical',\n",
       " NN -> 'section',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'house',\n",
       " PP -> PP PP,\n",
       " PP -> PP PP,\n",
       " PP -> IN NP,\n",
       " IN -> 'above',\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'brown',\n",
       " NN -> 'door',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> DT NN NN,\n",
       " DT -> 'the',\n",
       " NN -> 'housing',\n",
       " NN -> 'block',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP PP,\n",
       " NP -> NNP NNP,\n",
       " NNP -> 'Eigin',\n",
       " NNP -> 'Cashmere',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'ground',\n",
       " NN -> 'floor',\n",
       " NP -> NP PP,\n",
       " NP -> JJ NN,\n",
       " JJ -> 'Small',\n",
       " NN -> 'shed',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NN NN,\n",
       " NN -> 'lead',\n",
       " NN -> 'roof',\n",
       " NP -> NP ADVP,\n",
       " NP -> ADJP NN NN,\n",
       " ADJP -> JJ CC JJ,\n",
       " JJ -> 'Red',\n",
       " CC -> 'and',\n",
       " JJ -> 'gold',\n",
       " NN -> 'coffee',\n",
       " NN -> 'shop',\n",
       " ADVP -> JJ PP,\n",
       " JJ -> 'next',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'bridge',\n",
       " NP -> NP PP,\n",
       " NP -> JJ ADJP NN SYM NN,\n",
       " JJ -> 'Small',\n",
       " ADJP -> NN VBN,\n",
       " NN -> 'stone',\n",
       " VBN -> 'capped',\n",
       " NN -> 'monument',\n",
       " SYM -> '/',\n",
       " NN -> 'fountain',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP VP,\n",
       " NP -> DT NN,\n",
       " DT -> 'a',\n",
       " NN -> 'plaque',\n",
       " VP -> VBN PP,\n",
       " VBN -> 'built',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'pavement',\n",
       " NP -> NP SBAR,\n",
       " NP -> NP PP,\n",
       " NP -> JJ JJ NN,\n",
       " JJ -> 'Enormous',\n",
       " JJ -> 'Gothic',\n",
       " NN -> 'tower',\n",
       " PP -> IN NP,\n",
       " IN -> 'in',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'park',\n",
       " SBAR -> WHNP S,\n",
       " WHNP -> WDT,\n",
       " WDT -> 'that',\n",
       " S -> VP,\n",
       " VP -> VBZ VP,\n",
       " VBZ -> 'is',\n",
       " VP -> VBN ADVP,\n",
       " VBN -> 'stained',\n",
       " ADVP -> JJ,\n",
       " JJ -> 'black',\n",
       " NP -> NP PP,\n",
       " NP -> NN NN,\n",
       " NN -> 'Coffee',\n",
       " NN -> 'shop',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'left',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> DT VBN NN,\n",
       " DT -> 'the',\n",
       " VBN -> 'converted',\n",
       " NN -> 'church',\n",
       " NP -> NP PP PP,\n",
       " NP -> DT NNS,\n",
       " DT -> 'The',\n",
       " NNS -> 'windows',\n",
       " PP -> IN NP,\n",
       " IN -> 'above',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'restaurant',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP ADVP,\n",
       " NP -> DT JJ NN NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'black',\n",
       " NN -> 'street',\n",
       " NN -> 'furniture',\n",
       " ADVP -> JJ PP,\n",
       " JJ -> 'next',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> NP PP,\n",
       " NP -> DT NNP,\n",
       " DT -> 'the',\n",
       " NNP -> 'RBS',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'corner',\n",
       " NP -> NP PP,\n",
       " NP -> DT ADJP JJ NN,\n",
       " DT -> 'The',\n",
       " ADJP -> JJ VBG,\n",
       " JJ -> 'Austrian',\n",
       " VBG -> 'looking',\n",
       " JJ -> 'white',\n",
       " NN -> 'house',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP PP,\n",
       " NP -> DT JJ JJ NNS,\n",
       " DT -> 'the',\n",
       " JJ -> 'dark',\n",
       " JJ -> 'wooden',\n",
       " NNS -> 'beams',\n",
       " PP -> IN NP,\n",
       " IN -> 'at',\n",
       " NP -> DT NN NN,\n",
       " DT -> 'the',\n",
       " NN -> 'water',\n",
       " NN -> 'side',\n",
       " NP -> NP PP,\n",
       " NP -> DT ADJP NN,\n",
       " DT -> 'The',\n",
       " ADJP -> HYPH JJ,\n",
       " HYPH -> 'castle-',\n",
       " JJ -> 'like',\n",
       " NN -> 'tower',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> NP ADVP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'corner',\n",
       " ADVP -> JJ PP,\n",
       " JJ -> 'next',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> NP PP,\n",
       " NP -> DT NNP NNP NNP,\n",
       " DT -> 'the',\n",
       " NNP -> 'Tartan',\n",
       " NNP -> 'Weaving',\n",
       " NNP -> 'Mill',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> DT NNP NNP,\n",
       " DT -> 'the',\n",
       " NNP -> 'Royal',\n",
       " NNP -> 'Mile',\n",
       " NP -> NP VP,\n",
       " NP -> DT ADJP NN,\n",
       " DT -> 'The',\n",
       " ADJP -> JJ JJ,\n",
       " JJ -> 'green-',\n",
       " JJ -> 'ish',\n",
       " NN -> 'statue',\n",
       " VP -> VBG PP PP,\n",
       " VBG -> 'standing',\n",
       " PP -> IN NP,\n",
       " IN -> 'in',\n",
       " NP -> NN,\n",
       " NN -> 'front',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'square',\n",
       " PP -> IN NP,\n",
       " IN -> 'in',\n",
       " NP -> NP PP,\n",
       " NP -> NN,\n",
       " NN -> 'front',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'church',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> DT NNP NNP,\n",
       " DT -> 'the',\n",
       " NNP -> 'Royal',\n",
       " NNP -> 'Mile',\n",
       " NP -> NP PP PP,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'The',\n",
       " JJ -> 'square',\n",
       " NN -> 'building',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> DT JJ NN NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'right',\n",
       " NN -> 'hand',\n",
       " NN -> 'side',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP ADJP,\n",
       " NP -> DT CD JJ NNS,\n",
       " DT -> 'the',\n",
       " CD -> 'three',\n",
       " JJ -> 'tall',\n",
       " NNS -> 'pillars',\n",
       " ADJP -> JJ PP,\n",
       " JJ -> 'next',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> DT NNP NNP,\n",
       " DT -> 'the',\n",
       " NNP -> 'Pizza',\n",
       " NNP -> 'Hut',\n",
       " NP -> NP CC NP,\n",
       " NP -> DT NN NN NN,\n",
       " DT -> 'The',\n",
       " NN -> 'elephant',\n",
       " NN -> 'house',\n",
       " NN -> 'pub',\n",
       " CC -> 'and',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'flat',\n",
       " PP -> IN NP,\n",
       " IN -> 'above',\n",
       " NP -> PRP,\n",
       " PRP -> 'it',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ PP,\n",
       " VBZ -> \"'s\",\n",
       " PP -> IN NP,\n",
       " IN -> 'between',\n",
       " NP -> NP CC NP,\n",
       " NP -> DT NNP NN NN,\n",
       " DT -> 'the',\n",
       " NNP -> 'Subway',\n",
       " NN -> 'sandwich',\n",
       " NN -> 'shop',\n",
       " CC -> 'and',\n",
       " NP -> NP VP,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'another',\n",
       " JJ -> 'small',\n",
       " NN -> 'restaurant',\n",
       " VP -> VBN S,\n",
       " VBN -> 'called',\n",
       " S -> NP,\n",
       " NP -> NNP NNP,\n",
       " NNP -> 'Thai',\n",
       " NNP -> 'Basil',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ NP,\n",
       " VBZ -> \"'s\",\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'a',\n",
       " JJ -> 'Georgian',\n",
       " NN -> 'building',\n",
       " NP -> NP PP,\n",
       " NP -> DT NML JJ NN,\n",
       " DT -> 'A',\n",
       " NML -> JJ NN,\n",
       " JJ -> 'main',\n",
       " NN -> 'door',\n",
       " JJ -> 'Georgian',\n",
       " NN -> 'flat',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> NNP NNP,\n",
       " NNP -> 'Moray',\n",
       " NNP -> 'Place',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ NP PP,\n",
       " VBZ -> 'has',\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'a',\n",
       " JJ -> 'red',\n",
       " NN -> 'postbox',\n",
       " PP -> ADVP IN NP,\n",
       " ADVP -> RB,\n",
       " RB -> 'right',\n",
       " IN -> 'in',\n",
       " NP -> NP PP,\n",
       " NP -> NN,\n",
       " NN -> 'front',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> PRP,\n",
       " PRP -> 'it',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ NP,\n",
       " VBZ -> \"'s\",\n",
       " NP -> NP PP,\n",
       " NP -> DT ADJP NN,\n",
       " DT -> 'the',\n",
       " ADJP -> JJ JJ,\n",
       " JJ -> 'bright',\n",
       " JJ -> 'blue',\n",
       " NN -> 'door',\n",
       " PP -> IN NP,\n",
       " IN -> 'in',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'middle',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'building',\n",
       " PP -> IN NP,\n",
       " IN -> 'in',\n",
       " NP -> NNP NNP,\n",
       " NNP -> 'Ramsay',\n",
       " NNP -> 'Garden',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ VP,\n",
       " VBZ -> \"'s\",\n",
       " VP -> VBD NP,\n",
       " VBD -> 'got',\n",
       " NP -> NP VP,\n",
       " NP -> JJ NNS,\n",
       " JJ -> 'red',\n",
       " NNS -> 'steps',\n",
       " VP -> VBG ADVP,\n",
       " VBG -> 'leading',\n",
       " ADVP -> RB PP,\n",
       " RB -> 'up',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'door',\n",
       " PP -> PP PP,\n",
       " PP -> IN NP,\n",
       " IN -> 'To',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'right',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> NP VP,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'old',\n",
       " NN -> 'church',\n",
       " VP -> VBG NP,\n",
       " VBG -> 'facing',\n",
       " NP -> DT JJ NNS,\n",
       " DT -> 'the',\n",
       " JJ -> 'large',\n",
       " NNS -> 'windows',\n",
       " NP -> NP PP,\n",
       " NP -> NP PP,\n",
       " NP -> CD,\n",
       " CD -> 'One',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'left',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> NP NP,\n",
       " NP -> DT NNS,\n",
       " DT -> 'the',\n",
       " NNS -> 'buildings',\n",
       " NP -> JJ NN,\n",
       " JJ -> 'gable',\n",
       " NN -> 'wall',\n",
       " S -> PP VP,\n",
       " PP -> VBG NP,\n",
       " VBG -> 'Facing',\n",
       " NP -> DT NNP,\n",
       " DT -> 'the',\n",
       " NNP -> 'Building',\n",
       " VP -> VP VP,\n",
       " VP -> VBZ NP PP,\n",
       " VBZ -> 'fronts',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'building',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'left',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'cafe',\n",
       " PP -> IN NP,\n",
       " IN -> 'in',\n",
       " NP -> NN,\n",
       " NN -> 'red',\n",
       " VP -> VP NP,\n",
       " VP -> VBZ,\n",
       " VBZ -> 'is',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'target',\n",
       " S -> PP NP VP,\n",
       " PP -> IN NP,\n",
       " IN -> 'At',\n",
       " NP -> NN NN,\n",
       " NN -> 'street',\n",
       " NN -> 'level',\n",
       " NP -> PRP,\n",
       " PRP -> 'it',\n",
       " VP -> VBZ NP,\n",
       " VBZ -> 'is',\n",
       " NP -> DT NN,\n",
       " DT -> 'a',\n",
       " NN -> 'shop',\n",
       " PP -> PP NP,\n",
       " PP -> PP VP,\n",
       " PP -> ADVP IN NP,\n",
       " ADVP -> RB,\n",
       " RB -> 'directly',\n",
       " IN -> 'in',\n",
       " NP -> NP PP,\n",
       " NP -> NN,\n",
       " NN -> 'front',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'grass',\n",
       " PP -> IN NP,\n",
       " IN -> 'at',\n",
       " NP -> NNS,\n",
       " NNS -> 'roads',\n",
       " VP -> VBP,\n",
       " VBP -> 'end',\n",
       " NP -> DT ADJP NN,\n",
       " DT -> 'the',\n",
       " ADJP -> JJ VBN,\n",
       " JJ -> 'twin',\n",
       " VBN -> 'towered',\n",
       " NN -> 'building',\n",
       " NP -> NP SBAR,\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'The',\n",
       " NN -> 'cafe',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP PP,\n",
       " NP -> DT NNS,\n",
       " DT -> 'some',\n",
       " NNS -> 'tables',\n",
       " PP -> IN NP,\n",
       " IN -> 'in',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'yard',\n",
       " SBAR -> WHNP S,\n",
       " WHNP -> WDT,\n",
       " WDT -> 'that',\n",
       " S -> VP,\n",
       " VP -> VBZ PP,\n",
       " VBZ -> 'looks',\n",
       " PP -> IN NP,\n",
       " IN -> 'like',\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'a',\n",
       " JJ -> 'western',\n",
       " NN -> 'saloon',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN JJ NN,\n",
       " DT -> 'The',\n",
       " NN -> 'corner',\n",
       " JJ -> 'old',\n",
       " NN -> 'building',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP SBAR,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'red',\n",
       " NN -> 'door',\n",
       " SBAR -> WHNP S,\n",
       " WHNP -> WDT,\n",
       " WDT -> 'that',\n",
       " S -> VP,\n",
       " VP -> VBZ PP,\n",
       " VBZ -> 'looks',\n",
       " PP -> IN NP,\n",
       " IN -> 'like',\n",
       " NP -> DT NN,\n",
       " DT -> 'a',\n",
       " NN -> 'church',\n",
       " NP -> NP PP PP,\n",
       " NP -> DT NN NN,\n",
       " DT -> 'The',\n",
       " NN -> 'corner',\n",
       " NN -> 'building',\n",
       " PP -> IN NP,\n",
       " IN -> 'across',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'street',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP PP,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'small',\n",
       " NN -> 'yard',\n",
       " PP -> IN NP,\n",
       " IN -> 'in',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'front',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'The',\n",
       " NN -> 'shop',\n",
       " PP -> ADVP IN NP,\n",
       " ADVP -> RB,\n",
       " RB -> 'right',\n",
       " IN -> 'beside',\n",
       " NP -> DT `` JJ NN '',\n",
       " DT -> 'the',\n",
       " `` -> '\"',\n",
       " JJ -> 'elephant',\n",
       " NN -> 'house',\n",
       " '' -> '\"',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'store',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'red',\n",
       " NN -> 'facade',\n",
       " S -> VP,\n",
       " VP -> VB PP,\n",
       " VB -> 'Look',\n",
       " PP -> IN NP,\n",
       " IN -> 'at',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'building',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> PRP$ NN,\n",
       " PRP$ -> 'your',\n",
       " NN -> 'right',\n",
       " S -> VP,\n",
       " VP -> VB PP,\n",
       " VB -> 'Look',\n",
       " PP -> IN NP,\n",
       " IN -> 'at',\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'square',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> PRP$ NN,\n",
       " PRP$ -> 'your',\n",
       " NN -> 'right',\n",
       " S -> NP VP,\n",
       " NP -> DT NN,\n",
       " DT -> 'The',\n",
       " NN -> 'target',\n",
       " VP -> VBZ NP,\n",
       " VBZ -> 'is',\n",
       " NP -> NP PP,\n",
       " NP -> DT NNP NNP,\n",
       " DT -> 'the',\n",
       " NNP -> 'Festival',\n",
       " NNP -> 'Theater',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> NNP NNP,\n",
       " NNP -> 'North',\n",
       " NNP -> 'Bridge',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ NP,\n",
       " VBZ -> 'is',\n",
       " NP -> NP VP,\n",
       " NP -> DT JJ ADJP JJ NN,\n",
       " DT -> 'a',\n",
       " JJ -> 'large',\n",
       " ADJP -> NN VBN,\n",
       " NN -> 'glass',\n",
       " VBN -> 'fronted',\n",
       " JJ -> 'modern',\n",
       " NN -> 'building',\n",
       " VP -> ADVP VBN HYPH RP PP,\n",
       " ADVP -> RB,\n",
       " RB -> 'slightly',\n",
       " VBN -> 'set',\n",
       " HYPH -> '-',\n",
       " RP -> 'back',\n",
       " PP -> IN NP,\n",
       " IN -> 'from',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'road',\n",
       " S -> NP VP,\n",
       " NP -> NP PP,\n",
       " NP -> DT NN,\n",
       " DT -> 'A',\n",
       " NN -> 'bar',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> DT NNP NNP,\n",
       " DT -> 'the',\n",
       " NNP -> 'Royal',\n",
       " NNP -> 'Mile',\n",
       " VP -> VBN S,\n",
       " VBN -> 'called',\n",
       " S -> NP,\n",
       " NP -> NNP NNPS,\n",
       " NNP -> 'Deacon',\n",
       " NNPS -> 'Brodies',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ NP,\n",
       " VBZ -> 'has',\n",
       " NP -> NP PP,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'an',\n",
       " JJ -> 'ornate',\n",
       " NN -> 'front',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> DT ADJP NNS,\n",
       " DT -> 'some',\n",
       " ADJP -> JJ VBN,\n",
       " JJ -> 'gold',\n",
       " VBN -> 'coloured',\n",
       " NNS -> 'parts',\n",
       " FRAG -> ADVP VP,\n",
       " ADVP -> RB,\n",
       " RB -> 'Also',\n",
       " VP -> VBZ NP PP,\n",
       " VBZ -> 'has',\n",
       " NP -> DT VBG NNS,\n",
       " DT -> 'some',\n",
       " VBG -> 'hanging',\n",
       " NNS -> 'plants',\n",
       " PP -> IN NP,\n",
       " IN -> 'outside',\n",
       " NP -> PRP,\n",
       " PRP -> 'it',\n",
       " NP -> NP PP PP,\n",
       " NP -> DT NNP,\n",
       " DT -> 'The',\n",
       " NNP -> 'Assembly',\n",
       " PP -> IN NP,\n",
       " IN -> 'up',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'hill',\n",
       " PP -> IN NP,\n",
       " IN -> 'from',\n",
       " NP -> NP PP,\n",
       " NP -> DT NNP NNPS,\n",
       " DT -> 'the',\n",
       " NNP -> 'Art',\n",
       " NNPS -> 'Galleries',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> NNP NNP,\n",
       " NNP -> 'Princess',\n",
       " NNP -> 'Street',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ PP,\n",
       " VBZ -> 'looks',\n",
       " PP -> IN NP,\n",
       " IN -> 'like',\n",
       " NP -> NP PP,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'an',\n",
       " JJ -> 'old',\n",
       " NN -> 'church',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP PP,\n",
       " NP -> JJ NNS,\n",
       " JJ -> 'red',\n",
       " NNS -> 'banners',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> PRP,\n",
       " PRP -> 'it',\n",
       " NP -> NP PP,\n",
       " NP -> DT JJ NN NN,\n",
       " DT -> 'The',\n",
       " JJ -> 'old',\n",
       " NN -> 'stone',\n",
       " NN -> 'house',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP PP,\n",
       " NP -> DT ADJP NN,\n",
       " DT -> 'a',\n",
       " ADJP -> JJ JJ,\n",
       " JJ -> 'greeny',\n",
       " JJ -> 'blue',\n",
       " NN -> 'door',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> NNP NNP,\n",
       " NNP -> 'Moray',\n",
       " NNP -> 'Place',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ NP PP,\n",
       " VBZ -> 'has',\n",
       " NP -> NP CC NP,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'a',\n",
       " JJ -> 'black',\n",
       " NN -> 'fence',\n",
       " CC -> 'and',\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'a',\n",
       " JJ -> 'red',\n",
       " NN -> 'postbox',\n",
       " PP -> IN NP,\n",
       " IN -> 'outside',\n",
       " NP -> PRP,\n",
       " PRP -> 'it',\n",
       " NP -> NP PP,\n",
       " NP -> NP VP,\n",
       " NP -> DT NNP NNP,\n",
       " DT -> 'The',\n",
       " NNP -> 'Italian',\n",
       " NNP -> 'Restaurant',\n",
       " VP -> VBN S,\n",
       " VBN -> 'called',\n",
       " S -> NP,\n",
       " NP -> NNP,\n",
       " NNP -> 'Amarone',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> NP NNP,\n",
       " NP -> NNP NNP POS,\n",
       " NNP -> 'St',\n",
       " NNP -> 'Andrew',\n",
       " POS -> \"'s\",\n",
       " NNP -> 'Square',\n",
       " NP -> PRP$ ADJP,\n",
       " PRP$ -> 'Its',\n",
       " ADJP -> JJ JJ,\n",
       " JJ -> 'black',\n",
       " JJ -> 'coloured',\n",
       " S -> NP VP,\n",
       " NP -> NP,\n",
       " NP -> PRP,\n",
       " PRP -> 'It',\n",
       " VP -> VBZ ADJP SBAR,\n",
       " VBZ -> 'is',\n",
       " ADJP -> JJ,\n",
       " JJ -> 'unique',\n",
       " SBAR -> WHADVP S,\n",
       " WHADVP -> WRB,\n",
       " WRB -> 'how',\n",
       " S -> NP VP,\n",
       " NP -> PRP,\n",
       " PRP -> 'it',\n",
       " VP -> VBZ NP PP,\n",
       " VBZ -> 'provides',\n",
       " NP -> DT NN,\n",
       " DT -> 'a',\n",
       " NN -> 'focus',\n",
       " PP -> IN NP,\n",
       " IN -> 'to',\n",
       " NP -> DT NN,\n",
       " DT -> 'the',\n",
       " NN -> 'area',\n",
       " NP -> NP PP,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'old',\n",
       " NN -> 'church',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP PP,\n",
       " NP -> JJ,\n",
       " JJ -> 'bold',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> JJ NN,\n",
       " JJ -> 'red',\n",
       " NN -> 'door',\n",
       " NP -> NP PP PP,\n",
       " NP -> DT JJ CD NNS,\n",
       " DT -> 'The',\n",
       " JJ -> 'huge',\n",
       " CD -> '5',\n",
       " NNS -> 'storeys',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> NP PP,\n",
       " NP -> VBG NP,\n",
       " VBG -> 'building',\n",
       " NP -> NN NN,\n",
       " NN -> 'castle',\n",
       " NN -> 'style',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> NN,\n",
       " NN -> 'architecture',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NP PP,\n",
       " NP -> ADJP NN CC NN,\n",
       " ADJP -> RB JJ,\n",
       " RB -> 'very',\n",
       " JJ -> 'dominant',\n",
       " NN -> 'tower',\n",
       " CC -> 'and',\n",
       " NN -> 'dome',\n",
       " PP -> IN NP,\n",
       " IN -> 'on',\n",
       " NP -> NP PP,\n",
       " NP -> NN,\n",
       " NN -> 'top',\n",
       " PP -> IN NP,\n",
       " IN -> 'of',\n",
       " NP -> PRP,\n",
       " PRP -> 'it',\n",
       " S -> NP CC VP,\n",
       " NP -> NP PP,\n",
       " NP -> DT JJ NN,\n",
       " DT -> 'the',\n",
       " JJ -> 'symmetrical',\n",
       " NN -> 'facade',\n",
       " PP -> IN NP,\n",
       " IN -> 'with',\n",
       " NP -> NML NN,\n",
       " NML -> CD NNS,\n",
       " CD -> '3',\n",
       " NNS -> 'storeys',\n",
       " NN -> 'height',\n",
       " CC -> 'and',\n",
       " VP -> VB PP,\n",
       " VB -> 'look',\n",
       " PP -> IN NP,\n",
       " IN -> 'at',\n",
       " NP -> NP PP,\n",
       " NP -> PRP NN,\n",
       " ...]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. collect all the parse trees\n",
    "trees = []\n",
    "for doc in nlp.pipe(unique_sents_unpunct):\n",
    "    for sent in doc.sents:\n",
    "        bracketed = sent._.parse_string     # \"(S (NP …) (VP …))\"\n",
    "        tree = Tree.fromstring(bracketed)\n",
    "        # print(tree)\n",
    "        trees.append(tree)\n",
    "\n",
    "\n",
    "# 3. extract productions\n",
    "all_prods = []\n",
    "for t in trees:\n",
    "    all_prods += t.productions()\n",
    "\n",
    "# 4. build a grammar (dedupe productions)\n",
    "start_sym = trees[0].label()           # usually 'S'\n",
    "\n",
    "prods = list({ p for p in all_prods })  # set-dedupe, original producing 2000 cfg rules\n",
    "grammar = CFG(Nonterminal(start_sym), prods)\n",
    "\n",
    "all_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b5e51fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15429"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "75c1c087",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: '\"\\'\", \\'Brodie\\', \"\\'s\"'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test on the first sentence\u001b[39;00m\n\u001b[1;32m      2\u001b[0m test_sent \u001b[38;5;241m=\u001b[39m trees[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mleaves()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# #     # t.pretty_print()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(t)\n",
      "File \u001b[0;32m~/projects/populate-ns-lex/venv/lib/python3.9/site-packages/nltk/parse/chart.py:1474\u001b[0m, in \u001b[0;36mChartParser.parse\u001b[0;34m(self, tokens, tree_class)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, tree_class\u001b[38;5;241m=\u001b[39mTree):\n\u001b[0;32m-> 1474\u001b[0m     chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchart_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(chart\u001b[38;5;241m.\u001b[39mparses(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\u001b[38;5;241m.\u001b[39mstart(), tree_class\u001b[38;5;241m=\u001b[39mtree_class))\n",
      "File \u001b[0;32m~/projects/populate-ns-lex/venv/lib/python3.9/site-packages/nltk/parse/earleychart.py:352\u001b[0m, in \u001b[0;36mIncrementalChartParser.chart_parse\u001b[0;34m(self, tokens, trace)\u001b[0m\n\u001b[1;32m    349\u001b[0m trace_new_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_new_edges\n\u001b[1;32m    351\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tokens)\n\u001b[0;32m--> 352\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grammar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_coverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chart_class(tokens)\n\u001b[1;32m    354\u001b[0m grammar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\n",
      "File \u001b[0;32m~/projects/populate-ns-lex/venv/lib/python3.9/site-packages/nltk/grammar.py:666\u001b[0m, in \u001b[0;36mCFG.check_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m    665\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m missing)\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrammar does not cover some of the \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput words: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m missing\n\u001b[1;32m    668\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: '\"\\'\", \\'Brodie\\', \"\\'s\"'."
     ]
    }
   ],
   "source": [
    "# test on the first sentence\n",
    "test_sent = trees[0].leaves()\n",
    "\n",
    "for t in parser.parse(test_sent):\n",
    "# #     # t.pretty_print()\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d604e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48cb60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25698\n"
     ]
    }
   ],
   "source": [
    "# 4. build a grammar (dedupe productions)\n",
    "start_sym = trees[0].label()           \n",
    "\n",
    "prods = list({ p for p in all_prods })  # set-dedupe, original producing 2000 cfg rules\n",
    "grammar = CFG(Nonterminal(start_sym), prods)\n",
    "\n",
    "punct_tags = {\",\", \":\", \"``\", \"''\", \".\", \"(\", \")\", \"--\"}\n",
    "filtered_prods = [\n",
    "  p for p in all_prods\n",
    "  if not any(\n",
    "    isinstance(sym, Nonterminal) and sym.symbol() in punct_tags\n",
    "    for sym in p.rhs()\n",
    "  )\n",
    "]\n",
    "# grammar = CFG(Nonterminal(start_sym), filtered_prods) # producing 26k++ rules\n",
    "print(len(filtered_prods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# punct_tags = {\",\", \":\", \"``\", \"''\", \".\", \"(\", \")\", \"--\"}\n",
    "# filtered_prods = [\n",
    "#   p for p in all_prods\n",
    "#   if not any(\n",
    "#     isinstance(sym, Nonterminal) and sym.symbol() in punct_tags\n",
    "#     for sym in p.rhs()\n",
    "#   )\n",
    "# ]\n",
    "# grammar = CFG(Nonterminal(start_sym), filtered_prods) # producing 25k+ rules\n",
    "# # before you extract productions, do for each tree:\n",
    "# for t in trees:\n",
    "#     # this will break any rule X → A B C D … into a chain of binaries\n",
    "#     Tree.chomsky_normal_form(t, horzMarkov=2)\n",
    "\n",
    "# # extract production to keep RHS at length 2 or 1\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "# counts = Counter(all_prods)\n",
    "# keep = [p for p in all_prods if counts[p] > 1]   # e.g. freq > 1\n",
    "# grammar = CFG(Nonterminal(start_sym), list({p for p in keep}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cba191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb59b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 1254 productions (start state = NP)\n",
      "    VP -> MD PP\n",
      "    VBN -> 'named'\n",
      "    NN -> 'blind'\n",
      "    NNS -> 'pillars'\n",
      "    NN -> 'archway'\n",
      "    NN -> 'person'\n",
      "    NN -> 'postbox'\n",
      "    ADJP -> CD HYPH VBN\n",
      "    JJ -> 'beautiful'\n",
      "    NNS -> 'tables'\n",
      "    NP -> NP , ADJP\n",
      "    NN -> 'clock'\n",
      "    NP -> DT NNP\n",
      "    NN -> 'day'\n",
      "    NN -> 'image'\n",
      "    NP -> DT JJ , JJ NN\n",
      "    IN -> 'in'\n",
      "    NN -> 'style'\n",
      "    VP -> VBZ ADVP VP\n",
      "    RB -> 'directly'\n",
      "    JJ -> 'opposite'\n",
      "    VBN -> 'passed'\n",
      "    JJ -> 'vertical'\n",
      "    NN -> 'design'\n",
      "    IN -> 'up'\n",
      "    VP -> VBP VP\n",
      "    VB -> 'look'\n",
      "    NN -> 'outside'\n",
      "    NN -> 'tavern'\n",
      "    S -> NP\n",
      "    NN -> 'colour'\n",
      "    NNP -> 'Castro'\n",
      "    NN -> 'pyramid'\n",
      "    NP -> DT NML JJ NN\n",
      "    JJ -> 'outside'\n",
      "    IN -> 'from'\n",
      "    S -> CC NP VP\n",
      "    NNP -> 'Carlton'\n",
      "    NP -> JJ PP\n",
      "    NN -> 'part'\n",
      "    JJ -> 'pretty'\n",
      "    ADVP -> RBS RB\n",
      "    NP -> NNS NN\n",
      "    VBN -> 'nestled'\n",
      "    RBS -> 'least'\n",
      "    : -> '-'\n",
      "    NP -> DT JJ , NML NN\n",
      "    NNP -> 'Church'\n",
      "    JJ -> 'twin'\n",
      "    DT -> 'no'\n",
      "    DT -> 'an'\n",
      "    NN -> 'board'\n",
      "    DT -> 'The'\n",
      "    SQ -> VBP NP VP\n",
      "    NNP -> 'Frankenstein'\n",
      "    S -> S , NP VP\n",
      "    NN -> 'stone'\n",
      "    RB -> 'probably'\n",
      "    VBN -> 'set'\n",
      "    JJ -> 'large'\n",
      "    SBAR -> WHADVP S\n",
      "    NN -> 'thing'\n",
      "    NN -> 'couple'\n",
      "    NN -> 'wall'\n",
      "    IN -> 'inbetween'\n",
      "    NNS -> 'windows'\n",
      "    NNS -> 'doors'\n",
      "    JJ -> 'interior'\n",
      "    VB -> 'locate'\n",
      "    JJ -> 'Modern'\n",
      "    JJ -> 'detailed'\n",
      "    NN -> 'effect'\n",
      "    IN -> 'around'\n",
      "    JJ -> 'gray'\n",
      "    JJ -> 'octagonal'\n",
      "    NNP -> 'Basil'\n",
      "    NN -> 'name'\n",
      "    ADJP -> RB PP\n",
      "    CD -> '+Θ-¼'\n",
      "    PP -> NP IN NP\n",
      "    PRP -> 'You'\n",
      "    NN -> 'scene'\n",
      "    JJ -> 'towered'\n",
      "    NN -> 'river'\n",
      "    '' -> \"'\"\n",
      "    VP -> VBN PP PP\n",
      "    VBP -> 'do'\n",
      "    NNS -> 'menus'\n",
      "    NNS -> 'princes'\n",
      "    DT -> 'either'\n",
      "    VBG -> 'flying'\n",
      "    S -> ADVP NP VP\n",
      "    NNS -> 'blinds'\n",
      "    NNS -> 'stones'\n",
      "    NP -> JJ JJ NNS\n",
      "    NNP -> 'Edinburgh'\n",
      "    JJ -> 'external'\n",
      "    JJ -> 'orange'\n",
      "    NN -> 'line'\n",
      "    NN -> 'edge'\n",
      "    NN -> 'cabin'\n",
      "    NN -> 'Cafe'\n",
      "    JJ -> 'second'\n",
      "    NNS -> 'ones'\n",
      "    NNP -> 'Amarone'\n",
      "    NP -> NP ADVP\n",
      "    JJ -> 'typical'\n",
      "    ADJP -> ADJP JJ\n",
      "    NP -> JJR NNS\n",
      "    VP -> VBN NP\n",
      "    NNS -> 'things'\n",
      "    JJ -> 'cool'\n",
      "    NN -> 'architecture'\n",
      "    NN -> 'balcony'\n",
      "    NN -> 'metal'\n",
      "    PRT -> RP\n",
      "    VBG -> 'standing'\n",
      "    RB -> 'front'\n",
      "    NN -> 'column'\n",
      "    NP -> `` NP ''\n",
      "    NN -> 'police'\n",
      "    NN -> 'end'\n",
      "    VP -> VBG NP\n",
      "    NN -> 'something'\n",
      "    DT -> 'that'\n",
      "    NNP -> 'Exhibition'\n",
      "    RB -> 'about'\n",
      "    JJ -> '1st'\n",
      "    NNP -> 'Cathedral'\n",
      "    VB -> 'get'\n",
      "    NP -> DT NNP NNP\n",
      "    ADJP -> RB RB PP\n",
      "    NNP -> 'Festival'\n",
      "    ADJP -> JJ HYPH VBG\n",
      "    NML -> NN HYPH NN\n",
      "    ADJP -> NP JJ\n",
      "    NN -> 'street'\n",
      "    ADVP -> RB IN\n",
      "    S -> NP PP PP\n",
      "    NP -> NP , PP\n",
      "    VBN -> 'stained'\n",
      "    ADJP -> ADJP CC ADJP\n",
      "    VB -> 'See'\n",
      "    PRP -> 'us'\n",
      "    VB -> 'find'\n",
      "    NNS -> 'lots'\n",
      "    JJR -> 'older'\n",
      "    RB -> 'nearby'\n",
      "    JJ -> 'Old'\n",
      "    CD -> '4'\n",
      "    NP -> ADJP NNS\n",
      "    NML -> NNP NNP\n",
      "    RB -> 'up'\n",
      "    HYPH -> '+Θ-'\n",
      "    JJ -> 'Blue'\n",
      "    VBZ -> 'happens'\n",
      "    JJ -> 'possible'\n",
      "    JJ -> 'interesting'\n",
      "    VBN -> 'surrounded'\n",
      "    VBG -> 'being'\n",
      "    NP -> DT NML\n",
      "    RB -> 'now'\n",
      "    NP -> NP , CC NP\n",
      "    NP -> NP RB\n",
      "    NP -> DT JJ NML NN\n",
      "    NP -> DT NNPS\n",
      "    VP -> VBG NP NP\n",
      "    NN -> 'cream'\n",
      "    VB -> 'Point'\n",
      "    NML -> JJ NNP\n",
      "    NN -> 'sand'\n",
      "    VP -> VB ADJP\n",
      "    NN -> 'block'\n",
      "    RB -> 'immediately'\n",
      "    CD -> 'three'\n",
      "    PP -> IN ADVP\n",
      "    JJ -> 'full'\n",
      "    DT -> 'this'\n",
      "    NN -> 'structure'\n",
      "    NP -> DT JJ NN SYM NN\n",
      "    NN -> 'interest'\n",
      "    NN -> 'cupola'\n",
      "    S -> RB VP\n",
      "    NP -> JJ CD\n",
      "    NN -> \n",
      "    EX -> 'There'\n",
      "    VP -> VBZ NP\n",
      "    VP -> VBP RB VP\n",
      "    PP -> ADVP IN NP\n",
      "    JJ -> \n",
      "    JJ -> 'greek'\n",
      "    VP -> VBZ NP PP PP\n",
      "    JJ -> 'beige'\n",
      "    NP -> JJ NN\n",
      "    NN -> 'suruchi'\n",
      "    IN -> 'below'\n",
      "    NN -> 'Pub'\n",
      "    JJ -> 'circular'\n",
      "    ADJP -> JJ HYPH VBN\n",
      "    SBAR -> WHNP S\n",
      "    ADJP -> VBN PP\n",
      "    NP -> CD NNS\n",
      "    VBN -> 'called'\n",
      "    NN -> 'base'\n",
      "    NP -> NML NN NN\n",
      "    RB -> 'temporarily'\n",
      "    NN -> 'wood'\n",
      "    NN -> 'height'\n",
      "    DT -> 'some'\n",
      "    JJ -> 'gold'\n",
      "    VP -> VBZ ADJP SBAR\n",
      "    JJ -> 'grassy'\n",
      "    NN -> 'copper'\n",
      "    ADJP -> JJ CC JJ\n",
      "    ADVP -> ADVP PP\n",
      "    NN -> 'home'\n",
      "    -RRB- -> '?'\n",
      "    CC -> 'And'\n",
      "    JJ -> 'nice'\n",
      "    NN -> 'doorway'\n",
      "    JJ -> 'cobbled'\n",
      "    NP -> NML NN\n",
      "    VP -> VBG PRT PP\n",
      "    NP -> DT JJ JJ NNS\n",
      "    NP -> CD JJ NN NNS\n",
      "    RP -> 'out'\n",
      "    NNP -> 'Cashmere'\n",
      "    NN -> 'frankenstein'\n",
      "    JJ -> 'blue'\n",
      "    VBD -> 'got'\n",
      "    NNP -> 'Monument'\n",
      "    VBG -> 'looking'\n",
      "    JJ -> 'long'\n",
      "    NN -> 'guest'\n",
      "    NN -> 'branch'\n",
      "    VP -> VB\n",
      "    JJ -> 'Georgian'\n",
      "    NP -> DT NN NN\n",
      "    NNS -> 'Poundsavers'\n",
      "    JJR -> 'lower'\n",
      "    NN -> 'bend'\n",
      "    NN -> 'pediment'\n",
      "    NN -> 'entry'\n",
      "    ADJP -> ADVP JJ\n",
      "    RB -> 'rather'\n",
      "    NN -> 'museum'\n",
      "    NN -> 'maroon'\n",
      "    JJ -> 'many'\n",
      "    JJ -> 'golden'\n",
      "    IN -> 'off'\n",
      "    NN -> 'pole'\n",
      "    `` -> '-LSB-'\n",
      "    S -> PP , NP VP\n",
      "    PP -> IN S\n",
      "    NNS -> 'awnings'\n",
      "    NML -> NNP NNP NNP\n",
      "    NN -> 'group'\n",
      "    NNS -> 'curtains'\n",
      "    NP -> NP , NP\n",
      "    NN -> 'statue'\n",
      "    NP -> RB JJ NN\n",
      "    JJ -> 'victorian'\n",
      "    NNP -> 'Brodie'\n",
      "    PRP -> 'itself'\n",
      "    NN -> 'tower'\n",
      "    NP -> CD JJ NNS\n",
      "    NP -> NP : NP\n",
      "    NN -> 'photo'\n",
      "    VP -> VBP\n",
      "    VP -> VBP NP PP\n",
      "    JJ -> 'reddish'\n",
      "    NNS -> 'gables'\n",
      "    NN -> 'shopfront'\n",
      "    ADJP -> JJ HYPH JJ\n",
      "    JJ -> 'classical'\n",
      "    NN -> 'bunch'\n",
      "    JJ -> 'next'\n",
      "    JJ -> 'only'\n",
      "    IN -> 'before'\n",
      "    NNS -> 'seats'\n",
      "    NP -> DT CD JJ NN NNS\n",
      "    ADJP -> JJ SYM JJ\n",
      "    S -> S , S\n",
      "    PRP -> \n",
      "    PP -> IN ADJP\n",
      "    JJ -> 'similar'\n",
      "    NP -> DT NNP NNPS\n",
      "    NP -> NP IN NP\n",
      "    NML -> NN NN\n",
      "    NNS -> 'corners'\n",
      "    NN -> 'right'\n",
      "    NP -> DT VBG NNS\n",
      "    IN -> 'than'\n",
      "    NML -> CD NN\n",
      "    IN -> 'On'\n",
      "    RB -> 'closest'\n",
      "    NP -> NNP JJ NN\n",
      "    NN -> 'sign'\n",
      "    VBN -> 'faced'\n",
      "    JJ -> 'right'\n",
      "    NP -> NP , PP , PP\n",
      "    JJ -> 'upper'\n",
      "    NN -> 'bar'\n",
      "    VBG -> 'moving'\n",
      "    NNS -> 'bikes'\n",
      "    NNS -> 'flowers'\n",
      "    JJ -> 'elephant'\n",
      "    NP -> DT ADJP NNS\n",
      "    NNP -> 'The'\n",
      "    NNS -> 'arches'\n",
      "    NN -> 'granite'\n",
      "    NP -> NP -LRB- NP -RRB-\n",
      "    JJ -> 'high'\n",
      "    NP -> DT CD NNS\n",
      "    VP -> VBD PP PP\n",
      "    NN -> 'cathedral'\n",
      "    NN -> 'side'\n",
      "    NP -> ADJP JJ NN\n",
      "    S -> NP NP VP\n",
      "    NN -> 'steeple'\n",
      "    VP -> TO VP\n",
      "    NN -> 'garage'\n",
      "    NNP -> 'Thai'\n",
      "    NN -> 'van'\n",
      "    PRP -> 'i'\n",
      "    PP -> PP , PP\n",
      "    NN -> 'car'\n",
      "    JJ -> 'whole'\n",
      "    NN -> 'ground'\n",
      "    S -> '' NP VP\n",
      "    IN -> 'under'\n",
      "    JJ -> 'historic'\n",
      "    VBG -> 'overlooking'\n",
      "    PRP -> 'we'\n",
      "    NNP -> 'National'\n",
      "    NN -> 'flat'\n",
      "    JJ -> 'ground'\n",
      "    VP -> VBZ SBAR\n",
      "    NNS -> 'people'\n",
      "    NN -> 'subway'\n",
      "    NP -> CD\n",
      "    RB -> 'alone'\n",
      "    JJ -> 'flat'\n",
      "    VP -> VBG PP\n",
      "    NNP -> 'Mile'\n",
      "    NNP -> 'New'\n",
      "    JJ -> 'good'\n",
      "    VB -> 'Look'\n",
      "    VBG -> 'starting'\n",
      "    CD -> '1'\n",
      "    ADVP -> JJ\n",
      "    NN -> 'House'\n",
      "    IN -> 'against'\n",
      "    NP -> NN\n",
      "    IN -> 'In'\n",
      "    NP -> DT NN NN NN\n",
      "    NN -> 'building'\n",
      "    NNP -> 'Moray'\n",
      "    NN -> 'scaffolding'\n",
      "    VP -> VBP S\n",
      "    NNP -> 'Fraser'\n",
      "    JJ -> 'pointed'\n",
      "    NP -> NP\n",
      "    VB -> 'ask'\n",
      "    NNP -> 'Decon'\n",
      "    NN -> 'set'\n",
      "    NN -> 'ness'\n",
      "    UCP -> ADVP CC PP\n",
      "    JJ -> 'white'\n",
      "    S -> PP NP VP\n",
      "    NP -> VBN NN\n",
      "    NN -> 'strip'\n",
      "    JJ -> 'Grey'\n",
      "    NN -> 'google'\n",
      "    VBG -> 'hanging'\n",
      "    NP -> NP PP ADVP\n",
      "    NN -> 'red'\n",
      "    NP -> DT CD JJ NNS\n",
      "    VP -> VBN PP\n",
      "    VP -> VBG NP PP\n",
      "    `` -> \"'\"\n",
      "    NNS -> 'bricks'\n",
      "    VBG -> 'wearing'\n",
      "    NNS -> 'stories'\n",
      "    VBN -> 'parked'\n",
      "    JJ -> 'red'\n",
      "    NP -> JJS NN\n",
      "    NN -> 'criss'\n",
      "    NN -> 'water'\n",
      "    NN -> 'gap'\n",
      "    NP -> NP NNP NNP\n",
      "    NP -> JJ NNP\n",
      "    NP -> JJ JJ NN\n",
      "    NNP -> 'Hart'\n",
      "    NP -> JJ NN NNS\n",
      "    NNP -> 'Street'\n",
      "    RB -> 'back'\n",
      "    RB -> 'before'\n",
      "    NP -> NN CC NN\n",
      "    NNS -> 'lights'\n",
      "    NP -> QP NNS\n",
      "    ADJP -> RB JJ\n",
      "    NP -> NP , SBAR\n",
      "    CD -> '7'\n",
      "    NNS -> 'feet'\n",
      "    ADJP -> NP HYPH VBN\n",
      "    NN -> 'shape'\n",
      "    NP -> DT NML NN NN\n",
      "    NNP -> 'Bridge'\n",
      "    NN -> 'pattern'\n",
      "    NN -> 'wedge'\n",
      "    NP -> PRP\n",
      "    MD -> 'will'\n",
      "    IN -> 'between'\n",
      "    NP -> JJ , JJ NN\n",
      "    VBN -> 'flanked'\n",
      "    IN -> 'for'\n",
      "    NN -> 'bronze'\n",
      "    VBN -> 'painted'\n",
      "    JJ -> 'ugly'\n",
      "    NP -> NML NNP\n",
      "    ADJP -> RB JJ PP\n",
      "    NP -> PRP POS\n",
      "    VP -> VBP ADVP VP\n",
      "    NP -> JJR NN\n",
      "    JJ -> 'Black'\n",
      "    NN -> 'stop'\n",
      "    S -> `` NP\n",
      "    NN -> 'road'\n",
      "    VBZ -> \"'s\"\n",
      "    NP -> NNS CC NNS\n",
      "    JJ -> 'yellow'\n",
      "    NN -> 'sandwich'\n",
      "    NN -> 'verandah'\n",
      "    IN -> 'after'\n",
      "    S -> NP ADVP VP\n",
      "    ADVP -> RB RBS\n",
      "    VBN -> 'capped'\n",
      "    NN -> 'pillar'\n",
      "    VBN -> 'pointed'\n",
      "    NNS -> 'storeys'\n",
      "    NN -> 'booth'\n",
      "    NNS -> 'stairs'\n",
      "    NP -> NNP POS\n",
      "    NNPS -> 'Gardens'\n",
      "    VP -> MD VP\n",
      "    NN -> 'Building'\n",
      "    NP -> CD JJ JJ JJ NNS\n",
      "    NP -> NN CD\n",
      "    JJ -> 'quaint'\n",
      "    JJ -> 'shaped'\n",
      "    IN -> 'towards'\n",
      "    NN -> 'arch'\n",
      "    NN -> 'pub'\n",
      "    JJ -> 'pointy'\n",
      "    NN -> 'letter'\n",
      "    NP -> DT JJ\n",
      "    NNS -> 'floors'\n",
      "    VP -> VBD S\n",
      "    NP -> DT NML NNS\n",
      "    JJ -> 'third'\n",
      "    NN -> 'section'\n",
      "    NN -> 'complex'\n",
      "    NNS -> 'signs'\n",
      "    NN -> 'arrow'\n",
      "    CD -> '2'\n",
      "    JJS -> 'closest'\n",
      "    NNS -> 'balconies'\n",
      "    NN -> 'top'\n",
      "    NN -> 'facade'\n",
      "    CD -> 'five'\n",
      "    VP -> VBZ PP\n",
      "    VP -> NN\n",
      "    RB -> 'ahead'\n",
      "    CD -> 'Two'\n",
      "    VBN -> 'built'\n",
      "    JJ -> 'complete'\n",
      "    WHNP -> WP\n",
      "    NP -> NP PP PP\n",
      "    NN -> 'bit'\n",
      "    NN -> 'square'\n",
      "    S -> NP , PP CC VP\n",
      "    NP -> DT JJ NNS\n",
      "    JJ -> 'open'\n",
      "    NN -> 'plaque'\n",
      "    NNP -> 'North'\n",
      "    NN -> 'mile'\n",
      "    -RRB- -> '║'\n",
      "    JJ -> 'square'\n",
      "    NP -> NN SYM NN\n",
      "    NP -> NNP NNP NNP\n",
      "    NML -> CD HYPH NN\n",
      "    VP -> VBN S PP\n",
      "    NP -> DT JJ CD NNS\n",
      "    NN -> 'apartment'\n",
      "    NNS -> 'newsagents'\n",
      "    NN -> 'flag'\n",
      "    PRP$ -> 'its'\n",
      "    JJ -> 'same'\n",
      "    NN -> 'Church'\n",
      "    VP -> ADVP VBN PP\n",
      "    VP -> VP , CC VP\n",
      "    JJ -> 'fancy'\n",
      "    VP -> VBG ADVP PP\n",
      "    NNS -> 'shutters'\n",
      "    NN -> 'box'\n",
      "    PP -> PP NP VP\n",
      "    NN -> 'grass'\n",
      "    DT -> 'An'\n",
      "    ADJP -> ADJP SBAR\n",
      "    NN -> 'courtyard'\n",
      "    NN -> 'hand'\n",
      "    NN -> 'life'\n",
      "    IN -> 'into'\n",
      "    ADJP -> ADJP ADJP\n",
      "    VP -> VBZ NP ADVP\n",
      "    JJ -> 'several'\n",
      "    NP -> NML NNPS\n",
      "    NML -> NML CC NML\n",
      "    NP -> DT JJR JJ NN\n",
      "    VBN -> 'shaped'\n",
      "    NP -> NN NN\n",
      "    NNP -> 'City'\n",
      "    VBZ -> 'says'\n",
      "    IN -> 'near'\n",
      "    NN -> 'assembly'\n",
      "    NML -> NN\n",
      "    IN -> 'atop'\n",
      "    VP -> VP CC VP\n",
      "    NP -> CD NN\n",
      "    JJ -> 'brownish'\n",
      "    NNP -> 'Harry'\n",
      "    PRP$ -> 'our'\n",
      "    ADJP -> NN HYPH VBN\n",
      "    NN -> 'frame'\n",
      "    PP -> PP CC NP\n",
      "    NN -> 'bus'\n",
      "    WHADVP -> WRB\n",
      "    DT -> 'This'\n",
      "    JJ -> 'Narrow'\n",
      "    NNS -> 'bits'\n",
      "    ADJP -> NN HYPH JJ\n",
      "    JJ -> 'like'\n",
      "    VBZ -> 'looks'\n",
      "    NNS -> 'columns'\n",
      "    NP -> NP NNP NN\n",
      "    JJ -> 'double'\n",
      "    NML -> VBN NN\n",
      "    IN -> 'beyond'\n",
      "    CD -> 'one'\n",
      "    JJ -> 'tall'\n",
      "    QP -> ADVP CD\n",
      "    NN -> 'target'\n",
      "    NN -> 'bike'\n",
      "    NN -> 'close'\n",
      "    NN -> 'dog'\n",
      "    NN -> 'site'\n",
      "    CD -> '6'\n",
      "    NP -> RB\n",
      "    DT -> 'those'\n",
      "    JJ -> 'pink'\n",
      "    IN -> 'opposite'\n",
      "    VBG -> 'passing'\n",
      "    NP -> NNP\n",
      "    RB -> 'possibly'\n",
      "    JJ -> 'classic'\n",
      "    NN -> 'city'\n",
      "    NN -> 'script'\n",
      "    JJ -> 'left'\n",
      "    NN -> 'theatre'\n",
      "    NN -> 'sash'\n",
      "    SYM -> '/'\n",
      "    NNS -> 'parasols'\n",
      "    NN -> 'cafe'\n",
      "    NP -> NP RB RB NP\n",
      "    DT -> 'all'\n",
      "    ADJP -> JJ VBG\n",
      "    RB -> 'approx'\n",
      "    VP -> VBZ ADVP NP\n",
      "    NN -> 'sky'\n",
      "    NN -> 'word'\n",
      "    VB -> 'be'\n",
      "    VBZ -> 'is'\n",
      "    IN -> 'outside'\n",
      "    NN -> 'pizza'\n",
      "    NN -> 'distance'\n",
      "    NP -> DT ADJP JJ NN\n",
      "    NN -> 'construction'\n",
      "    NP -> ADVP NP\n",
      "    ADJP -> ADJP PP\n",
      "    NN -> 'exterior'\n",
      "    VBN -> 'made'\n",
      "    ADJP -> NN CC JJ\n",
      "    IN -> 'at'\n",
      "    PP -> ADVP PP\n",
      "    CD -> '18'\n",
      "    NNP -> 'Giles'\n",
      "    ADJP -> JJR\n",
      "    S -> NP , VP\n",
      "    SBAR -> SINV\n",
      "    RB -> 'so'\n",
      "    VP -> VBG ADVP\n",
      "    CD -> 'four'\n",
      "    NP -> CD NN NNS\n",
      "    NP -> DT NNP POS\n",
      "    JJ -> 'wide'\n",
      "    IN -> 'Across'\n",
      "    ADVP -> IN\n",
      "    NP -> PRP$ JJ\n",
      "    NP -> PRP$ ADJP\n",
      "    JJ -> 'huge'\n",
      "    NN -> 'traffic'\n",
      "    NP -> NP , SBAR ,\n",
      "    , -> ','\n",
      "    JJ -> 'royal'\n",
      "    JJS -> 'tallest'\n",
      "    DT -> 'All'\n",
      "    VB -> 'check'\n",
      "    VBN -> 'got'\n",
      "    NN -> 'woman'\n",
      "    RB -> 'Just'\n",
      "    RB -> 'far'\n",
      "    NP -> NN NN NN\n",
      "    VBG -> 'walking'\n",
      "    NP -> NP ADJP\n",
      "    VBP -> 'know'\n",
      "    JJ -> 'new'\n",
      "    NNP -> 'Rowling'\n",
      "    NN -> 'town'\n",
      "    DT -> 'the'\n",
      "    PP -> VBG NP\n",
      "    NN -> 'patisserie'\n",
      "    JJ -> 'green'\n",
      "    NNS -> 'POUNDSAVERS'\n",
      "    NN -> 'glass'\n",
      "    NNS -> 'steps'\n",
      "    VP -> VBN ADVP\n",
      "    POS -> \"'s\"\n",
      "    NN -> 'yard'\n",
      "    NNS -> 'turrets'\n",
      "    VBG -> 'having'\n",
      "    NNP -> 'Patisserie'\n",
      "    IN -> 'without'\n",
      "    MD -> 'can'\n",
      "    VBN -> 'left'\n",
      "    JJR -> 'closer'\n",
      "    CD -> '435'\n",
      "    PP -> PP , CC PP\n",
      "    VP -> VB PP\n",
      "    NN -> 'hall'\n",
      "    NNP -> 'Restaurant'\n",
      "    NN -> 'plinth'\n",
      "    IN -> 'inside'\n",
      "    NN -> 'tudor'\n",
      "    NP -> ADJP NN NN\n",
      "    VB -> 'think'\n",
      "    NNS -> 'houses'\n",
      "    NP -> NN CC JJ\n",
      "    NNS -> 'shades'\n",
      "    NN -> 'cashmere'\n",
      "    VP -> VBG PP PP\n",
      "    INTJ -> UH\n",
      "    VBZ -> 'seems'\n",
      "    VBP -> 'have'\n",
      "    NN -> 'ft'\n",
      "    JJ -> 'entire'\n",
      "    NN -> 'front'\n",
      "    RB -> 'diagonally'\n",
      "    JJ -> 'bright'\n",
      "    PP -> PP SBAR\n",
      "    VBD -> 'left'\n",
      "    NP -> NN RB\n",
      "    NN -> 'Art'\n",
      "    JJ -> 'front'\n",
      "    NP -> DT JJS\n",
      "    NP -> PRP$ JJ NN\n",
      "    S -> VP .\n",
      "    JJ -> 'brown'\n",
      "    NN -> 'office'\n",
      "    RB -> 'just'\n",
      "    PRP -> 'them'\n",
      "    ADVP -> JJ PP\n",
      "    '' -> '\"'\n",
      "    PRP$ -> 'Its'\n",
      "    FRAG -> PP , NP\n",
      "    -RRB- -> '-RRB-'\n",
      "    NNPS -> 'Poundsavers'\n",
      "    JJS -> 'nearest'\n",
      "    RB -> 'very'\n",
      "    VP -> VBZ ADJP PP\n",
      "    NP -> NP , NP , CC NP\n",
      "    NN -> 'door'\n",
      "    NNS -> 'stacks'\n",
      "    VBZ -> 'consists'\n",
      "    NP -> NP CC NP\n",
      "    NN -> 'weaving'\n",
      "    NP -> DT NN\n",
      "    NN -> 'elephant'\n",
      "    S -> VP\n",
      "    NNP -> 'College'\n",
      "    NP -> PDT DT NNS\n",
      "    ADJP -> JJ VBN\n",
      "    VBN -> 'located'\n",
      "    NN -> 'sandstone'\n",
      "    NP -> JJ ADJP NNS\n",
      "    NP -> NP PP , PP\n",
      "    RB -> 'outside'\n",
      "    HYPH -> '-'\n",
      "    IN -> 'along'\n",
      "    : -> ';'\n",
      "    JJ -> 'roman'\n",
      "    JJ -> 'Tall'\n",
      "    RB -> 'straight'\n",
      "    VBN -> 'seen'\n",
      "    JJ -> 'black'\n",
      "    JJ -> 'residential'\n",
      "    RP -> 'up'\n",
      "    ADJP -> JJ JJ\n",
      "    NP -> DT NNS\n",
      "    QP -> RB CD\n",
      "    NNS -> 'pedestrians'\n",
      "    VB -> 'Come'\n",
      "    NP -> DT CD NN NNS\n",
      "    JJ -> 'Big'\n",
      "    NN -> 'umbrella'\n",
      "    VP -> VBZ ADVP\n",
      "    IN -> 'down'\n",
      "    NNP -> 'Tavern'\n",
      "    NNP -> 'Potter'\n",
      "    ADJP -> RB JJ CC JJ\n",
      "    VB -> 'Walk'\n",
      "    NP -> EX\n",
      "    JJ -> 'historical'\n",
      "    NN -> 'view'\n",
      "    VBG -> 'sitting'\n",
      "    NP -> NP , ADVP\n",
      "    VP -> VBP ADJP\n",
      "    JJ -> 'coloured'\n",
      "    RB -> 'away'\n",
      "    JJ -> 'modern'\n",
      "    RB -> 'Not'\n",
      "    VP -> VBP SBAR\n",
      "    PP -> IN `` NP ''\n",
      "    MD -> 'would'\n",
      "    JJ -> 'grey'\n",
      "    NN -> 'area'\n",
      "    VB -> 'know'\n",
      "    ADVP -> RB RB\n",
      "    NN -> 'brick'\n",
      "    S -> S , CC S\n",
      "    JJ -> 'tiny'\n",
      "    JJ -> 'massive'\n",
      "    NNS -> 'galleries'\n",
      "    NN -> 'Statue'\n",
      "    PRP -> 'he'\n",
      "    NP -> DT NN NNS\n",
      "    NML -> JJ HYPH NN\n",
      "    JJ -> 'gothic'\n",
      "    NN -> 'coat'\n",
      "    WHPP -> IN WHNP\n",
      "    VP -> VBN PRT\n",
      "    NNP -> 'Garden'\n",
      "    PP -> IN PP\n",
      "    VP -> VB NP PP\n",
      "    IN -> 'behind'\n",
      "    IN -> 'by'\n",
      "    NNP -> 'Place'\n",
      "    PP -> PP CC PP\n",
      "    NNP -> 'Valerie'\n",
      "    NNP -> 'Town'\n",
      "    FW -> 'florentine'\n",
      "    NN -> 'Pound'\n",
      "    VP -> VB NP\n",
      "    IN -> 'to'\n",
      "    RB -> 'further'\n",
      "    RB -> 'too'\n",
      "    IN -> 'out'\n",
      "    NP -> NP NNP NNP -RRB- CD\n",
      "    JJ -> 'White'\n",
      "    -RRB- -> '-RSB-'\n",
      "    NP -> CD JJ JJ NNS\n",
      "    IN -> 'At'\n",
      "    NN -> 'art'\n",
      "    NNS -> 'cars'\n",
      "    PP -> PP , VP\n",
      "    WDT -> 'that'\n",
      "    RB -> \"n't\"\n",
      "    VBN -> 'situated'\n",
      "    NP -> DT NML NN\n",
      "    RB -> 'not'\n",
      "    IN -> 'Beside'\n",
      "    NP -> JJ NML NN\n",
      "    NNP -> 'Express'\n",
      "    ADVP -> RB PP\n",
      "    ADJP -> RB JJ HYPH JJ\n",
      "    NN -> 'sidewalk'\n",
      "    NN -> 'ade'\n",
      "    ADVP -> IN PP\n",
      "    JJ -> 'Thai'\n",
      "    VP -> VBZ ADVP PP\n",
      "    NN -> 'bay'\n",
      "    NP -> DT ADJP\n",
      "    NN -> 'church'\n",
      "    JJ -> 'round'\n",
      "    VBN -> 'coloured'\n",
      "    NN -> 'park'\n",
      "    S -> S NP VP\n",
      "    NN -> 'chapel'\n",
      "    VP -> VBP PP\n",
      "    RB -> 'infront'\n",
      "    VBG -> 'leading'\n",
      "    DT -> 'A'\n",
      "    . -> '!'\n",
      "    JJ -> 'looking'\n",
      "    WP -> 'what'\n",
      "    NN -> 'level'\n",
      "    NNS -> 'flags'\n",
      "    DT -> 'each'\n",
      "    JJ -> 'domed'\n",
      "    FW -> 'fa+Γª'\n",
      "    JJ -> 'central'\n",
      "    NP -> ADJP NN\n",
      "    VP -> VBZ PP ADVP\n",
      "    PP -> JJ NP\n",
      "    JJ -> 'New'\n",
      "    VBP -> 'see'\n",
      "    NN -> 'restaurant'\n",
      "    JJ -> 'indian'\n",
      "    CC -> 'or'\n",
      "    NNPS -> 'Galleries'\n",
      "    CD -> '3'\n",
      "    DT -> 'another'\n",
      "    NNP -> 'Deacon'\n",
      "    PRP -> 'me'\n",
      "    NNP -> 'Brodies'\n",
      "    NN -> 'valerie'\n",
      "    NNP -> 'St'\n",
      "    VP -> VB PRT NP\n",
      "    VBN -> 'blocked'\n",
      "    NP -> PRP$ NN\n",
      "    NN -> 'man'\n",
      "    NN -> 'entrance'\n",
      "    NN -> 'driveway'\n",
      "    JJ -> 'grand'\n",
      "    RB -> 'Also'\n",
      "    NN -> 'coffee'\n",
      "    NP -> NP , NP CC NP\n",
      "    JJ -> 'Red'\n",
      "    NN -> 'pedestrian'\n",
      "    WHNP -> WDT\n",
      "    PRP -> 'it'\n",
      "    NNP -> 'Elgin'\n",
      "    S -> INTJ , VP\n",
      "    JJ -> 'main'\n",
      "    ADVP -> RB RB PP\n",
      "    RB -> 'much'\n",
      "    RB -> 'there'\n",
      "    IN -> 'above'\n",
      "    NN -> 'Block'\n",
      "    RB -> 'down'\n",
      "    IN -> 'on'\n",
      "    NN -> 'shop'\n",
      "    S -> PRP$ NP\n",
      "    IN -> 'past'\n",
      "    NP -> NP NN\n",
      "    JJ -> 'Gothic'\n",
      "    JJ -> 'silver'\n",
      "    CD -> 'Three'\n",
      "    NNP -> 'Hotel'\n",
      "    UH -> 'no'\n",
      "    VP -> VBZ VP\n",
      "    NNS -> 'walls'\n",
      "    VP -> VBZ S\n",
      "    NNP -> 'Cafe'\n",
      "    JJ -> 'big'\n",
      "    NNP -> 'Assembly'\n",
      "    NP -> NP NP\n",
      "    JJ -> 'glassy'\n",
      "    NN -> 'spire'\n",
      "    IN -> 'of'\n",
      "    RB -> \n",
      "    WRB -> 'where'\n",
      "    NNP -> 'Royal'\n",
      "    ADJP -> JJ\n",
      "    NP -> NP , S\n",
      "    NP -> JJ NN CC NN\n",
      "    WP -> 'who'\n",
      "    VBZ -> 'has'\n",
      "    IN -> 'over'\n",
      "    NP -> DT JJ NN NN\n",
      "    MD -> 'ca'\n",
      "    JJ -> 'visible'\n",
      "    EX -> 'there'\n",
      "    VBZ -> 'Looks'\n",
      "    NN -> 'storey'\n",
      "    NN -> 'roof'\n",
      "    VBN -> 'covered'\n",
      "    NN -> 'centre'\n",
      "    JJ -> 'storey'\n",
      "    NN -> 'bank'\n",
      "    NP -> NNP NNP POS\n",
      "    NP -> DT JJ JJ NN\n",
      "    NN -> 'tree'\n",
      "    VP -> VBG PP ADVP\n",
      "    NNS -> 'poundsavers'\n",
      "    NP -> VBG NNS\n",
      "    NP -> DT JJ JJ JJ NN\n",
      "    NN -> 'tenement'\n",
      "    S -> ADVP VP\n",
      "    SBAR -> IN S\n",
      "    VP -> VBZ RB ADJP\n",
      "    NN -> 'festival'\n",
      "    NP -> DT ADJP NN NN\n",
      "    PP -> PP , PP ,\n",
      "    IN -> 'with'\n",
      "    NP -> DT JJS NN\n",
      "    VP -> VBG\n",
      "    FW -> 'suruchi'\n",
      "    VP -> VB SBAR\n",
      "    VP -> VBZ `` NP -RRB-\n",
      "    JJ -> 'outdoor'\n",
      "    PDT -> 'all'\n",
      "    NP -> NP CC PP\n",
      "    NP -> NNS\n",
      "    JJ -> 'half'\n",
      "    IN -> 'onto'\n",
      "    NN -> 'friend'\n",
      "    JJ -> 'slight'\n",
      "    NN -> 'rooftop'\n",
      "    JJ -> 'fun'\n",
      "    VBG -> 'including'\n",
      "    NNP -> 'Tartan'\n",
      "    NN -> 'place'\n",
      "    NN -> 'cherry'\n",
      "    JJ -> 'ancient'\n",
      "    NN -> 'cross'\n",
      "    VBN -> 'topped'\n",
      "    VP -> VBZ ADJP ADVP\n",
      "    NP -> JJ NN HYPH NN\n",
      "    VBP -> 'think'\n",
      "    NP -> NP , VP\n",
      "    JJ -> 'Small'\n",
      "    NN -> 'junction'\n",
      "    NN -> 'point'\n",
      "    PP -> IN NP\n",
      "    CD -> 'two'\n",
      "    NN -> 'chimney'\n",
      "    NP -> VBN NNS\n",
      "    UH -> 'Wow'\n",
      "    NP -> PRP$ JJ NN NN\n",
      "    . -> '?'\n",
      "    NP -> JJ\n",
      "    JJ -> 'symmetrical'\n",
      "    NN -> 'foreground'\n",
      "    NP -> CD ADJP NNS\n",
      "    NN -> 'pantheon'\n",
      "    VP -> VB ADVP\n",
      "    VB -> 'see'\n",
      "    NP -> NP PP , ADVP\n",
      "    ADJP -> JJR JJ\n",
      "    NNS -> 'trees'\n",
      "    CD -> '12'\n",
      "    NNP -> 'Ramsay'\n",
      "    NP -> DT ADJP CD\n",
      "    NN -> 'monument'\n",
      "    NN -> 'picture'\n",
      "    VP -> VBD PP\n",
      "    RB -> 'next'\n",
      "    DT -> 'a'\n",
      "    NNS -> 'parts'\n",
      "    VBN -> 'bricked'\n",
      "    RB -> 'only'\n",
      "    NN -> 'back'\n",
      "    NN -> 'property'\n",
      "    NN -> 'way'\n",
      "    NP -> NP JJ NN\n",
      "    JJR -> 'smaller'\n",
      "    NN -> 'left'\n",
      "    NN -> 'camera'\n",
      "    CC -> 'but'\n",
      "    PP -> IN\n",
      "    NN -> 'hut'\n",
      "    JJ -> 'Triangular'\n",
      "    JJ -> 'Typical'\n",
      "    NP -> DT ADJP NN\n",
      "    VBZ -> 'appears'\n",
      "    NP -> JJ JJ NN NNS\n",
      "    JJ -> 'narrow'\n",
      "    RB -> 'right'\n",
      "    NNP -> 'Subway'\n",
      "    NN -> 'middle'\n",
      "    NN -> 'house'\n",
      "    NNS -> 'sides'\n",
      "    RB -> 'almost'\n",
      "    NNP -> 'Caf+Γª'\n",
      "    VP -> VP , VP\n",
      "    VB -> 'tell'\n",
      "    RB -> 'above'\n",
      "    PP -> PP ADVP\n",
      "    JJ -> 'middle'\n",
      "    NP -> DT NML NNP\n",
      "    NP -> DT NN HYPH NN\n",
      "    NNS -> 'chairs'\n",
      "    JJ -> 'Middle'\n",
      "    NNS -> 'banners'\n",
      "    NP -> DT\n",
      "    VP -> VBP NP\n",
      "    NN -> 'horse'\n",
      "    RB -> 'Probably'\n",
      "    JJ -> 'light'\n",
      "    VBN -> 'obscured'\n",
      "    NP -> JJ HYPH NN\n",
      "    `` -> '\"'\n",
      "    RB -> 'partly'\n",
      "    NP -> DT VBN NN\n",
      "    NP -> CD JJ NN\n",
      "    UH -> 'hey'\n",
      "    NN -> 'everything'\n",
      "    JJ -> 'arched'\n",
      "    NP -> RB CD NN\n",
      "    RB -> 'of'\n",
      "    IN -> 'beside'\n",
      "    JJ -> 'Left'\n",
      "    VP -> VB NP ADVP\n",
      "    PP -> RB IN NP\n",
      "    -RRB- -> '╞'\n",
      "    NP -> PRP NN\n",
      "    NN -> 'type'\n",
      "    VBG -> 'surrounding'\n",
      "    PRP -> 'you'\n",
      "    S -> ADJP\n",
      "    NNP -> 'Elephant'\n",
      "    S -> `` NP ''\n",
      "    PRP -> 'I'\n",
      "    VBG -> 'Looking'\n",
      "    NN -> 'fence'\n",
      "    NNP -> 'Georgian'\n",
      "    JJ -> 'Opposite'\n",
      "    NP -> NNP NN\n",
      "    CC -> '+'\n",
      "    NP -> FW\n",
      "    JJ -> 'fronted'\n",
      "    NNP -> 'Theatre'\n",
      "    RB -> 'Ahead'\n",
      "    NNS -> 'blocks'\n",
      "    IN -> 'as'\n",
      "    RB -> 'really'\n",
      "    NN -> 'store'\n",
      "    NNS -> 'towers'\n",
      "    NN -> 'hill'\n",
      "    JJ -> 'Large'\n",
      "    NP -> NP SBAR\n",
      "    NNP -> 'Weaving'\n",
      "    ADJP -> NP PP\n",
      "    IN -> 'With'\n",
      "    NP -> PDT DT NN\n",
      "    VP -> VP ''\n",
      "    ADJP -> RB JJR\n",
      "    NN -> 'gallery'\n",
      "    JJR -> 'larger'\n",
      "    VBN -> 'storied'\n",
      "    NN -> 'Door'\n",
      "    NP -> DT NN CC NN\n",
      "    JJ -> 'wooden'\n",
      "    NP -> DT CD\n",
      "    NP -> NN NNS\n",
      "    NP -> JJ ADJP NN\n",
      "    NN -> 'seating'\n",
      "    NNS -> 'streets'\n",
      "    IN -> 'To'\n",
      "    VP -> VB VP\n",
      "    NNS -> 'plants'\n",
      "    VBG -> 'building'\n",
      "    VP -> VB S\n",
      "    ADJP -> NN VBN\n",
      "    S -> PP VP NP\n",
      "    ADJP -> NN JJ\n",
      "    NNP -> 'RBS'\n",
      "    NN -> 'dome'\n",
      "    NNP -> 'Scott'\n",
      "    RB -> 'Next'\n",
      "    NN -> 'turret'\n",
      "    ADJP -> CD JJ\n",
      "    JJ -> 'thai'\n",
      "    VP -> VBN\n",
      "    NP -> DT JJR NN\n",
      "    JJ -> 'old'\n",
      "    NNS -> 'offices'\n",
      "    JJ -> 'traditional'\n",
      "    RB -> 'already'\n",
      "    NN -> 'window'\n",
      "    NP -> DT JJ , ADJP NN\n",
      "    NP -> NP NNP\n",
      "    VP -> MD RB VP\n",
      "    NNS -> 'faces'\n",
      "    JJ -> 'dark'\n",
      "    VBN -> 'colored'\n",
      "    NNS -> 'dormers'\n",
      "    JJ -> 'gable'\n",
      "    VBD -> 'called'\n",
      "    VBG -> 'facing'\n",
      "    PP -> PP CC ADVP\n",
      "    NP -> PRP PRP\n",
      "    VBN -> 'arched'\n",
      "    PRP -> 'He'\n",
      "    SBAR -> S\n",
      "    NP -> NML NNS\n",
      "    VP -> VBZ\n",
      "    VBZ -> 'shows'\n",
      "    VP -> VBZ ADJP S\n",
      "    NNS -> 'posters'\n",
      "    CD -> '9'\n",
      "    DT -> 'That'\n",
      "    VP -> VBD NP\n",
      "    NP -> JJ NN NN\n",
      "    PP -> PP PP\n",
      "    JJS -> 'most'\n",
      "    RB -> 'kind'\n",
      "    JJ -> 'multi'\n",
      "    CC -> '&'\n",
      "    TO -> 'to'\n",
      "    NN -> 'number'\n",
      "    NP -> QP NN\n",
      "    RBS -> 'most'\n",
      "    NNS -> 'railings'\n",
      "    VBN -> 'fronted'\n",
      "    NML -> NNS\n",
      "    JJ -> 'national'\n",
      "    NP -> NP PP\n",
      "    IN -> 'like'\n",
      "    S -> NP VP .\n",
      "    VP -> VP NP\n",
      "    JJ -> 'medieval'\n",
      "    NN -> 'iron'\n",
      "    NNS -> 'boards'\n",
      "    CC -> 'and'\n",
      "    NP -> DT NNP NNP NNP\n",
      "    ADVP -> IN RB\n",
      "    NNP -> 'Scottish'\n",
      "    VP -> VBP ADJP PP\n",
      "    VP -> VBZ NP PP\n",
      "    NP -> JJ NNS\n",
      "    NN -> 'menu'\n",
      "    JJ -> 'funny'\n",
      "    VBP -> 'are'\n",
      "    NN -> 'one'\n",
      "    NN -> 'castle'\n",
      "    NN -> 'shed'\n",
      "    NP -> JJ NNS CC NNS\n",
      "    JJ -> 'short'\n",
      "    RP -> 'in'\n",
      "    JJ -> 'little'\n",
      "    IN -> 'across'\n",
      "    PP -> IN NP PP\n",
      "    JJ -> '2nd'\n",
      "    CD -> '10'\n",
      "    VP -> VB PP PP\n",
      "    VP -> VBN S\n",
      "    RB -> 'at'\n",
      "    S -> S CC S\n",
      "    NNP -> 'House'\n",
      "    NN -> 'center'\n",
      "    VBN -> 'terraced'\n",
      "    JJ -> 'small'\n",
      "    VBP -> 'look'\n",
      "    VP -> VP .\n",
      "    VBZ -> 'sits'\n",
      "    NP -> NP VP\n",
      "    NN -> 'color'\n",
      "    PRP -> 'It'\n",
      "    NN -> 'corner'\n",
      "    NP -> DT JJ CD\n",
      "    VP -> VB NP S\n",
      "    RB -> 'as'\n",
      "    RB -> 'slightly'\n",
      "    NN -> 'terrace'\n",
      "    NN -> 'basil'\n",
      "    ADVP -> RB JJ PP\n",
      "    JJ -> 'portable'\n",
      "    JJR -> 'lighter'\n",
      "    NN -> 'storefront'\n",
      "    NN -> 'bottom'\n",
      "    NN -> 'floor'\n",
      "    JJ -> 'greenish'\n",
      "    NN -> 'flagpole'\n",
      "    NNS -> 'cones'\n",
      "    PRP -> 'they'\n",
      "    NNP -> 'Suruchi'\n",
      "    NP -> DT JJ NN\n",
      "    WDT -> 'which'\n",
      "    JJ -> 'different'\n",
      "    NNS -> 'battlements'\n",
      "    NP -> CD JJR JJ NNS\n",
      "    NP -> DT NNP NN\n",
      "    JJ -> 'bottom'\n",
      "    NNP -> 'Florentine'\n",
      "    JJR -> 'darker'\n",
      "    NP -> NP SYM NP\n",
      "    JJ -> 'triangular'\n",
      "    VP -> VBN ADVP PP\n",
      "    NN -> 'pavement'\n",
      "    JJ -> 'far'\n",
      "    VBZ -> 'Has'\n",
      "    JJ -> 'rectangular'\n",
      "    IN -> 'Between'\n",
      "    NN -> 'story'\n",
      "    NNS -> 'buildings'\n",
      "    CD -> 'six'\n",
      "    NP -> NML JJ NN\n",
      "    NP -> NN FW\n",
      "    NNP -> 'Mill'\n",
      "    NN -> 'post'\n",
      "    NP -> DT JJ ADJP NN\n",
      "    VBN -> 'Called'\n",
      "    NN -> 'bridge'\n",
      "    RB -> 'also'\n",
      "    VBP -> \"'re\"\n",
      "    NNP -> 'Gallery'\n",
      "    SINV -> PP VP NP\n",
      "    NNP -> 'Princes'\n",
      "    NNS -> 'apartments'\n",
      "    NNS -> 'statues'\n",
      "    NN -> 'background'\n",
      "    NNS -> 'flats'\n",
      "    S -> NP VP\n",
      "    CD -> '5'\n",
      "    ADJP -> JJ PP\n",
      "    PRP$ -> 'your'\n",
      "    NML -> JJ NN\n",
      "    RB -> 'quite'\n",
      "    NP -> NN HYPH NN\n",
      "    NN -> 'frontage'\n",
      "    JJ -> 'Italian'\n",
      "    JJ -> 'other'\n",
      "    RB -> 'here'\n",
      "    ADVP -> RB\n",
      "    JJR -> 'taller'\n",
      "    NNS -> 'rooms'\n",
      "    JJ -> 'temporary'\n",
      "    NN -> 'row'\n",
      "    NP -> NNP NNP\n",
      "    -LRB- -> '-LRB-'\n",
      "    NP -> JJS\n",
      "    NP -> JJ NNP NN\n",
      "    JJ -> 'Greek'\n",
      "    JJ -> 'squat'\n",
      "    NML -> NML NN\n",
      "    SQ -> VBZ NP VP\n",
      "    SBAR -> WHPP S\n",
      "    JJ -> 'first'\n",
      "    NP -> NP ADVP PP\n",
      "    JJ -> 'ornate'\n",
      "    JJ -> 'Roman'\n",
      "    VP -> VBZ ADJP\n"
     ]
    }
   ],
   "source": [
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303ab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Traditional', 'early', 'Victorian', 'terrace', 'on', '3', 'floors', '+', 'dormer']\n"
     ]
    }
   ],
   "source": [
    "test_tokens = trees[2].leaves()\n",
    "print(test_tokens)\n",
    "# for t in parser.parse(test_tokens):\n",
    "# #     # t.pretty_print()\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6677d778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
