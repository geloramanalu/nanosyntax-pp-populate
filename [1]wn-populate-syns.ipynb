{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4b47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b481e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868295a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfff571",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepositions = [\n",
    "    'of',\n",
    "\t'with',\n",
    "\t'at',\n",
    "\t'from',\n",
    "\t'into',\n",
    "\t'during',\n",
    "\t'including',\n",
    "\t'until',\n",
    "\t'against',\n",
    "\t'among',\n",
    "\t'throughout',\n",
    "\t'despite',\n",
    "\t'towards',\n",
    "\t'upon',\n",
    "\t'concerning',\n",
    "\t'to',\n",
    "\t'in',\n",
    "\t'for',\n",
    "\t'on',\n",
    "\t'by',\n",
    "\t'about',\n",
    "\t'like',\n",
    "\t'through',\n",
    "\t'over',\n",
    "\t'before',\n",
    "\t'between',\n",
    "\t'after',\n",
    "\t'since',\n",
    "\t'without',\n",
    "\t'under',\n",
    "\t'within',\n",
    "\t'along',\n",
    "\t'following',\n",
    "\t'across',\n",
    "\t'behind',\n",
    "\t'beyond',\n",
    "\t'plus',\n",
    "\t'except',\n",
    "\t'but',\n",
    "\t'up',\n",
    "\t'out',\n",
    "\t'around',\n",
    "\t'down',\n",
    "\t'off',\n",
    "\t'above',\n",
    "\t'near'\n",
    "]\n",
    "\n",
    "prepositions_wikipedia = [\n",
    "\t\"aboard\",\n",
    "        \"about\",\n",
    "        \"above\",\n",
    "        \"absent\",\n",
    "        \"across\",\n",
    "        \"after\",\n",
    "        \"against\",\n",
    "        \"along\",\n",
    "        \"alongside\",\n",
    "        \"amid\",\n",
    "        \"amidst\",\n",
    "        \"among\",\n",
    "        \"amongst\",\n",
    "        \"around\",\n",
    "        \"as\",\n",
    "        \"astride\",\n",
    "        \"at\",\n",
    "        \"atop\",\n",
    "        \"before\",\n",
    "        \"afore\",\n",
    "        \"behind\",\n",
    "        \"below\",\n",
    "        \"beneath\",\n",
    "        \"beside\",\n",
    "        \"besides\",\n",
    "        \"between\",\n",
    "        \"beyond\",\n",
    "        \"by\",\n",
    "        \"circa\",\n",
    "        \"despite\",\n",
    "        \"down\",\n",
    "        \"during\",\n",
    "        \"except\",\n",
    "        \"for\",\n",
    "        \"from\",\n",
    "        \"in\",\n",
    "        \"inside\",\n",
    "        \"into\",\n",
    "        \"less\",\n",
    "        \"like\",\n",
    "        \"minus\",\n",
    "        \"near\",\n",
    "        \"nearer\",\n",
    "        \"nearest\",\n",
    "        \"notwithstanding\",\n",
    "        \"of\",\n",
    "        \"off\",\n",
    "        \"on\",\n",
    "        \"onto\",\n",
    "        \"opposite\",\n",
    "        \"outside\",\n",
    "        \"over\",\n",
    "        \"past\",\n",
    "        \"per\",\n",
    "        \"save\",\n",
    "        \"since\",\n",
    "        \"through\",\n",
    "        \"throughout\",\n",
    "        \"to\",\n",
    "        \"toward\",\n",
    "        \"towards\",\n",
    "        \"under\",\n",
    "        \"underneath\",\n",
    "        \"until\",\n",
    "        \"up\",\n",
    "        \"upon\",\n",
    "        \"upside\",\n",
    "        \"versus\",\n",
    "        \"via\",\n",
    "        \"with\",\n",
    "        \"within\",\n",
    "        \"without\",\n",
    "        \"worth\",\n",
    "        \"according to\",\n",
    "        \"adjacent to\",\n",
    "        \"ahead of\",\n",
    "        \"apart from\",\n",
    "        \"as of\",\n",
    "        \"as per\",\n",
    "        \"as regards\",\n",
    "        \"aside from\",\n",
    "        \"astern of\",\n",
    "        \"back to\",\n",
    "        \"because of\",\n",
    "        \"close to\",\n",
    "        \"due to\",\n",
    "        \"except for\",\n",
    "        \"far from\",\n",
    "        \"inside of\",\n",
    "        \"instead of\",\n",
    "        \"left of\",\n",
    "        \"near to\",\n",
    "        \"next to\",\n",
    "        \"opposite of\",\n",
    "        \"opposite to\",\n",
    "        \"out from\",\n",
    "        \"out of\",\n",
    "        \"outside of\",\n",
    "        \"owing to\",\n",
    "        \"prior to\",\n",
    "        \"pursuant to\",\n",
    "        \"rather than\",\n",
    "        \"regardless of\",\n",
    "        \"right of\",\n",
    "        \"subsequent to\",\n",
    "        \"such as\",\n",
    "        \"thanks to\",\n",
    "        \"up to\",\n",
    "        \"as far as\",\n",
    "        \"as opposed to\",\n",
    "        \"as soon as\",\n",
    "        \"as well as\",\n",
    "        \"at the behest of\",\n",
    "        \"by means of\",\n",
    "        \"by virtue of\",\n",
    "        \"for the sake of\",\n",
    "        \"in accordance with\",\n",
    "        \"in addition to\",\n",
    "        \"in case of\",\n",
    "        \"in front of\",\n",
    "        \"in lieu of\",\n",
    "        \"in place of\",\n",
    "        \"in point of\",\n",
    "        \"in spite of\",\n",
    "        \"on account of\",\n",
    "        \"on behalf of\",\n",
    "        \"on top of\",\n",
    "        \"with regard to\",\n",
    "        \"with respect to\",\n",
    "        \"with a view to\"\n",
    "]\n",
    "\n",
    "merge_prepositions = list(set(prepositions + prepositions_wikipedia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610f190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b73f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relation(syns, method):\n",
    "    return{\n",
    "        lemma.name()\n",
    "        for syn in syns\n",
    "        for mero_hypo in getattr(syn, method)()\n",
    "        for lemma in mero_hypo.lemmas()\n",
    "    }\n",
    "    \n",
    "meronym_methods  = ['part_meronyms', 'member_meronyms', 'substance_meronyms']\n",
    "holonym_methods  = ['part_holonyms', 'member_holonyms', 'substance_holonyms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e251855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>antonyms</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "      <th>meronym</th>\n",
       "      <th>holonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notwithstanding</td>\n",
       "      <td>all the same, even so, however, nevertheless, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inside of</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>around</td>\n",
       "      <td>about, approximately, close to, just about, mo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as regards</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>out</td>\n",
       "      <td>KO'd, away, come out, come out of the closet, ...</td>\n",
       "      <td>{safe}</td>\n",
       "      <td>break, bring out, disclose, discover, divulge,...</td>\n",
       "      <td>putout, strikeout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>down</td>\n",
       "      <td>Down, John L. H. Down, belt down, blue, bolt d...</td>\n",
       "      <td>{upwards, upwardly, upward, up}</td>\n",
       "      <td>ameliorate, amend, better, defeat, drink, eat,...</td>\n",
       "      <td>civilise, civilize, cultivate, duck down, educ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>right of</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rather than</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with respect to</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>amongst</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>according to</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>upon</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>via</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>with</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>as well as</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>before</td>\n",
       "      <td>ahead, earlier, in front</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>from</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>as</td>\n",
       "      <td>A, AS, American Samoa, As, Eastern Samoa, a, a...</td>\n",
       "      <td>None</td>\n",
       "      <td>alphabetic character, base, blood group, blood...</td>\n",
       "      <td>dehydroretinol, retinol, vitamin A1, vitamin A2</td>\n",
       "      <td>Pago Pago, Pango Pango, mA, micromicron, milli...</td>\n",
       "      <td>DNA, Latin alphabet, RNA, Roman alphabet, Samo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>including</td>\n",
       "      <td>admit, include, let in</td>\n",
       "      <td>{exclude}</td>\n",
       "      <td>add, allow, consider, countenance, let, permit...</td>\n",
       "      <td>attach to, bear, carry, colligate, comprehend,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        preposition                                           synonyms  \\\n",
       "0   notwithstanding  all the same, even so, however, nevertheless, ...   \n",
       "1         inside of                                               None   \n",
       "2               for                                               None   \n",
       "3            around  about, approximately, close to, just about, mo...   \n",
       "4        as regards                                               None   \n",
       "5               out  KO'd, away, come out, come out of the closet, ...   \n",
       "6              down  Down, John L. H. Down, belt down, blue, bolt d...   \n",
       "7          right of                                               None   \n",
       "8       rather than                                               None   \n",
       "9   with respect to                                               None   \n",
       "10          amongst                                               None   \n",
       "11     according to                                               None   \n",
       "12             upon                                               None   \n",
       "13              via                                               None   \n",
       "14             with                                               None   \n",
       "15       as well as                                               None   \n",
       "16           before                           ahead, earlier, in front   \n",
       "17             from                                               None   \n",
       "18               as  A, AS, American Samoa, As, Eastern Samoa, a, a...   \n",
       "19        including                             admit, include, let in   \n",
       "\n",
       "                           antonyms  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3                              None   \n",
       "4                              None   \n",
       "5                            {safe}   \n",
       "6   {upwards, upwardly, upward, up}   \n",
       "7                              None   \n",
       "8                              None   \n",
       "9                              None   \n",
       "10                             None   \n",
       "11                             None   \n",
       "12                             None   \n",
       "13                             None   \n",
       "14                             None   \n",
       "15                             None   \n",
       "16                             None   \n",
       "17                             None   \n",
       "18                             None   \n",
       "19                        {exclude}   \n",
       "\n",
       "                                             hypernym  \\\n",
       "0                                                None   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4                                                None   \n",
       "5   break, bring out, disclose, discover, divulge,...   \n",
       "6   ameliorate, amend, better, defeat, drink, eat,...   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9                                                None   \n",
       "10                                               None   \n",
       "11                                               None   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18  alphabetic character, base, blood group, blood...   \n",
       "19  add, allow, consider, countenance, let, permit...   \n",
       "\n",
       "                                              hyponym  \\\n",
       "0                                                None   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4                                                None   \n",
       "5                                   putout, strikeout   \n",
       "6   civilise, civilize, cultivate, duck down, educ...   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9                                                None   \n",
       "10                                               None   \n",
       "11                                               None   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18    dehydroretinol, retinol, vitamin A1, vitamin A2   \n",
       "19  attach to, bear, carry, colligate, comprehend,...   \n",
       "\n",
       "                                              meronym  \\\n",
       "0                                                None   \n",
       "1                                                None   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9                                                None   \n",
       "10                                               None   \n",
       "11                                               None   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18  Pago Pago, Pango Pango, mA, micromicron, milli...   \n",
       "19                                               None   \n",
       "\n",
       "                                              holonym  \n",
       "0                                                None  \n",
       "1                                                None  \n",
       "2                                                None  \n",
       "3                                                None  \n",
       "4                                                None  \n",
       "5                                                None  \n",
       "6                                                None  \n",
       "7                                                None  \n",
       "8                                                None  \n",
       "9                                                None  \n",
       "10                                               None  \n",
       "11                                               None  \n",
       "12                                               None  \n",
       "13                                               None  \n",
       "14                                               None  \n",
       "15                                               None  \n",
       "16                                               None  \n",
       "17                                               None  \n",
       "18  DNA, Latin alphabet, RNA, Roman alphabet, Samo...  \n",
       "19                                               None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "mero_hypo_rel = {}\n",
    "for prep in merge_prepositions:\n",
    "    syns = wn.synsets(prep, pos=wn.ADV) + \\\n",
    "        wn.synsets(prep, pos=wn.ADJ) + \\\n",
    "        wn.synsets(prep, pos=wn.NOUN) + \\\n",
    "        wn.synsets(prep, pos=wn.VERB)\n",
    "    \n",
    "    lemmas = {lemma.name() for syn in syns for lemma in syn.lemmas()}\n",
    "    antonym = [antonym_lem.name() for syn in syns for synlem in syn.lemmas() for antonym_lem in synlem.antonyms()  ]\n",
    "    antonym = set(antonym)\n",
    "    hypernym = {lem_hyper.name() for syn in syns for hyper in syn.hypernyms() for lem_hyper in hyper.lemmas()}\n",
    "    hyponym = {lem_hypo.name() for syn in syns for hypo in syn.hyponyms() for lem_hypo in hypo.lemmas()}\n",
    "    meronym = set().union(*(extract_relation(syns, m) for m in meronym_methods))\n",
    "    holonym = set().union(*(extract_relation(syns, h) for h in holonym_methods))\n",
    "    \n",
    "    lemmas.discard(prep)\n",
    "    \n",
    "    if lemmas:\n",
    "        synonym_str = ', '.join(sorted(lemmas))\n",
    "    if antonym:\n",
    "        antonym_str = ', '.join(sorted(antonym))\n",
    "    if hypernym:    \n",
    "        hypernym_str = ', '.join(sorted(hypernym))\n",
    "    if hyponym:\n",
    "        hyponym_str = ', '.join(sorted(hyponym))\n",
    "    if meronym:\n",
    "        meronym_str = ', '.join(sorted(meronym))\n",
    "    if holonym:\n",
    "        holonym_str = ', '.join(sorted(holonym))\n",
    "        \n",
    "    \n",
    "    rows.append({\n",
    "        'preposition': prep,\n",
    "        'synonyms': synonym_str if lemmas else None,\n",
    "        'antonyms': antonym if antonym else None,\n",
    "        'hypernym': hypernym_str if hypernym else None,\n",
    "        'hyponym': hyponym_str if hyponym else None,\n",
    "        'meronym': meronym_str if meronym else None,\n",
    "        'holonym': holonym_str if holonym else None,   \n",
    "        \n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(rows)\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].replace(to_replace=r'[{}_]', value=' ', regex=True)\n",
    "    \n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be85dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>antonyms</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "      <th>meronym</th>\n",
       "      <th>holonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>aboard</td>\n",
       "      <td>alongside, on base, on board</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>about</td>\n",
       "      <td>almost, approximately, around, astir, close to...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>above</td>\n",
       "      <td>higher up, in a higher place, supra, to a high...</td>\n",
       "      <td>below</td>\n",
       "      <td>section, subdivision</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>absent</td>\n",
       "      <td>absentminded, abstracted, lacking, missing, re...</td>\n",
       "      <td>present</td>\n",
       "      <td>disappear, go away, vanish</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>according to</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>across</td>\n",
       "      <td>crossways, crosswise</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>adjacent to</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>afore</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>after</td>\n",
       "      <td>afterward, afterwards, later, later on, subseq...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>against</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>ahead of</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>along</td>\n",
       "      <td>on</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>alongside</td>\n",
       "      <td>aboard</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>amid</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>amidst</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>among</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>amongst</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>apart from</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>around</td>\n",
       "      <td>about, approximately, close to, just about, mo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>as</td>\n",
       "      <td>A, AS, American Samoa, As, Eastern Samoa, a, a...</td>\n",
       "      <td>None</td>\n",
       "      <td>alphabetic character, base, blood group, blood...</td>\n",
       "      <td>dehydroretinol, retinol, vitamin A1, vitamin A2</td>\n",
       "      <td>Pago Pago, Pango Pango, mA, micromicron, milli...</td>\n",
       "      <td>DNA, Latin alphabet, RNA, Roman alphabet, Samo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      preposition                                           synonyms antonyms  \\\n",
       "61         aboard                       alongside, on base, on board     None   \n",
       "65          about  almost, approximately, around, astir, close to...     None   \n",
       "79          above  higher up, in a higher place, supra, to a high...    below   \n",
       "60         absent  absentminded, abstracted, lacking, missing, re...  present   \n",
       "11   according to                                               None     None   \n",
       "64         across                               crossways, crosswise     None   \n",
       "46    adjacent to                                               None     None   \n",
       "113         afore                                               None     None   \n",
       "30          after  afterward, afterwards, later, later on, subseq...     None   \n",
       "43        against                                               None     None   \n",
       "135      ahead of                                               None     None   \n",
       "85          along                                                 on     None   \n",
       "101     alongside                                             aboard     None   \n",
       "32           amid                                               None     None   \n",
       "127        amidst                                               None     None   \n",
       "96          among                                               None     None   \n",
       "10        amongst                                               None     None   \n",
       "130    apart from                                               None     None   \n",
       "3          around  about, approximately, close to, just about, mo...     None   \n",
       "18             as  A, AS, American Samoa, As, Eastern Samoa, a, a...     None   \n",
       "\n",
       "                                              hypernym  \\\n",
       "61                                                None   \n",
       "65                                                None   \n",
       "79                                section, subdivision   \n",
       "60                          disappear, go away, vanish   \n",
       "11                                                None   \n",
       "64                                                None   \n",
       "46                                                None   \n",
       "113                                               None   \n",
       "30                                                None   \n",
       "43                                                None   \n",
       "135                                               None   \n",
       "85                                                None   \n",
       "101                                               None   \n",
       "32                                                None   \n",
       "127                                               None   \n",
       "96                                                None   \n",
       "10                                                None   \n",
       "130                                               None   \n",
       "3                                                 None   \n",
       "18   alphabetic character, base, blood group, blood...   \n",
       "\n",
       "                                             hyponym  \\\n",
       "61                                              None   \n",
       "65                                              None   \n",
       "79                                              None   \n",
       "60                                              None   \n",
       "11                                              None   \n",
       "64                                              None   \n",
       "46                                              None   \n",
       "113                                             None   \n",
       "30                                              None   \n",
       "43                                              None   \n",
       "135                                             None   \n",
       "85                                              None   \n",
       "101                                             None   \n",
       "32                                              None   \n",
       "127                                             None   \n",
       "96                                              None   \n",
       "10                                              None   \n",
       "130                                             None   \n",
       "3                                               None   \n",
       "18   dehydroretinol, retinol, vitamin A1, vitamin A2   \n",
       "\n",
       "                                               meronym  \\\n",
       "61                                                None   \n",
       "65                                                None   \n",
       "79                                                None   \n",
       "60                                                None   \n",
       "11                                                None   \n",
       "64                                                None   \n",
       "46                                                None   \n",
       "113                                               None   \n",
       "30                                                None   \n",
       "43                                                None   \n",
       "135                                               None   \n",
       "85                                                None   \n",
       "101                                               None   \n",
       "32                                                None   \n",
       "127                                               None   \n",
       "96                                                None   \n",
       "10                                                None   \n",
       "130                                               None   \n",
       "3                                                 None   \n",
       "18   Pago Pago, Pango Pango, mA, micromicron, milli...   \n",
       "\n",
       "                                               holonym  \n",
       "61                                                None  \n",
       "65                                                None  \n",
       "79                                                None  \n",
       "60                                                None  \n",
       "11                                                None  \n",
       "64                                                None  \n",
       "46                                                None  \n",
       "113                                               None  \n",
       "30                                                None  \n",
       "43                                                None  \n",
       "135                                               None  \n",
       "85                                                None  \n",
       "101                                               None  \n",
       "32                                                None  \n",
       "127                                               None  \n",
       "96                                                None  \n",
       "10                                                None  \n",
       "130                                               None  \n",
       "3                                                 None  \n",
       "18   DNA, Latin alphabet, RNA, Roman alphabet, Samo...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['antonyms'] = (\n",
    "    df['antonyms']\n",
    "      .fillna('')                                           \n",
    "      .astype(str)                                          \n",
    "      .str.replace(r'[{}_\\']', ' ', regex=True)             \n",
    "      .str.strip()                                          \n",
    "      .replace({'': None})                                  \n",
    ")\n",
    "#sort df aplhabetically\n",
    "df = df.sort_values(by='preposition', ascending=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2882a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['carrefour', 'crossing', 'crossroad', 'intersection']]\n"
     ]
    }
   ],
   "source": [
    "synset_word = wn.synonyms('crossway')\n",
    "\n",
    "print(synset_word)\n",
    "# find synset each synset_word\n",
    "# for i in synset_word:\n",
    "#     try:\n",
    "#         print(wn.synsets(i))\n",
    "#     except AttributeError:\n",
    "#         print(f\"AttributeError: {i} not found in WordNet\")\n",
    "#         continue\n",
    "        \n",
    "\n",
    "# print(synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b2660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87d622ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lying or extending across the length of a thing or in a cross direction\n"
     ]
    }
   ],
   "source": [
    "syns = wn.synsets('crosswise')[0].lemmas()[0].synset().definition()\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb231f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2866eae7",
   "metadata": {},
   "source": [
    "### Compile definition from Merriam Webster Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb56abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/glora/projects/populate-ns-lex/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5041672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_html_content(preposition, path_to_save = './scrap_meriam_webster/'):\n",
    "    # encode spaces for URL and create filename\n",
    "    prep_encoded = preposition.replace(' ', '%20')\n",
    "    url = f\"https://www.merriam-webster.com/dictionary/{prep_encoded}\"\n",
    "    \n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        filename = f\"{prep_encoded.replace('%20', '_')}.html\"\n",
    "        filepath = os.path.join(path_to_save, filename)\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(resp.text)\n",
    "        print(f\"Saved HTML for '{preposition}' → {filepath}\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch '{preposition}' (status {resp.status_code})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70f7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prep in merge_prepositions:\n",
    "#     save_html_content(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79207e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL and parameters\n",
    "# url = \"https://www.merriam-webster.com/dictionary/\"\n",
    "\n",
    "# def get_merriam_webster_definition(word):\n",
    "#     word = word.replace(\" \", \"%20\")\n",
    "#     # Make a GET request to the URL \n",
    "#     response = requests.get(url + word)\n",
    "#     if response.status_code != 200:\n",
    "#         return None\n",
    "#     # parse it here\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#     return get_first_definition(soup)\n",
    "\n",
    "def load_saved_definitions(html_dir):\n",
    "    definitions = {}\n",
    "    # find  .html in that folder\n",
    "    for filepath in glob.glob(os.path.join(html_dir, '*.html')):\n",
    "        #infer word from the filename, e.g. 'until.html' -> 'until'\n",
    "        name = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        word = name.replace('_', ' ')\n",
    "        # read & parse\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            html = f.read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # run your existing scraper logic\n",
    "        definition = get_first_definition(soup, word)\n",
    "        definitions[word] = definition\n",
    "    \n",
    "    return definitions\n",
    "\n",
    "\n",
    "def get_first_definition(soup, preposition_name=None):\n",
    "    phrase_span = soup.find('span', class_='drp', string=preposition_name)\n",
    "    if phrase_span:\n",
    "        # the definition is in the very next <div class=\"vg\"> block\n",
    "        vg = phrase_span.find_next_sibling('div', class_='vg')\n",
    "        if vg:\n",
    "            dt = vg.find('span', class_='dtText')\n",
    "            if dt:\n",
    "                # pull out the raw text, strip leading “: ”, etc.\n",
    "                raw = dt.get_text(separator=' ', strip=True)\n",
    "                cleaned = re.sub(r'^\\s*:\\s*', '', raw)\n",
    "                # split off any trailing “: ” left-over\n",
    "                return ' '.join(re.findall(r'\\([^)]+\\)|[A-Za-z]+', cleaned))\n",
    "\n",
    "    pos_link = soup.find('a', href=re.compile(r'preposition'))\n",
    "    # fall back to any unText spans\n",
    "    if pos_link is None:\n",
    "        unspans = soup.find_all('span', class_='unText')\n",
    "        if unspans:\n",
    "            text = ''.join(unspans[0].strings).strip()\n",
    "            # print(text)\n",
    "            return ' '.join(re.findall(r'\\([^)]+\\)|[A-Za-z]+', text))\n",
    "\n",
    "    # preposition link’s entry container\n",
    "    container = (\n",
    "        pos_link.find_parent('div', id=re.compile(r'dictionary-entry-[0-9]+'))\n",
    "        if pos_link else\n",
    "        soup.find('div', id=re.compile(r'dictionary-entry-\\d+'))\n",
    "    )\n",
    "    # grab the first <span class=\"dtText\">\n",
    "    dt_spans = container.find_all('span', class_='dtText')\n",
    "    for span in dt_spans:\n",
    "        # print(span.find(class_='mw_t_bc'))\n",
    "        \n",
    "        \n",
    "        # if span.find('strong') or span.find('span', class_='text-uppercase'):\n",
    "        #     continue\n",
    "\n",
    "        # otherwise this is our “clean” definition\n",
    "        # raw = span.get_text(separator=' ', strip=True)\n",
    "        # raw = re.sub(r'^\\s*:\\s*', '', raw)           # strip the leading colon\n",
    "        # words = re.findall(r'\\([^)]+\\)|[A-Za-z]+', raw)\n",
    "        # return ' '.join(words)\n",
    "        texts = [t.strip() \n",
    "         for t in span.find_all(string=True, recursive=False) \n",
    "         if t.strip()]\n",
    "        result = \", \".join(texts)\n",
    "        if len(result) >= 2:\n",
    "            return result\n",
    "\n",
    "    # if we got here, no clean dtText – fall back to <span class='unText'>…\n",
    "    unspans = container.find_all('span', class_='unText')\n",
    "    if unspans:\n",
    "        raw = ''.join(unspans[0].strings).strip()\n",
    "        return ' '.join(re.findall(r'\\([^)]+\\)|[A-Za-z]+', raw))\n",
    "\n",
    "    # last‐ditch resort\n",
    "    dt = container.find('span', class_='dtText')\n",
    "    if dt:\n",
    "        link = dt.find('a')\n",
    "        if link:\n",
    "            # e.g. “subsequent to”\n",
    "            return link.get_text(strip=True)\n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_preposition_definitions(prepositions):\n",
    "    definitions = {}\n",
    "    for prep in prepositions:\n",
    "        definition = get_preposition_definitions(prep)\n",
    "        if definition:\n",
    "            definitions[prep] = definition\n",
    "        else:\n",
    "            definitions[prep] = None\n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a8059e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df18d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abc44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c4731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61315aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_def = get_preposition_definitions(merge_prepositions)\n",
    "# df_def = pd.DataFrame(list(df_def.items()), columns=['preposition', 'definition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc5117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_folder = './scrap_meriam_webster'\n",
    "\n",
    "defs = load_saved_definitions(html_folder)\n",
    "df_def_local = pd.DataFrame(\n",
    "    list(defs.items()),\n",
    "    columns=['preposition', 'definition']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8edaa81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['preposition', 'definition'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print isna values\n",
    "# df_def_local[df_def_local['definition'].isna()]\n",
    "df_def_local.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c479f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>astride</td>\n",
       "      <td>on or above and with one leg on each side of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>as opposed to</td>\n",
       "      <td>used to refer to something that is different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aside from</td>\n",
       "      <td>in addition to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>as</td>\n",
       "      <td>in the capacity, character, condition, or role of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>as per</td>\n",
       "      <td>in accordance with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>as far as</td>\n",
       "      <td>with regard to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>as soon as</td>\n",
       "      <td>immediately at or shortly after the time that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>as well as</td>\n",
       "      <td>in addition to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>as regards</td>\n",
       "      <td>in regard to, with respect to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>as of</td>\n",
       "      <td>,, ,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       preposition                                         definition\n",
       "7          astride       on or above and with one leg on each side of\n",
       "17   as opposed to  used to refer to something that is different f...\n",
       "23      aside from                                     in addition to\n",
       "26              as  in the capacity, character, condition, or role of\n",
       "45          as per                                 in accordance with\n",
       "75       as far as                                     with regard to\n",
       "77      as soon as      immediately at or shortly after the time that\n",
       "91      as well as                                     in addition to\n",
       "96      as regards                      in regard to, with respect to\n",
       "107          as of                                               ,, ,"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_def_local.sort_values(by='preposition', ascending=True)\n",
    "df_def_local[df_def_local['preposition'].str.match('as')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "718a4464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [preposition, definition]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df_def_local[df_def_local['preposition'] == 'astern of']\n",
    "# df_def_local[df_def_local['preposition'].str.contains('astern of')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc2065cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>as of</td>\n",
       "      <td>used to indicate a time or date at which something begins or ends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    preposition  \\\n",
       "107       as of   \n",
       "\n",
       "                                                            definition  \n",
       "107  used to indicate a time or date at which something begins or ends  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add definition of 'as of'\n",
    "df_def_local.loc[df_def_local['preposition'] == 'as of', 'definition'] = 'used to indicate a time or date at which something begins or ends'\n",
    "df_def_local[df_def_local['preposition'] == 'as of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa33d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    save_html_content(prep)\n",
    "# add from populated df\n",
    "prep_to_append = []\n",
    "for prep in df_def_local['preposition']:\n",
    "    # check if prep is in df['preposition']\n",
    "    if prep not in df['preposition'].values:\n",
    "        prep_to_append.append(prep)\n",
    "            \n",
    "for prep in prep_to_append:\n",
    "    save_html_content(prep, path_to_save = './scrap_meriam_webster/additional_wiki_pop/')\n",
    "\n",
    "dfs_add = load_saved_definitions('./scrap_meriam_webster/additional_wiki_pop/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97535348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with</td>\n",
       "      <td>in opposition to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preposition        definition\n",
       "9        with  in opposition to"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_def_local[df_def_local['preposition'] == 'with']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb25d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff590f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217f3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db85b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a50894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ef0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b41f01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d10b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075a2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4fa6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b413cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627cb0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a498cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'used as a function word to indicate an outward movement'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with one word\n",
    "urrll = 'https://www.merriam-webster.com/dictionary/out'\n",
    "rqg = requests.get(urrll)\n",
    "sup = BeautifulSoup(rqg.text, 'html.parser')\n",
    "get_first_definition(sup, 'out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1c3980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_def_local.to_csv('./dictionaries/preposition_definitions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3cfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55842c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ef1365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22463a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f232cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e96173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3a37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a74bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6e426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afab822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70a89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14885bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d7ef13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e01874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62c78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a1c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b8f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a895db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86455671",
   "metadata": {},
   "source": [
    "['from', 'one', 'side', 'the', 'opposite', 'side', 'over', 'through']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a66f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82fffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f380c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6f2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7b17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7edc3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb4cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f52b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b06de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb4c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e66d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391acca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c671de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8bc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94001767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24706c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f65341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78bf20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee17bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cc01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958cc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da43ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3535b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7711bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466adab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793bf78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa26fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db349c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2400f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ab163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b52ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b4adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca800e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2025af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe923d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9326a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfa5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556194e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2720a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea643cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063735ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd103114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011c7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd98f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fcb010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbd40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccbb9388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the cards were face upward', 'an upward stroke of the pen']\n"
     ]
    }
   ],
   "source": [
    "syns_n = wn.synsets('upward')\n",
    "all_name = [lemma.name() for syn in syns_n for lemma in syn.lemmas()]\n",
    "print(syns_n[0].examples())\n",
    "# print(syns_n)\n",
    "\n",
    "# for item in syns_n:\n",
    "#     if item:\n",
    "#         head = item.lemmas()[0].name()\n",
    "#         hypos = item.synonyms()\n",
    "#         print(hypos)\n",
    "        \n",
    "#     if hypos:\n",
    "#         # take the first hyponym synset, then its first lemma\n",
    "#         hypo_lemma = hypos[0].lemmas()[0].name()\n",
    "#         hypos_def = hypos[0].definition()\n",
    "#     else:\n",
    "#         hypo_lemma = None\n",
    "#         hypos_def = None\n",
    "\n",
    "\n",
    "#     print(f\"{head} : {hypo_lemma}, {hypos_def}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7131396",
   "metadata": {},
   "source": [
    "### Get semantic relations of the prepositions to define its spatial status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae7d9315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preposition</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>antonyms</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "      <th>meronym</th>\n",
       "      <th>holonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>aboard</td>\n",
       "      <td>alongside, on base, on board</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>about</td>\n",
       "      <td>almost, approximately, around, astir, close to, just about, more or less, most, near, nearly, nigh, or so, roughly, some, virtually, well-nigh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>above</td>\n",
       "      <td>higher up, in a higher place, supra, to a higher place</td>\n",
       "      <td>below</td>\n",
       "      <td>section, subdivision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>absent</td>\n",
       "      <td>absentminded, abstracted, lacking, missing, remove, scatty, wanting</td>\n",
       "      <td>present</td>\n",
       "      <td>disappear, go away, vanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>according to</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      preposition  \\\n",
       "102        aboard   \n",
       "33          about   \n",
       "41          above   \n",
       "95         absent   \n",
       "122  according to   \n",
       "\n",
       "                                                                                                                                           synonyms  \\\n",
       "102                                                                                                                    alongside, on base, on board   \n",
       "33   almost, approximately, around, astir, close to, just about, more or less, most, near, nearly, nigh, or so, roughly, some, virtually, well-nigh   \n",
       "41                                                                                           higher up, in a higher place, supra, to a higher place   \n",
       "95                                                                              absentminded, abstracted, lacking, missing, remove, scatty, wanting   \n",
       "122                                                                                                                                             NaN   \n",
       "\n",
       "    antonyms                    hypernym hyponym meronym holonym  \n",
       "102      NaN                         NaN     NaN     NaN     NaN  \n",
       "33       NaN                         NaN     NaN     NaN     NaN  \n",
       "41     below        section, subdivision     NaN     NaN     NaN  \n",
       "95   present  disappear, go away, vanish     NaN     NaN     NaN  \n",
       "122      NaN                         NaN     NaN     NaN     NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_list = \"dictionaries/preposition_wordnet_wiki_pop.csv\"\n",
    "df = pd.read_csv(prep_list, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ec176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch definition with scraping playwright of each preposition from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90a702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b1a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd528aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c7107f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d018f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precede', 'predate', 'leading'}\n"
     ]
    }
   ],
   "source": [
    "word_synsets = wn.synsets('following')\n",
    "antos = [antonym_lem.name() for syn in word_synsets for synlem in syn.lemmas() for antonym_lem in synlem.antonyms()  ]\n",
    "\n",
    "unique_dict = {}\n",
    "for word in antos:\n",
    "    unique_dict[word] = unique_dict.get(word, 0) + 1\n",
    "\n",
    "antos_set = set(antos)\n",
    "print(antos_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "992dbe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low level country : Lemma('lowland.n.01.lowland')\n",
      "of relatively low or level country : Lemma('lowland.a.01.lowland')\n"
     ]
    }
   ],
   "source": [
    "# antonym lemmas\n",
    "for syn in wn.synsets('highland'):\n",
    "    for lemma in syn.lemmas():\n",
    "        ants = lemma.antonyms()\n",
    "        if ants:\n",
    "            first_ant = ants[0]\n",
    "            print(first_ant.synset().definition(), \":\", first_ant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5503ea3",
   "metadata": {},
   "source": [
    "### Search tokes of lexicon entry and all its definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2ace719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close : the temporal end; the concluding time\n",
      "crowd : a large number of things or people considered together\n",
      "push : the act of applying force in order to move something away\n"
     ]
    }
   ],
   "source": [
    "select = df[df['preposition'].str.contains('near', na=False)]\n",
    "arr=[]\n",
    "for idx, item in enumerate(select['hyponym']):\n",
    "    if pd.notna(item):\n",
    "        # arr.append(item)\n",
    "        select_tokens = [token.strip() for token in item.split(',')]\n",
    "\n",
    "select_tokens\n",
    "for i in select_tokens:\n",
    "    if len(wn.synsets(i)) != 0:\n",
    "        hypernym_highland = wn.synsets(i)[0]\n",
    "        print(i, \":\", hypernym_highland.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7bf240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993d758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7791e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558af8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df7331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e795750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bear down on : No definition found\n",
      "bear down upon : No definition found\n",
      "close : Lemma('stopping_point.n.01.stopping_point') ; the temporal end; the concluding time\n",
      "crowd : Lemma('crowd.n.01.crowd') ; a large number of things or people considered together\n",
      "drive up : No definition found\n",
      "edge in : No definition found\n",
      "edge up : No definition found\n",
      "push : Lemma('push.n.01.push') ; the act of applying force in order to move something away\n"
     ]
    }
   ],
   "source": [
    "items = df[df['preposition'].str.contains('near', na=False)]['hyponym']\n",
    "for i in items:\n",
    "    if i:\n",
    "        if pd.notna(i):\n",
    "            select_tokens = [token.strip() for token in i.split(',')]\n",
    "            for j in select_tokens:\n",
    "                if len(wn.synsets(j)) != 0:\n",
    "                    token_def = wn.synsets(j)[0]\n",
    "                    print(j, \":\", token_def.lemmas()[0], \";\", token_def.definition())\n",
    "\n",
    "                else:\n",
    "                    print(j, \":\", \"No definition found\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646bf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37103981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690c48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3eafa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43279601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b9eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0e245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fb3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ab58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83cbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0337f785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306d403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ffd323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d01e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731ba2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1215a53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['come_near', 'dear', 'close', 'cheeseparing', 'nearly', 'go_up', 'most', 'draw_near', 'good', 'skinny', 'approximate', 'nigh', 'almost', 'come_on', 'well-nigh', 'draw_close', 'about', 'penny-pinching', 'virtually', 'approach']\n",
      "come_near : almost do or experience something\n",
      "dear : a beloved person; used as terms of endearment\n",
      "close : the temporal end; the concluding time\n",
      "cheeseparing : giving or spending with reluctance\n",
      "nearly : (of actions or states) slightly short of or not quite accomplished; all but\n",
      "go_up : move upward\n",
      "most : (superlative of `many' used with count nouns and often preceded by `the') quantifier meaning the greatest in number\n",
      "draw_near : move towards\n",
      "good : benefit\n",
      "skinny : confidential information about a topic or person\n",
      "approximate : be close or similar\n",
      "nigh : not far distant in time or space or degree or circumstances\n",
      "almost : (of actions or states) slightly short of or not quite accomplished; all but\n",
      "come_on : appear or become visible; make a showing\n",
      "well-nigh : (of actions or states) slightly short of or not quite accomplished; all but\n",
      "draw_close : move or arrange oneself in a comfortable and cozy position\n",
      "about : on the move\n",
      "penny-pinching : extreme care in spending money; reluctance to spend money unnecessarily\n",
      "virtually : in essence or effect but not in fact\n",
      "approach : ideas or actions intended to deal with a problem or situation\n"
     ]
    }
   ],
   "source": [
    "synonym = wn.synsets('near')\n",
    "#flatten synonym list\n",
    "synonym = [lemma.name() for syn in synonym for lemma in syn.lemmas()]\n",
    "#remove duplicates\n",
    "synonym = set(synonym)\n",
    "#remove the word itself\n",
    "synonym.discard('near')\n",
    "#remove empty strings\n",
    "synonym = [s for s in synonym if s]\n",
    "\n",
    "print(synonym)\n",
    "\n",
    "for i in synonym:\n",
    "    if len(wn.synsets(i)) != 0:\n",
    "        syns_synonym = wn.synsets(i)[0]\n",
    "        print(i, \":\", syns_synonym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a782c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e5b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bde07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa95a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d56368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a912267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796ef14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b9241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff87d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d6970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78a93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08e595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ec02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d29646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f8840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4cdc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cd265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0933fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c89f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417eb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cb2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031e907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "091a7470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['window']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The bird flew out the window\"\n",
    "\n",
    "# parse with earley parser and cfg\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N | Det N PP\n",
    "    VP -> V PP | V NP\n",
    "    PP -> P NP\n",
    "    Det -> 'The' | 'the' | 'a'\n",
    "    N -> 'bird' | 'window'\n",
    "    V -> 'flew'\n",
    "    P -> 'in' | 'out'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.EarleyChartParser(grammar)\n",
    "\n",
    "# get N in the PP\n",
    "parsed = False\n",
    "parsed_sentence = parser.parse(sentence.split())\n",
    "\n",
    "#access N node of tree\n",
    "for tree in parsed_sentence:\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == 'PP':\n",
    "            # get the N in the NP in PP recursively\n",
    "            for sub_subtree in subtree.subtrees():\n",
    "                if sub_subtree.label() == 'N':\n",
    "                    print(sub_subtree.leaves())\n",
    "                    parsed = True\n",
    "                    break\n",
    "            \n",
    "            # print(subtree.leaves())\n",
    "            parsed = True\n",
    "            break\n",
    "\n",
    "# for tree in parser.parse(sentence.split()):\n",
    "#     parsed = True\n",
    "#     print(type(tree))\n",
    "#     print(tree)\n",
    "#     tree.pretty_print()\n",
    "\n",
    "# if not parsed:\n",
    "#    print(\"The sentence could not be parsed with the given grammar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a35557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894a049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ed5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78003ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50809d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713abd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd342af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb6d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320250c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcfdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361037c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853da7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854b1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c354e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9029d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b82ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde16c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8edf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de333ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f8512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79b951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70399ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b592693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37ab5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ba067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fda6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('preposition_wordnet_wiki_pop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25da450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa6dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
